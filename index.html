<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-K8S运维管理" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/15/K8S%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/" class="article-date">
  <time class="dt-published" datetime="2024-04-15T09:27:00.000Z" itemprop="datePublished">2024-04-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/15/K8S%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/">K8S运维管理</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、Helm包管理器"><a href="#一、Helm包管理器" class="headerlink" title="一、Helm包管理器"></a>一、Helm包管理器</h1><h2 id="1-1-什么是Helm？"><a href="#1-1-什么是Helm？" class="headerlink" title="1.1 什么是Helm？"></a>1.1 什么是Helm？</h2><p>Kubernetes 包管理器<br>Helm 是查找、分享和使用软件构件 Kubernetes 的最优方式。</p>
<p>Helm 管理名为 chart 的 Kubernetes 包的工具。Helm 可以做以下的事情：</p>
<ul>
<li>从头开始创建新的 chart</li>
<li>将 chart 打包成归档(tgz)文件</li>
<li>与存储 chart 的仓库进行交互</li>
<li>在现有的 Kubernetes 集群中安装和卸载 chart</li>
<li>管理与 Helm 一起安装的 chart 的发布周期</li>
</ul>
<p>对于Helm，有三个重要的概念：</p>
<ol>
<li><em>chart</em> 创建Kubernetes应用程序所必需的一组信息。</li>
<li><em>config</em> 包含了可以合并到打包的chart中的配置信息，用于创建一个可发布的对象。</li>
<li><em>release</em> 是一个与特定配置相结合的chart的运行实例。</li>
</ol>
<h2 id="1-2-Helm架构"><a href="#1-2-Helm架构" class="headerlink" title="1.2 Helm架构"></a>1.2 Helm架构</h2><h3 id="1-2-1-重要概念"><a href="#1-2-1-重要概念" class="headerlink" title="1.2.1 重要概念"></a>1.2.1 重要概念</h3><ul>
<li><strong>chart：</strong> <em>chart</em> 创建 Kubernetes 应用程序所必需的一组信息。</li>
<li><strong>config：</strong> <em>config</em> 包含了可以合并到打包的 chart 中的配置信息，用于创建一个可发布的对象。</li>
<li><strong>release：</strong> <em>release</em> 是一个与特定配置相结合的 chart 的运行实例。</li>
</ul>
<h3 id="1-2-2-组件"><a href="#1-2-2-组件" class="headerlink" title="1.2.2 组件"></a>1.2.2 组件</h3><h4 id="Helm客户端"><a href="#Helm客户端" class="headerlink" title="Helm客户端"></a>Helm客户端</h4><p><strong>Helm 客户端</strong> 是终端用户的命令行客户端。负责以下内容：</p>
<ol>
<li>本地 chart 开发</li>
<li>管理仓库</li>
<li>管理发布</li>
<li>与 Helm 库建立接口<ul>
<li>发送安装的 chart</li>
<li>发送升级或卸载现有发布的请求</li>
</ul>
</li>
</ol>
<h4 id="Helm库"><a href="#Helm库" class="headerlink" title="Helm库"></a>Helm库</h4><p><strong>Helm 库</strong> 提供执行所有 Helm 操作的逻辑。与 Kubernetes API 服务交互并提供以下功能：</p>
<ul>
<li>结合 chart 和配置来构建版本</li>
<li>将 chart 安装到 Kubernetes 中，并提供后续发布对象</li>
<li>与 Kubernetes 交互升级和卸载 chart</li>
</ul>
<p>独立的 Helm 库封装了 Helm 逻辑以便不同的客户端可以使用它。</p>
<h2 id="1-3-安装Helm"><a href="#1-3-安装Helm" class="headerlink" title="1.3 安装Helm"></a>1.3 安装Helm</h2><p><a target="_blank" rel="noopener" href="https://helm.sh/zh/docs/intro/install/">https://helm.sh/zh/docs/intro/install/</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 下载二进制文件</span><br><span class="line">wget https://get.helm.sh/helm-v3.14.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 解压</span><br><span class="line">tar zxvf helm-v3.14.4-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 将解压目录下的helm程序移动至/usr/local/bin/helm</span><br><span class="line">mv linux-amd64/helm /usr/local/bin/</span><br><span class="line"></span><br><span class="line"># 添加阿里云helm仓库</span><br></pre></td></tr></table></figure>

<h2 id="1-4-Helm的常用命令"><a href="#1-4-Helm的常用命令" class="headerlink" title="1.4 Helm的常用命令"></a>1.4 Helm的常用命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">helm repo # 列出、增加、更新、删除 chart 仓库</span><br><span class="line">helm search # 使用关键词搜索 chart</span><br><span class="line">helm pull # 拉取远程仓库中的 chart 到本地</span><br><span class="line">helm create # 在本地创建新的 chart</span><br><span class="line">helm dependency # 管理 chart 依赖</span><br><span class="line">helm install # 安装 chart</span><br><span class="line">helm list # 列出所有release</span><br><span class="line">helm lint # 检查 chart 配置是否有误</span><br><span class="line">helm package # 打包本地 chart</span><br><span class="line">helm rollback # 回滚 release 到历史版本</span><br><span class="line">helm uninstall # 卸载 release</span><br><span class="line">helm upgrade # 升级release</span><br></pre></td></tr></table></figure>

<h2 id="1-5-chart详解"><a href="#1-5-chart详解" class="headerlink" title="1.5 chart详解"></a>1.5 chart详解</h2><h3 id="1-5-1-目录结构"><a href="#1-5-1-目录结构" class="headerlink" title="1.5.1 目录结构"></a>1.5.1 目录结构</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mychart</span><br><span class="line">├── Chart.yaml</span><br><span class="line">├── charts # 该目录保存其他依赖的 chart（子 chart）</span><br><span class="line">├── templates # chart 配置模板，用于渲染最终的 Kubernetes YAML 文件</span><br><span class="line">│   ├── NOTES.txt # 用户运行 helm install 时候的提示信息</span><br><span class="line">│   ├── _helpers.tpl # 用于创建模板时的帮助类</span><br><span class="line">│   ├── deployment.yaml # Kubernetes deployment 配置</span><br><span class="line">│   ├── ingress.yaml # Kubernetes ingress 配置</span><br><span class="line">│   ├── service.yaml # Kubernetes service 配置</span><br><span class="line">│   ├── serviceaccount.yaml # Kubernetes serviceaccount 配置</span><br><span class="line">│   └── tests</span><br><span class="line">│       └── test-connection.yaml</span><br><span class="line">└── values.yaml # 定义 chart 模板中的自定义配置的默认值，可以在执行 helm install 或 helm update 的时候覆盖</span><br></pre></td></tr></table></figure>

<h3 id="1-5-2-Redis-chart实践"><a href="#1-5-2-Redis-chart实践" class="headerlink" title="1.5.2 Redis chart实践"></a>1.5.2 Redis chart实践</h3><ol>
<li><p>修改helm源</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 查看默认仓库</span><br><span class="line">helm repo list</span><br><span class="line"></span><br><span class="line"># 添加仓库</span><br><span class="line">helm repo add bitnami https://charts.bitnami.com/bitnami</span><br><span class="line">helm repo add azure http://mirror.azure.cn/kubernetes/charts</span><br></pre></td></tr></table></figure>
</li>
<li><p>搜索redis chart</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 搜索 redis chart</span><br><span class="line">helm search repo redis</span><br><span class="line"></span><br><span class="line"># 查看安装说明</span><br><span class="line">helm show readme bitnami/redis</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置安装</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 先将 chart 拉到本地</span><br><span class="line">helm pull bitnami/redis</span><br><span class="line"></span><br><span class="line"># 解压后，修改 values.yaml 中的参数</span><br><span class="line">tar zxvf redis-19.1.5.tgz</span><br><span class="line"></span><br><span class="line"># 修改 storageClass 为 nfs-csi</span><br><span class="line"># 设置 redis 密码 password</span><br><span class="line"># 修改集群架构 architecture，默认是主从（replication，3个节点），可以修改为 standalone 单机模式</span><br><span class="line"># 修改实例存储大小 persistence.size 为需要的大小</span><br><span class="line"># 修改 service.nodePorts.redis 向外暴露端口，范围 &lt;30000-32767&gt;</span><br><span class="line"></span><br><span class="line"># 安装操作</span><br><span class="line"># 创建命名空间</span><br><span class="line">kubectl create namespace redis-test</span><br><span class="line"></span><br><span class="line"># 安装</span><br><span class="line">cd ../</span><br><span class="line">helm install redis ./redis -n redis-test</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看安装情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看 helm 安装列表</span><br><span class="line">helm list</span><br><span class="line"></span><br><span class="line"># 查看 redis 命名空间下所有对象信息</span><br><span class="line">kubectl get all -n redis-test</span><br></pre></td></tr></table></figure>
</li>
<li><p>升级与回滚</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">要想升级 chart 可以修改本地的 chart 配置并执行：</span><br><span class="line">helm upgrade [RELEASE] [CHART] [flags]</span><br><span class="line">helm upgrade redis ./redis -n redis-test</span><br><span class="line">使用 helm ls 的命令查看当前运行的 chart 的 release 版本，并使用下面的命令回滚到历史版本：</span><br><span class="line"></span><br><span class="line">helm rollback &lt;RELEASE&gt; [REVISION] [flags]</span><br><span class="line"></span><br><span class="line"># 查看历史</span><br><span class="line">helm history redis</span><br><span class="line"># 回退到上一版本</span><br><span class="line">helm rollback redis -n redis-test</span><br><span class="line"># 回退到指定版本</span><br><span class="line">helm rollback redis 3 -n redis-test</span><br></pre></td></tr></table></figure>
</li>
<li><p>helm卸载redis</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm delete redis -n redis</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="二、k8s集群监控"><a href="#二、k8s集群监控" class="headerlink" title="二、k8s集群监控"></a>二、k8s集群监控</h1><h2 id="2-1-监控方案"><a href="#2-1-监控方案" class="headerlink" title="2.1 监控方案"></a>2.1 监控方案</h2><h3 id="Heapster"><a href="#Heapster" class="headerlink" title="Heapster"></a>Heapster</h3><p>Heapster 是容器集群监控和性能分析工具，天然的支持Kubernetes 和 CoreOS。</p>
<p>Kubernetes 有个出名的监控 agent—cAdvisor。在每个kubernetes Node 上都会运行 cAdvisor，它会收集本机以及容器的监控数据(cpu,memory,filesystem,network,uptime)。<br>在较新的版本中，K8S 已经将 cAdvisor 功能集成到 kubelet 组件中。每个 Node 节点可以直接进行 web 访问。</p>
<h3 id="Weave-Scope"><a href="#Weave-Scope" class="headerlink" title="Weave Scope"></a>Weave Scope</h3><p><a target="_blank" rel="noopener" href="https://github.com/weaveworks/scope">Weave Scope</a> 可以监控 kubernetes 集群中的一系列资源的状态、资源使用情况、应用拓扑、scale、还可以直接通过浏览器进入容器内部调试等，其提供的功能包括：</p>
<ul>
<li>交互式拓扑界面</li>
<li>图形模式和表格模式</li>
<li>过滤功能</li>
<li>搜索功能</li>
<li>实时度量</li>
<li>容器排错</li>
<li>插件扩展</li>
</ul>
<h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><p>Prometheus 是一套开源的监控系统、报警、时间序列的集合，最初由 SoundCloud 开发，后来随着越来越多公司的使用，于是便独立成开源项目。自此以后，许多公司和组织都采用了 Prometheus 作为监控告警工具。</p>
<h2 id="2-2-Prometheus-监控-k8s"><a href="#2-2-Prometheus-监控-k8s" class="headerlink" title="2.2 Prometheus 监控 k8s"></a>2.2 Prometheus 监控 k8s</h2><h3 id="2-2-1-自定义配置"><a href="#2-2-1-自定义配置" class="headerlink" title="2.2.1 自定义配置"></a>2.2.1 自定义配置</h3><h4 id="2-2-1-1-创建-ConfigMap-配置"><a href="#2-2-1-1-创建-ConfigMap-配置" class="headerlink" title="2.2.1.1 创建 ConfigMap 配置"></a>2.2.1.1 创建 ConfigMap 配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"># 创建 prometheus-config.yml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus-config</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">data:</span><br><span class="line">  prometheus.yml: |</span><br><span class="line">    global:</span><br><span class="line">      scrape_interval: 15s </span><br><span class="line">      evaluation_interval: 15s</span><br><span class="line">    scrape_configs:</span><br><span class="line">      - job_name: &#x27;prometheus&#x27;</span><br><span class="line">        static_configs:</span><br><span class="line">        - targets: [&#x27;localhost:9090&#x27;]</span><br><span class="line">        </span><br><span class="line"># 配置 job，帮助 prometheus 找到所有节点信息，修改 prometheus-config.yml 增加为如下内容</span><br><span class="line">      - job_name: &#x27;kubernetes-nodes&#x27;</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: node</span><br><span class="line"></span><br><span class="line">      - job_name: &#x27;kubernetes-service&#x27;</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: service</span><br><span class="line"></span><br><span class="line">      - job_name: &#x27;kubernetes-endpoints&#x27;</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: endpoints</span><br><span class="line"></span><br><span class="line">      - job_name: &#x27;kubernetes-ingress&#x27;</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: ingress</span><br><span class="line">        </span><br><span class="line"># 监控k8s集群</span><br><span class="line">      - job_name: &#x27;kubernetes-kubelet&#x27;</span><br><span class="line">        scheme: https</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: node</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">        - target_label: __address__</span><br><span class="line">          replacement: kubernetes.default.svc:443</span><br><span class="line">        - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">          regex: (.+)</span><br><span class="line">          target_label: __metrics_path__</span><br><span class="line">          replacement: /api/v1/nodes/$&#123;1&#125;/proxy/metrics</span><br><span class="line">          </span><br><span class="line"># 从 kubelet 获取节点容器资源使用情况</span><br><span class="line">      - job_name: &#x27;kubernetes-cadvisor&#x27;</span><br><span class="line">        scheme: https</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: node</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - target_label: __address__</span><br><span class="line">          replacement: kubernetes.default.svc:443</span><br><span class="line">        - source_labels: [__meta_kubernetes_node_name]</span><br><span class="line">          regex: (.+)</span><br><span class="line">          target_label: __metrics_path__</span><br><span class="line">          replacement: /api/v1/nodes/$&#123;1&#125;/proxy/metrics/cadvisor</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_node_label_(.+)</span><br><span class="line">          </span><br><span class="line"># 增加监控采集任务</span><br><span class="line">      - job_name: &#x27;kubernetes-pods&#x27;</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: pod</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]</span><br><span class="line">          action: keep</span><br><span class="line">          regex: true</span><br><span class="line">        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]</span><br><span class="line">          action: replace</span><br><span class="line">          target_label: __metrics_path__</span><br><span class="line">          regex: (.+)</span><br><span class="line">        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]</span><br><span class="line">          action: replace</span><br><span class="line">          regex: ([^:]+)(?::\d+)?;(\d+)</span><br><span class="line">          replacement: $1:$2</span><br><span class="line">          target_label: __address__</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_pod_label_(.+)</span><br><span class="line">        - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">          action: replace</span><br><span class="line">          target_label: kubernetes_namespace</span><br><span class="line">        - source_labels: [__meta_kubernetes_pod_name]</span><br><span class="line">          action: replace</span><br><span class="line">          target_label: kubernetes_pod_name</span><br><span class="line"></span><br><span class="line"># 通过监控 apiserver 来监控所有对应的入口请求，增加 api-server 监控配置</span><br><span class="line">      - job_name: &#x27;kubernetes-apiservers&#x27;</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: endpoints</span><br><span class="line">        scheme: https</span><br><span class="line">        tls_config:</span><br><span class="line">          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]</span><br><span class="line">          action: keep</span><br><span class="line">          regex: default;kubernetes;https</span><br><span class="line">        - target_label: __address__</span><br><span class="line">          replacement: kubernetes.default.svc:443</span><br><span class="line"></span><br><span class="line"># 配置监控采集所有 service/ingress 信息，加入配置到配置文件</span><br><span class="line">      - job_name: &#x27;kubernetes-services&#x27;</span><br><span class="line">        metrics_path: /probe</span><br><span class="line">        params:</span><br><span class="line">          module: [http_2xx]</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: service</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]</span><br><span class="line">          action: keep</span><br><span class="line">          regex: true</span><br><span class="line">        - source_labels: [__address__]</span><br><span class="line">          target_label: __param_target</span><br><span class="line">        - target_label: __address__</span><br><span class="line">          replacement: blackbox-exporter.default.svc.cluster.local:9115</span><br><span class="line">        - source_labels: [__param_target]</span><br><span class="line">          target_label: instance</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_service_label_(.+)</span><br><span class="line">        - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">          target_label: kubernetes_namespace</span><br><span class="line">        - source_labels: [__meta_kubernetes_service_name]</span><br><span class="line">          target_label: kubernetes_name</span><br><span class="line"></span><br><span class="line">      - job_name: &#x27;kubernetes-ingresses&#x27;</span><br><span class="line">        metrics_path: /probe</span><br><span class="line">        params:</span><br><span class="line">          module: [http_2xx]</span><br><span class="line">        kubernetes_sd_configs:</span><br><span class="line">        - role: ingress</span><br><span class="line">        relabel_configs:</span><br><span class="line">        - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe]</span><br><span class="line">          action: keep</span><br><span class="line">          regex: true</span><br><span class="line">        - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]</span><br><span class="line">          regex: (.+);(.+);(.+)</span><br><span class="line">          replacement: $&#123;1&#125;://$&#123;2&#125;$&#123;3&#125;</span><br><span class="line">          target_label: __param_target</span><br><span class="line">        - target_label: __address__</span><br><span class="line">          replacement: blackbox-exporter.default.svc.cluster.local:9115</span><br><span class="line">        - source_labels: [__param_target]</span><br><span class="line">          target_label: instance</span><br><span class="line">        - action: labelmap</span><br><span class="line">          regex: __meta_kubernetes_ingress_label_(.+)</span><br><span class="line">        - source_labels: [__meta_kubernetes_namespace]</span><br><span class="line">          target_label: kubernetes_namespace</span><br><span class="line">        - source_labels: [__meta_kubernetes_ingress_name]</span><br><span class="line">          target_label: kubernetes_name</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-2-创建-Prometheus-配置"><a href="#2-2-1-2-创建-Prometheus-配置" class="headerlink" title="2.2.1.2 创建 Prometheus 配置"></a>2.2.1.2 创建 Prometheus 配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"># 创建 prometheus-deploy.yml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  labels:</span><br><span class="line">    name: prometheus</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: prometheus</span><br><span class="line">    protocol: TCP</span><br><span class="line">    port: 9090</span><br><span class="line">    targetPort: 9090</span><br><span class="line">  selector:</span><br><span class="line">    app: prometheus</span><br><span class="line">  type: NodePort</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    name: prometheus</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: prometheus</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: prometheus</span><br><span class="line">    # 配置认证权限</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: prometheus</span><br><span class="line">      serviceAccount: prometheus</span><br><span class="line">      containers:</span><br><span class="line">      - name: prometheus</span><br><span class="line">        image: prom/prometheus</span><br><span class="line">        command:</span><br><span class="line">        - &quot;/bin/prometheus&quot;</span><br><span class="line">        args:</span><br><span class="line">        - &quot;--config.file=/etc/prometheus/prometheus.yml&quot;</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9090</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &quot;/etc/prometheus&quot;</span><br><span class="line">          name: prometheus-config</span><br><span class="line">        - mountPath: &quot;/etc/localtime&quot;</span><br><span class="line">          name: timezone</span><br><span class="line">      volumes:</span><br><span class="line">      - name: prometheus-config</span><br><span class="line">        configMap:</span><br><span class="line">          name: prometheus-config</span><br><span class="line">      - name: timezone</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /usr/share/zoneinfo/Asia/Shanghai</span><br><span class="line">          </span><br><span class="line"># 查看 serviceaccount 认证证书</span><br><span class="line">kubectl exec -it &lt;pod name&gt; -- ls /var/run/secrets/kubernetes.io/serviceaccount/</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-3-配置访问权限"><a href="#2-2-1-3-配置访问权限" class="headerlink" title="2.2.1.3 配置访问权限"></a>2.2.1.3 配置访问权限</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># 创建 prometheus-rbac-setup.yml</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  - nodes/proxy</span><br><span class="line">  - services</span><br><span class="line">  - endpoints</span><br><span class="line">  - pods</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- apiGroups:</span><br><span class="line">  - extensions</span><br><span class="line">  resources:</span><br><span class="line">  - ingresses</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">- nonResourceURLs: [&quot;/metrics&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;]</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: prometheus</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: prometheus</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: prometheus</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line"># 查看 serviceaccount 认证证书</span><br><span class="line">kubectl exec -it &lt;pod name&gt; -- ls /var/run/secrets/kubernetes.io/serviceaccount/</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-4-系统时间同步"><a href="#2-2-1-4-系统时间同步" class="headerlink" title="2.2.1.4 系统时间同步"></a>2.2.1.4 系统时间同步</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看系统时间</span><br><span class="line">date</span><br><span class="line"></span><br><span class="line"># 同步网络时间</span><br><span class="line">ntpdate cn.pool.ntp.org</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-5-创建命名空间配置"><a href="#2-2-1-5-创建命名空间配置" class="headerlink" title="2.2.1.5 创建命名空间配置"></a>2.2.1.5 创建命名空间配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 创建 kube-monitoring.yml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-monitoring</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-6-监控-k8s-集群"><a href="#2-2-1-6-监控-k8s-集群" class="headerlink" title="2.2.1.6 监控 k8s 集群"></a>2.2.1.6 监控 k8s 集群</h4><h5 id="Exporter-监控资源使用情况"><a href="#Exporter-监控资源使用情况" class="headerlink" title="Exporter 监控资源使用情况"></a>Exporter 监控资源使用情况</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 创建 node-exporter-daemonset.yml 文件</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: node-exporter</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: node-exporter</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        prometheus.io/scrape: &#x27;true&#x27;</span><br><span class="line">        prometheus.io/port: &#x27;9100&#x27;</span><br><span class="line">        prometheus.io/path: &#x27;metrics&#x27;</span><br><span class="line">      labels:</span><br><span class="line">        app: node-exporter</span><br><span class="line">      name: node-exporter</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: prom/node-exporter</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: node-exporter</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9100</span><br><span class="line">          hostPort: 9100</span><br><span class="line">          name: scrape</span><br><span class="line">      hostNetwork: true</span><br><span class="line">      hostPID: true</span><br></pre></td></tr></table></figure>

<h5 id="对-Ingress-和-Service-进行网络探测"><a href="#对-Ingress-和-Service-进行网络探测" class="headerlink" title="对 Ingress 和 Service 进行网络探测"></a>对 Ingress 和 Service 进行网络探测</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"># 创建 blackbox-exporter.yaml 进行网络探测</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: blackbox-exporter</span><br><span class="line">  name: blackbox-exporter</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: blackbox</span><br><span class="line">    port: 9115</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: blackbox-exporter</span><br><span class="line">  type: ClusterIP</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: blackbox-exporter</span><br><span class="line">  name: blackbox-exporter</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: blackbox-exporter</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: blackbox-exporter</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: prom/blackbox-exporter</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        name: blackbox-exporter</span><br></pre></td></tr></table></figure>

<h4 id="2-2-1-7-Grafana可视化"><a href="#2-2-1-7-Grafana可视化" class="headerlink" title="2.2.1.7 Grafana可视化"></a>2.2.1.7 Grafana可视化</h4><p>Grafana 是一个通用的可视化工具。‘通用’意味着 Grafana 不仅仅适用于展示 Prometheus 下的监控数据，也同样适用于一些其他的数据可视化需求。在开始使用Grafana之前，我们首先需要明确一些 Grafana下的基本概念，以帮助用户能够快速理解Grafana。</p>
<h5 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h5><ul>
<li><p>数据源（Data Source）</p>
<p>对于Grafana而言，Prometheus这类为其提供数据的对象均称为数据源（Data Source）。目前，Grafana官方提供了对：Graphite, InfluxDB, OpenTSDB, Prometheus, Elasticsearch, CloudWatch的支持。对于Grafana管理员而言，只需要将这些对象以数据源的形式添加到Grafana中，Grafana便可以轻松的实现对这些数据的可视化工作。</p>
</li>
<li><p>仪表盘（Dashboard）</p>
<p><a target="_blank" rel="noopener" href="https://grafana.com/grafana/dashboards/?pg=hp&plcmt=lt-box-dashboards">官方 Dashboard 模板</a></p>
<p>通过数据源定义好可视化的数据来源之后，对于用户而言最重要的事情就是实现数据的可视化。在Grafana中，我们通过Dashboard来组织和管理我们的数据可视化图表：</p>
</li>
</ul>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_dashboard_components.png" alt="仪表盘"></p>
<ul>
<li><p>组织和用户</p>
<p>作为一个通用可视化工具，Grafana除了提供灵活的可视化定制能力以外，还提供了面向企业的组织级管理能力。在Grafana中Dashboard是属于一个<strong>Organization（组织）</strong>，通过Organization，可以在更大规模上使用Grafana，例如对于一个企业而言，我们可以创建多个Organization，其中<strong>User（用户）</strong>可以属于一个或多个不同的Organization。 并且在不同的Organization下，可以为User赋予不同的权限。 从而可以有效的根据企业的组织架构定义整个管理模型。</p>
</li>
</ul>
<h5 id="集成-Grafana"><a href="#集成-Grafana" class="headerlink" title="集成 Grafana"></a>集成 Grafana</h5><ul>
<li>部署 Grafana</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana-core</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">  labels:</span><br><span class="line">    app: grafana</span><br><span class="line">    component: core</span><br><span class="line">spec:</span><br><span class="line">  serviceName: &quot;grafana&quot;</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: grafana</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: grafana</span><br><span class="line">        component: core</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: grafana/grafana:6.5.3</span><br><span class="line">        name: grafana-core</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        env:</span><br><span class="line">          # The following env variables set up basic auth twith the default admin user and admin password.</span><br><span class="line">          - name: GF_AUTH_BASIC_ENABLED</span><br><span class="line">            value: &quot;true&quot;</span><br><span class="line">          - name: GF_AUTH_ANONYMOUS_ENABLED</span><br><span class="line">            value: &quot;false&quot;</span><br><span class="line">          # - name: GF_AUTH_ANONYMOUS_ORG_ROLE</span><br><span class="line">          #   value: Admin</span><br><span class="line">          # does not really work, because of template variables in exported dashboards:</span><br><span class="line">          # - name: GF_DASHBOARDS_JSON_ENABLED</span><br><span class="line">          #   value: &quot;true&quot;</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /login</span><br><span class="line">            port: 3000</span><br><span class="line">          # initialDelaySeconds: 30</span><br><span class="line">          # timeoutSeconds: 1</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: grafana-persistent-storage</span><br><span class="line">          mountPath: /var/lib/grafana</span><br><span class="line">          subPath: grafana</span><br><span class="line">      securityContext:</span><br><span class="line">        fsGroup: 472</span><br><span class="line">        runAsUser: 472</span><br><span class="line">  volumeClaimTemplates:</span><br><span class="line">  - metadata:</span><br><span class="line">      name: grafana-persistent-storage</span><br><span class="line">    spec:</span><br><span class="line">      storageClassName: nfs-csi</span><br><span class="line">      accessModes:</span><br><span class="line">      - ReadWriteOnce</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: &quot;1Gi&quot;</span><br></pre></td></tr></table></figure>

<ul>
<li>服务发现</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: grafana</span><br><span class="line">  namespace: kube-monitoring</span><br><span class="line">  labels:</span><br><span class="line">    app: grafana</span><br><span class="line">    component: core</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 3000</span><br><span class="line">      nodePort: 30011</span><br><span class="line">  selector:</span><br><span class="line">    app: grafana</span><br><span class="line">    component: core</span><br></pre></td></tr></table></figure>

<ul>
<li><p>配置 Grafana 面板</p>
<p>添加 Prometheus 数据源</p>
<p><a target="_blank" rel="noopener" href="https://grafana.com/grafana/dashboards/315">下载 k8s 面板</a>，导入该面板</p>
</li>
</ul>
<h4 id="2-2-1-8-使用自定义配置创建资源"><a href="#2-2-1-8-使用自定义配置创建资源" class="headerlink" title="2.2.1.8 使用自定义配置创建资源"></a>2.2.1.8 使用自定义配置创建资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 创建部署对象</span><br><span class="line">kubectl create -f ./</span><br><span class="line"></span><br><span class="line"># 查看 pod 状态</span><br><span class="line">kubectl get pods -l app=node-exporter</span><br><span class="line">kubectl get pods -l app=prometheus</span><br><span class="line"></span><br><span class="line"># 获取服务信息</span><br><span class="line">kubectl get svc -l name=prometheus</span><br><span class="line"></span><br><span class="line"># 通过 http://节点ip:端口 进行访问</span><br><span class="line"></span><br><span class="line"># 查看 serviceaccount 认证证书</span><br><span class="line">kubectl exec -it &lt;pod name&gt; -- ls /var/run/secrets/kubernetes.io/serviceaccount/</span><br><span class="line"></span><br><span class="line"># 查看 daemonset 运行状态</span><br><span class="line">kubectl get daemonsets -l app=node-exporter</span><br><span class="line"></span><br><span class="line"># 删除部署对象</span><br><span class="line">kubectl delete -f ./</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-kube-prometheus"><a href="#2-2-2-kube-prometheus" class="headerlink" title="2.2.2 kube-prometheus"></a>2.2.2 kube-prometheus</h3><p>项目地址：<a target="_blank" rel="noopener" href="https://github.com/prometheus-operator/kube-prometheus">https://github.com/prometheus-operator/kube-prometheus</a></p>
<h4 id="创建资源"><a href="#创建资源" class="headerlink" title="创建资源"></a>创建资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">下载资源</span><br><span class="line">wget https://github.com/prometheus-operator/kube-prometheus/archive/refs/heads/release-0.11.zip</span><br><span class="line"></span><br><span class="line">解压</span><br><span class="line">unzip release-0.11.zip</span><br><span class="line"></span><br><span class="line">创建资源</span><br><span class="line">cd kube-prometheus-release-0.11/manifests/</span><br><span class="line">kubectl create -f setup/</span><br><span class="line">kubectl apply -f ./</span><br><span class="line"></span><br><span class="line">查看资源</span><br><span class="line">kubectl get all -n monitoring</span><br></pre></td></tr></table></figure>

<h4 id="配置-Ingress"><a href="#配置-Ingress" class="headerlink" title="配置 Ingress"></a>配置 Ingress</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 通过域名访问（没有域名可以在主机配置 hosts，IP地址设置为ingress所在的node的IP）</span><br><span class="line">192.168.122.110 grafana.xiaoyu123.cn</span><br><span class="line">192.168.122.110 prometheus.xiaoyu123.cn</span><br><span class="line">192.168.122.110 alertmanager.xiaoyu123.cn</span><br><span class="line"></span><br><span class="line"># 创建 prometheus-ingress.yaml</span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress</span><br><span class="line">metadata:</span><br><span class="line">  namespace: monitoring</span><br><span class="line">  name: prometheus-ingress</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: grafana.xiaoyu123.cn  # 访问 Grafana 域名</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: grafana</span><br><span class="line">            port:</span><br><span class="line">              number: 3000</span><br><span class="line">  - host: prometheus.xiaoyu123.cn  # 访问 Prometheus 域名</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: prometheus-k8s </span><br><span class="line">            port:</span><br><span class="line">              number: 9090</span><br><span class="line">  - host: alertmanager.xiaoyu123.cn  # 访问 alertmanager 域名</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        pathType: Prefix</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: alertmanager-main</span><br><span class="line">            port:</span><br><span class="line">              number: 9093</span><br><span class="line"></span><br><span class="line"># 创建 ingress</span><br><span class="line">kubectl apply -f prometheus-ingress.yaml</span><br></pre></td></tr></table></figure>

<h4 id="卸载"><a href="#卸载" class="headerlink" title="卸载"></a>卸载</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f ./</span><br><span class="line">kubectl delete -f setup/</span><br></pre></td></tr></table></figure>

<h1 id="三、ELK日志管理"><a href="#三、ELK日志管理" class="headerlink" title="三、ELK日志管理"></a>三、ELK日志管理</h1><h2 id="3-1-ELK-组成"><a href="#3-1-ELK-组成" class="headerlink" title="3.1 ELK 组成"></a>3.1 ELK 组成</h2><h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><p>ES 作为一个搜索型文档数据库，拥有优秀的搜索能力，以及提供了丰富的 REST API 让我们可以轻松的调用接口。</p>
<h3 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h3><p>Filebeat 是一款轻量的数据收集工具</p>
<h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><p>通过 Logstash 同样可以进行日志收集，但是若每一个节点都需要收集时，部署 Logstash 有点过重，因此这里主要用到 Logstash 的数据清洗能力，收集交给 Filebeat 去实现</p>
<h3 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h3><p>Kibana 是一款基于 ES 的可视化操作界面工具，利用 Kibana 可以实现非常方便的 ES 可视化操作</p>
<h2 id="3-2-集成-ELK"><a href="#3-2-集成-ELK" class="headerlink" title="3.2 集成 ELK"></a>3.2 集成 ELK</h2><h3 id="部署-es-搜索服务"><a href="#部署-es-搜索服务" class="headerlink" title="部署 es 搜索服务"></a>部署 es 搜索服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line"># 需要提前给 es 落盘节点打上标签 </span><br><span class="line">kubectl label nodes k8s-node1 es=data</span><br><span class="line"></span><br><span class="line"># 创建 elasticsearch.yaml</span><br><span class="line">--- </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: Service </span><br><span class="line">metadata: </span><br><span class="line">  name: elasticsearch-logging </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: elasticsearch-logging </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">    kubernetes.io/name: &quot;Elasticsearch&quot; </span><br><span class="line">spec: </span><br><span class="line">  ports: </span><br><span class="line">  - port: 9200 </span><br><span class="line">    protocol: TCP </span><br><span class="line">    targetPort: db </span><br><span class="line">  selector: </span><br><span class="line">    k8s-app: elasticsearch-logging </span><br><span class="line">--- </span><br><span class="line"># RBAC authn and authz </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: ServiceAccount </span><br><span class="line">metadata: </span><br><span class="line">  name: elasticsearch-logging </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: elasticsearch-logging </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">--- </span><br><span class="line">kind: ClusterRole </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1 </span><br><span class="line">metadata: </span><br><span class="line">  name: elasticsearch-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: elasticsearch-logging </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">rules: </span><br><span class="line">- apiGroups: </span><br><span class="line">  - &quot;&quot; </span><br><span class="line">  resources: </span><br><span class="line">  - &quot;services&quot; </span><br><span class="line">  - &quot;namespaces&quot; </span><br><span class="line">  - &quot;endpoints&quot; </span><br><span class="line">  verbs: </span><br><span class="line">  - &quot;get&quot; </span><br><span class="line">--- </span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1 </span><br><span class="line">metadata: </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  name: elasticsearch-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: elasticsearch-logging </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">subjects: </span><br><span class="line">- kind: ServiceAccount </span><br><span class="line">  name: elasticsearch-logging </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  apiGroup: &quot;&quot; </span><br><span class="line">roleRef: </span><br><span class="line">  kind: ClusterRole </span><br><span class="line">  name: elasticsearch-logging </span><br><span class="line">  apiGroup: &quot;&quot; </span><br><span class="line">--- </span><br><span class="line"># Elasticsearch deployment itself </span><br><span class="line">apiVersion: apps/v1 </span><br><span class="line">kind: StatefulSet #使用statefulset创建Pod </span><br><span class="line">metadata: </span><br><span class="line">  name: elasticsearch-logging #pod名称,使用statefulSet创建的Pod是有序号有顺序的 </span><br><span class="line">  namespace: kube-logging  #命名空间 </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: elasticsearch-logging </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">    srv: srv-elasticsearch </span><br><span class="line">spec: </span><br><span class="line">  serviceName: elasticsearch-logging #与svc相关联，这可以确保使用以下DNS地址访问Statefulset中的每个pod (es-cluster-[0,1,2].elasticsearch.elk.svc.cluster.local) </span><br><span class="line">  replicas: 1 #副本数量,单节点 </span><br><span class="line">  selector: </span><br><span class="line">    matchLabels: </span><br><span class="line">      k8s-app: elasticsearch-logging #和pod template配置的labels相匹配 </span><br><span class="line">  template: </span><br><span class="line">    metadata: </span><br><span class="line">      labels: </span><br><span class="line">        k8s-app: elasticsearch-logging </span><br><span class="line">        kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    spec: </span><br><span class="line">      serviceAccountName: elasticsearch-logging </span><br><span class="line">      containers: </span><br><span class="line">      - image: docker.io/library/elasticsearch:7.9.3 </span><br><span class="line">        name: elasticsearch-logging </span><br><span class="line">        resources: </span><br><span class="line">          # need more cpu upon initialization, therefore burstable class </span><br><span class="line">          limits: </span><br><span class="line">            cpu: 1000m </span><br><span class="line">            memory: 2Gi </span><br><span class="line">          requests: </span><br><span class="line">            cpu: 100m </span><br><span class="line">            memory: 500Mi </span><br><span class="line">        ports: </span><br><span class="line">        - containerPort: 9200 </span><br><span class="line">          name: db </span><br><span class="line">          protocol: TCP </span><br><span class="line">        - containerPort: 9300 </span><br><span class="line">          name: transport </span><br><span class="line">          protocol: TCP </span><br><span class="line">        volumeMounts: </span><br><span class="line">        - name: elasticsearch-logging </span><br><span class="line">          mountPath: /usr/share/elasticsearch/data/   #挂载点 </span><br><span class="line">        env: </span><br><span class="line">        - name: &quot;NAMESPACE&quot; </span><br><span class="line">          valueFrom: </span><br><span class="line">            fieldRef: </span><br><span class="line">              fieldPath: metadata.namespace </span><br><span class="line">        - name: &quot;discovery.type&quot;  #定义单节点类型 </span><br><span class="line">          value: &quot;single-node&quot; </span><br><span class="line">        - name: ES_JAVA_OPTS #设置Java的内存参数，可以适当进行加大调整 </span><br><span class="line">          value: &quot;-Xms512m -Xmx2g&quot;  </span><br><span class="line">      volumes: </span><br><span class="line">      - name: elasticsearch-logging </span><br><span class="line">        hostPath: </span><br><span class="line">          path: /data/es/ </span><br><span class="line">      nodeSelector: #如果需要匹配落盘节点可以添加 nodeSelect </span><br><span class="line">        es: data </span><br><span class="line">      tolerations: </span><br><span class="line">      - effect: NoSchedule </span><br><span class="line">        operator: Exists </span><br><span class="line">      # Elasticsearch requires vm.max_map_count to be at least 262144. </span><br><span class="line">      # If your OS already sets up this number to a higher value, feel free </span><br><span class="line">      # to remove this init container. </span><br><span class="line">      initContainers: #容器初始化前的操作 </span><br><span class="line">      - name: elasticsearch-logging-init </span><br><span class="line">        image: alpine:3.6 </span><br><span class="line">        command: [&quot;/sbin/sysctl&quot;, &quot;-w&quot;, &quot;vm.max_map_count=262144&quot;] #添加mmap计数限制，太低可能造成内存不足的错误 </span><br><span class="line">        securityContext:  #仅应用到指定的容器上，并且不会影响Volume </span><br><span class="line">          privileged: true #运行特权容器 </span><br><span class="line">      - name: increase-fd-ulimit </span><br><span class="line">        image: busybox </span><br><span class="line">        imagePullPolicy: IfNotPresent </span><br><span class="line">        command: [&quot;sh&quot;, &quot;-c&quot;, &quot;ulimit -n 65536&quot;] #修改文件描述符最大数量 </span><br><span class="line">        securityContext: </span><br><span class="line">          privileged: true </span><br><span class="line">      - name: elasticsearch-volume-init #es数据落盘初始化，加上777权限 </span><br><span class="line">        image: alpine:3.6 </span><br><span class="line">        command: </span><br><span class="line">          - chmod </span><br><span class="line">          - -R </span><br><span class="line">          - &quot;777&quot; </span><br><span class="line">          - /usr/share/elasticsearch/data/ </span><br><span class="line">        volumeMounts: </span><br><span class="line">        - name: elasticsearch-logging </span><br><span class="line">          mountPath: /usr/share/elasticsearch/data/</span><br><span class="line"></span><br><span class="line"># 创建 namespace.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-logging</span><br><span class="line"></span><br><span class="line"># 创建命名空间</span><br><span class="line">kubectl apply -f namespace.yaml</span><br><span class="line"></span><br><span class="line"># 创建服务</span><br><span class="line">kubectl apply -f elasticsearch.yaml</span><br><span class="line"></span><br><span class="line"># 查看 pod 启用情况</span><br><span class="line">kubectl get pod -n kube-logging</span><br></pre></td></tr></table></figure>

<h3 id="部署-logstash-数据清洗"><a href="#部署-logstash-数据清洗" class="headerlink" title="部署 logstash 数据清洗"></a>部署 logstash 数据清洗</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br></pre></td><td class="code"><pre><span class="line"># 创建 logstash.yaml 并部署服务</span><br><span class="line">--- </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: Service </span><br><span class="line">metadata: </span><br><span class="line">  name: logstash </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">spec: </span><br><span class="line">  ports: </span><br><span class="line">  - port: 5044 </span><br><span class="line">    targetPort: beats </span><br><span class="line">  selector: </span><br><span class="line">    type: logstash </span><br><span class="line">  clusterIP: None </span><br><span class="line">--- </span><br><span class="line">apiVersion: apps/v1 </span><br><span class="line">kind: Deployment </span><br><span class="line">metadata: </span><br><span class="line">  name: logstash </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">spec: </span><br><span class="line">  selector: </span><br><span class="line">    matchLabels: </span><br><span class="line">      type: logstash </span><br><span class="line">  template: </span><br><span class="line">    metadata: </span><br><span class="line">      labels: </span><br><span class="line">        type: logstash </span><br><span class="line">        srv: srv-logstash </span><br><span class="line">    spec: </span><br><span class="line">      containers: </span><br><span class="line">      - image: docker.io/kubeimages/logstash:7.9.3 #该镜像支持arm64和amd64两种架构 </span><br><span class="line">        name: logstash </span><br><span class="line">        ports: </span><br><span class="line">        - containerPort: 5044 </span><br><span class="line">          name: beats </span><br><span class="line">        command: </span><br><span class="line">        - logstash </span><br><span class="line">        - &#x27;-f&#x27; </span><br><span class="line">        - &#x27;/etc/logstash_c/logstash.conf&#x27; </span><br><span class="line">        env: </span><br><span class="line">        - name: &quot;XPACK_MONITORING_ELASTICSEARCH_HOSTS&quot; </span><br><span class="line">          value: &quot;http://elasticsearch-logging:9200&quot; </span><br><span class="line">        volumeMounts: </span><br><span class="line">        - name: config-volume </span><br><span class="line">          mountPath: /etc/logstash_c/ </span><br><span class="line">        - name: config-yml-volume </span><br><span class="line">          mountPath: /usr/share/logstash/config/ </span><br><span class="line">        - name: timezone </span><br><span class="line">          mountPath: /etc/localtime </span><br><span class="line">        resources: #logstash一定要加上资源限制，避免对其他业务造成资源抢占影响 </span><br><span class="line">          limits: </span><br><span class="line">            cpu: 1000m </span><br><span class="line">            memory: 2048Mi </span><br><span class="line">          requests: </span><br><span class="line">            cpu: 512m </span><br><span class="line">            memory: 512Mi </span><br><span class="line">      volumes: </span><br><span class="line">      - name: config-volume </span><br><span class="line">        configMap: </span><br><span class="line">          name: logstash-conf </span><br><span class="line">          items: </span><br><span class="line">          - key: logstash.conf </span><br><span class="line">            path: logstash.conf </span><br><span class="line">      - name: timezone </span><br><span class="line">        hostPath: </span><br><span class="line">          path: /etc/localtime </span><br><span class="line">      - name: config-yml-volume </span><br><span class="line">        configMap: </span><br><span class="line">          name: logstash-yml </span><br><span class="line">          items: </span><br><span class="line">          - key: logstash.yml </span><br><span class="line">            path: logstash.yml </span><br><span class="line"> </span><br><span class="line">--- </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: ConfigMap </span><br><span class="line">metadata: </span><br><span class="line">  name: logstash-conf </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    type: logstash </span><br><span class="line">data: </span><br><span class="line">  logstash.conf: |- </span><br><span class="line">    input &#123;</span><br><span class="line">      beats &#123; </span><br><span class="line">        port =&gt; 5044 </span><br><span class="line">      &#125; </span><br><span class="line">    &#125; </span><br><span class="line">    filter &#123;</span><br><span class="line">      # 处理 ingress 日志 </span><br><span class="line">      if [kubernetes][container][name] == &quot;nginx-ingress-controller&quot; &#123;</span><br><span class="line">        json &#123;</span><br><span class="line">          source =&gt; &quot;message&quot; </span><br><span class="line">          target =&gt; &quot;ingress_log&quot; </span><br><span class="line">        &#125;</span><br><span class="line">        if [ingress_log][requesttime] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            convert =&gt; [&quot;[ingress_log][requesttime]&quot;, &quot;float&quot;] </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if [ingress_log][upstremtime] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            convert =&gt; [&quot;[ingress_log][upstremtime]&quot;, &quot;float&quot;] </span><br><span class="line">          &#125;</span><br><span class="line">        &#125; </span><br><span class="line">        if [ingress_log][status] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            convert =&gt; [&quot;[ingress_log][status]&quot;, &quot;float&quot;] </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if  [ingress_log][httphost] and [ingress_log][uri] &#123;</span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[ingress_log][entry]&quot; =&gt; &quot;%&#123;[ingress_log][httphost]&#125;%&#123;[ingress_log][uri]&#125;&quot;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            split =&gt; [&quot;[ingress_log][entry]&quot;,&quot;/&quot;] </span><br><span class="line">          &#125; </span><br><span class="line">          if [ingress_log][entry][1] &#123; </span><br><span class="line">            mutate &#123; </span><br><span class="line">              add_field =&gt; &#123;&quot;[ingress_log][entrypoint]&quot; =&gt; &quot;%&#123;[ingress_log][entry][0]&#125;/%&#123;[ingress_log][entry][1]&#125;&quot;&#125; </span><br><span class="line">              remove_field =&gt; &quot;[ingress_log][entry]&quot; </span><br><span class="line">            &#125;</span><br><span class="line">          &#125; else &#123; </span><br><span class="line">            mutate &#123; </span><br><span class="line">              add_field =&gt; &#123;&quot;[ingress_log][entrypoint]&quot; =&gt; &quot;%&#123;[ingress_log][entry][0]&#125;/&quot;&#125; </span><br><span class="line">              remove_field =&gt; &quot;[ingress_log][entry]&quot; </span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      # 处理以srv进行开头的业务服务日志 </span><br><span class="line">      if [kubernetes][container][name] =~ /^srv*/ &#123; </span><br><span class="line">        json &#123; </span><br><span class="line">          source =&gt; &quot;message&quot; </span><br><span class="line">          target =&gt; &quot;tmp&quot; </span><br><span class="line">        &#125; </span><br><span class="line">        if [kubernetes][namespace] == &quot;kube-logging&quot; &#123; </span><br><span class="line">          drop&#123;&#125; </span><br><span class="line">        &#125; </span><br><span class="line">        if [tmp][level] &#123; </span><br><span class="line">          mutate&#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][level]&quot; =&gt; &quot;%&#123;[tmp][level]&#125;&quot;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">          if [applog][level] == &quot;debug&quot;&#123; </span><br><span class="line">            drop&#123;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">        &#125; </span><br><span class="line">        if [tmp][msg] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][msg]&quot; =&gt; &quot;%&#123;[tmp][msg]&#125;&quot;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">        &#125; </span><br><span class="line">        if [tmp][func] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][func]&quot; =&gt; &quot;%&#123;[tmp][func]&#125;&quot;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">        &#125; </span><br><span class="line">        if [tmp][cost]&#123; </span><br><span class="line">          if &quot;ms&quot; in [tmp][cost] &#123; </span><br><span class="line">            mutate &#123; </span><br><span class="line">              split =&gt; [&quot;[tmp][cost]&quot;,&quot;m&quot;] </span><br><span class="line">              add_field =&gt; &#123;&quot;[applog][cost]&quot; =&gt; &quot;%&#123;[tmp][cost][0]&#125;&quot;&#125; </span><br><span class="line">              convert =&gt; [&quot;[applog][cost]&quot;, &quot;float&quot;] </span><br><span class="line">            &#125; </span><br><span class="line">          &#125; else &#123; </span><br><span class="line">            mutate &#123; </span><br><span class="line">              add_field =&gt; &#123;&quot;[applog][cost]&quot; =&gt; &quot;%&#123;[tmp][cost]&#125;&quot;&#125; </span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if [tmp][method] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][method]&quot; =&gt; &quot;%&#123;[tmp][method]&#125;&quot;&#125; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if [tmp][request_url] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][request_url]&quot; =&gt; &quot;%&#123;[tmp][request_url]&#125;&quot;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">        &#125;</span><br><span class="line">        if [tmp][meta._id] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][traceId]&quot; =&gt; &quot;%&#123;[tmp][meta._id]&#125;&quot;&#125; </span><br><span class="line">          &#125; </span><br><span class="line">        &#125; </span><br><span class="line">        if [tmp][project] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][project]&quot; =&gt; &quot;%&#123;[tmp][project]&#125;&quot;&#125; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if [tmp][time] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][time]&quot; =&gt; &quot;%&#123;[tmp][time]&#125;&quot;&#125; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if [tmp][status] &#123; </span><br><span class="line">          mutate &#123; </span><br><span class="line">            add_field =&gt; &#123;&quot;[applog][status]&quot; =&gt; &quot;%&#123;[tmp][status]&#125;&quot;&#125; </span><br><span class="line">            convert =&gt; [&quot;[applog][status]&quot;, &quot;float&quot;] </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      mutate &#123; </span><br><span class="line">        rename =&gt; [&quot;kubernetes&quot;, &quot;k8s&quot;] </span><br><span class="line">        remove_field =&gt; &quot;beat&quot; </span><br><span class="line">        remove_field =&gt; &quot;tmp&quot; </span><br><span class="line">        remove_field =&gt; &quot;[k8s][labels][app]&quot; </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    output &#123; </span><br><span class="line">      elasticsearch &#123; </span><br><span class="line">        hosts =&gt; [&quot;http://elasticsearch-logging:9200&quot;] </span><br><span class="line">        codec =&gt; json </span><br><span class="line">        index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot; #索引名称以logstash+日志进行每日新建 </span><br><span class="line">      &#125; </span><br><span class="line">    &#125; </span><br><span class="line">---</span><br><span class="line"> </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: ConfigMap </span><br><span class="line">metadata: </span><br><span class="line">  name: logstash-yml </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    type: logstash </span><br><span class="line">data: </span><br><span class="line">  logstash.yml: |- </span><br><span class="line">    http.host: &quot;0.0.0.0&quot; </span><br><span class="line">    xpack.monitoring.elasticsearch.hosts: http://elasticsearch-logging:9200</span><br></pre></td></tr></table></figure>

<h3 id="部署-filebeat-数据采集"><a href="#部署-filebeat-数据采集" class="headerlink" title="部署 filebeat 数据采集"></a>部署 filebeat 数据采集</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"># 创建 filebeat.yaml 并部署</span><br><span class="line">--- </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: ConfigMap </span><br><span class="line">metadata: </span><br><span class="line">  name: filebeat-config </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: filebeat </span><br><span class="line">data: </span><br><span class="line">  filebeat.yml: |- </span><br><span class="line">    filebeat.inputs: </span><br><span class="line">    - type: container </span><br><span class="line">      enable: true</span><br><span class="line">      paths: </span><br><span class="line">        - /var/log/containers/*.log #这里是filebeat采集挂载到pod中的日志目录 </span><br><span class="line">      processors: </span><br><span class="line">        - add_kubernetes_metadata: #添加k8s的字段用于后续的数据清洗 </span><br><span class="line">            host: $&#123;NODE_NAME&#125;</span><br><span class="line">            matchers: </span><br><span class="line">            - logs_path: </span><br><span class="line">                logs_path: &quot;/var/log/containers/&quot; </span><br><span class="line">    #output.kafka:  #如果日志量较大，es中的日志有延迟，可以选择在filebeat和logstash中间加入kafka </span><br><span class="line">    #  hosts: [&quot;kafka-log-01:9092&quot;, &quot;kafka-log-02:9092&quot;, &quot;kafka-log-03:9092&quot;] </span><br><span class="line">    # topic: &#x27;topic-test-log&#x27; </span><br><span class="line">    #  version: 2.0.0 </span><br><span class="line">    output.logstash: #因为还需要部署logstash进行数据的清洗，因此filebeat是把数据推到logstash中 </span><br><span class="line">       hosts: [&quot;logstash:5044&quot;] </span><br><span class="line">       enabled: true </span><br><span class="line">--- </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: ServiceAccount </span><br><span class="line">metadata: </span><br><span class="line">  name: filebeat </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: filebeat</span><br><span class="line">--- </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole </span><br><span class="line">metadata: </span><br><span class="line">  name: filebeat </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: filebeat </span><br><span class="line">rules: </span><br><span class="line">- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group </span><br><span class="line">  resources: </span><br><span class="line">  - namespaces </span><br><span class="line">  - pods </span><br><span class="line">  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;] </span><br><span class="line">--- </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">  name: filebeat </span><br><span class="line">subjects: </span><br><span class="line">- kind: ServiceAccount </span><br><span class="line">  name: filebeat </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">roleRef: </span><br><span class="line">  kind: ClusterRole </span><br><span class="line">  name: filebeat </span><br><span class="line">  apiGroup: rbac.authorization.k8s.io </span><br><span class="line">--- </span><br><span class="line">apiVersion: apps/v1 </span><br><span class="line">kind: DaemonSet </span><br><span class="line">metadata: </span><br><span class="line">  name: filebeat </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: filebeat </span><br><span class="line">spec: </span><br><span class="line">  selector: </span><br><span class="line">    matchLabels: </span><br><span class="line">      k8s-app: filebeat </span><br><span class="line">  template: </span><br><span class="line">    metadata: </span><br><span class="line">      labels: </span><br><span class="line">        k8s-app: filebeat </span><br><span class="line">    spec: </span><br><span class="line">      serviceAccountName: filebeat </span><br><span class="line">      terminationGracePeriodSeconds: 30 </span><br><span class="line">      containers: </span><br><span class="line">      - name: filebeat </span><br><span class="line">        image: docker.io/kubeimages/filebeat:7.9.3 #该镜像支持arm64和amd64两种架构 </span><br><span class="line">        args: [ </span><br><span class="line">          &quot;-c&quot;, &quot;/etc/filebeat.yml&quot;, </span><br><span class="line">          &quot;-e&quot;,&quot;-httpprof&quot;,&quot;0.0.0.0:6060&quot; </span><br><span class="line">        ] </span><br><span class="line">        #ports: </span><br><span class="line">        #  - containerPort: 6060 </span><br><span class="line">        #    hostPort: 6068 </span><br><span class="line">        env: </span><br><span class="line">        - name: NODE_NAME </span><br><span class="line">          valueFrom: </span><br><span class="line">            fieldRef: </span><br><span class="line">              fieldPath: spec.nodeName </span><br><span class="line">        - name: ELASTICSEARCH_HOST </span><br><span class="line">          value: elasticsearch-logging </span><br><span class="line">        - name: ELASTICSEARCH_PORT </span><br><span class="line">          value: &quot;9200&quot; </span><br><span class="line">        securityContext: </span><br><span class="line">          runAsUser: 0 </span><br><span class="line">          # If using Red Hat OpenShift uncomment this: </span><br><span class="line">          #privileged: true </span><br><span class="line">        resources: </span><br><span class="line">          limits: </span><br><span class="line">            memory: 1000Mi </span><br><span class="line">            cpu: 1000m </span><br><span class="line">          requests: </span><br><span class="line">            memory: 100Mi </span><br><span class="line">            cpu: 100m </span><br><span class="line">        volumeMounts: </span><br><span class="line">        - name: config #挂载的是filebeat的配置文件 </span><br><span class="line">          mountPath: /etc/filebeat.yml </span><br><span class="line">          readOnly: true </span><br><span class="line">          subPath: filebeat.yml </span><br><span class="line">        - name: data #持久化filebeat数据到宿主机上 </span><br><span class="line">          mountPath: /usr/share/filebeat/data </span><br><span class="line">        - name: varlibdockercontainers #这里主要是把宿主机上的源日志目录挂载到filebeat容器中,如果没有修改docker或者containerd的runtime进行了标准的日志落盘路径，可以把mountPath改为/var/lib </span><br><span class="line">          mountPath: /var/lib</span><br><span class="line">          readOnly: true </span><br><span class="line">        - name: varlog #这里主要是把宿主机上/var/log/pods和/var/log/containers的软链接挂载到filebeat容器中 </span><br><span class="line">          mountPath: /var/log/ </span><br><span class="line">          readOnly: true </span><br><span class="line">        - name: timezone </span><br><span class="line">          mountPath: /etc/localtime </span><br><span class="line">      volumes: </span><br><span class="line">      - name: config </span><br><span class="line">        configMap: </span><br><span class="line">          defaultMode: 0600 </span><br><span class="line">          name: filebeat-config </span><br><span class="line">      - name: varlibdockercontainers </span><br><span class="line">        hostPath: #如果没有修改docker或者containerd的runtime进行了标准的日志落盘路径，可以把path改为/var/lib </span><br><span class="line">          path: /var/lib</span><br><span class="line">      - name: varlog </span><br><span class="line">        hostPath: </span><br><span class="line">          path: /var/log/ </span><br><span class="line">      # data folder stores a registry of read status for all files, so we don&#x27;t send everything again on a Filebeat pod restart </span><br><span class="line">      - name: inputs </span><br><span class="line">        configMap: </span><br><span class="line">          defaultMode: 0600 </span><br><span class="line">          name: filebeat-inputs </span><br><span class="line">      - name: data </span><br><span class="line">        hostPath: </span><br><span class="line">          path: /data/filebeat-data </span><br><span class="line">          type: DirectoryOrCreate </span><br><span class="line">      - name: timezone </span><br><span class="line">        hostPath: </span><br><span class="line">          path: /etc/localtime </span><br><span class="line">      tolerations: #加入容忍能够调度到每一个节点 </span><br><span class="line">      - effect: NoExecute </span><br><span class="line">        key: dedicated </span><br><span class="line">        operator: Equal </span><br><span class="line">        value: gpu </span><br><span class="line">      - effect: NoSchedule </span><br><span class="line">        operator: Exists</span><br></pre></td></tr></table></figure>

<h3 id="部署-kibana-可视化界面"><a href="#部署-kibana-可视化界面" class="headerlink" title="部署 kibana 可视化界面"></a>部署 kibana 可视化界面</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"># 此处有配置 kibana 访问域名，如果没有域名则需要在本机配置 hosts</span><br><span class="line">192.168.113.121 kibana.wolfcode.cn</span><br><span class="line"></span><br><span class="line"># 创建 kibana.yaml 并创建服务</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  namespace: kube-logging</span><br><span class="line">  name: kibana-config</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kibana</span><br><span class="line">data:</span><br><span class="line">  kibana.yml: |-</span><br><span class="line">    server.name: kibana</span><br><span class="line">    server.host: &quot;0&quot;</span><br><span class="line">    i18n.locale: zh-CN                      #设置默认语言为中文</span><br><span class="line">    elasticsearch:</span><br><span class="line">      hosts: $&#123;ELASTICSEARCH_HOSTS&#125;         #es集群连接地址，由于我这都都是k8s部署且在一个ns下，可以直接使用service name连接</span><br><span class="line">--- </span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: Service </span><br><span class="line">metadata: </span><br><span class="line">  name: kibana </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: kibana </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">    kubernetes.io/name: &quot;Kibana&quot; </span><br><span class="line">    srv: srv-kibana </span><br><span class="line">spec: </span><br><span class="line">  type: NodePort</span><br><span class="line">  ports: </span><br><span class="line">  - port: 5601 </span><br><span class="line">    protocol: TCP </span><br><span class="line">    targetPort: ui </span><br><span class="line">  selector: </span><br><span class="line">    k8s-app: kibana </span><br><span class="line">--- </span><br><span class="line">apiVersion: apps/v1 </span><br><span class="line">kind: Deployment </span><br><span class="line">metadata: </span><br><span class="line">  name: kibana </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: kibana </span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot; </span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile </span><br><span class="line">    srv: srv-kibana </span><br><span class="line">spec: </span><br><span class="line">  replicas: 1 </span><br><span class="line">  selector: </span><br><span class="line">    matchLabels: </span><br><span class="line">      k8s-app: kibana </span><br><span class="line">  template: </span><br><span class="line">    metadata: </span><br><span class="line">      labels: </span><br><span class="line">        k8s-app: kibana </span><br><span class="line">    spec: </span><br><span class="line">      containers: </span><br><span class="line">      - name: kibana </span><br><span class="line">        image: docker.io/kubeimages/kibana:7.9.3 #该镜像支持arm64和amd64两种架构 </span><br><span class="line">        resources: </span><br><span class="line">          # need more cpu upon initialization, therefore burstable class </span><br><span class="line">          limits: </span><br><span class="line">            cpu: 1000m </span><br><span class="line">          requests: </span><br><span class="line">            cpu: 100m </span><br><span class="line">        env: </span><br><span class="line">          - name: ELASTICSEARCH_HOSTS </span><br><span class="line">            value: http://elasticsearch-logging:9200 </span><br><span class="line">        ports: </span><br><span class="line">        - containerPort: 5601 </span><br><span class="line">          name: ui </span><br><span class="line">          protocol: TCP </span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config</span><br><span class="line">          mountPath: /usr/share/kibana/config/kibana.yml</span><br><span class="line">          readOnly: true</span><br><span class="line">          subPath: kibana.yml</span><br><span class="line">      volumes:</span><br><span class="line">      - name: config</span><br><span class="line">        configMap:</span><br><span class="line">          name: kibana-config</span><br><span class="line">--- </span><br><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress </span><br><span class="line">metadata: </span><br><span class="line">  name: kibana </span><br><span class="line">  namespace: kube-logging </span><br><span class="line">spec: </span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules: </span><br><span class="line">  - host: kibana.wolfcode.cn</span><br><span class="line">    http: </span><br><span class="line">      paths: </span><br><span class="line">      - path: / </span><br><span class="line">        pathType: Prefix</span><br><span class="line">        backend: </span><br><span class="line">          service:</span><br><span class="line">            name: kibana </span><br><span class="line">            port:</span><br><span class="line">              number: 5601</span><br></pre></td></tr></table></figure>

<h3 id="Kibana-配置"><a href="#Kibana-配置" class="headerlink" title="Kibana 配置"></a>Kibana 配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line">进入 Kibana 界面，打开菜单中的 Stack Management 可以看到采集到的日志</span><br><span class="line"></span><br><span class="line">避免日志越来越大，占用磁盘过多，进入 索引生命周期策略 界面点击 创建策略 按钮</span><br><span class="line"></span><br><span class="line">设置策略名称为 logstash-history-ilm-policy</span><br><span class="line">关闭 热阶段</span><br><span class="line">开启删除阶段，设置保留天数为 7 天</span><br><span class="line"></span><br><span class="line">保存配置</span><br><span class="line"></span><br><span class="line">为了方便在 discover 中查看日志，选择 索引模式 然后点击 创建索引模式 按钮</span><br><span class="line"></span><br><span class="line">索引模式名称 里面配置 logstash-*</span><br><span class="line">点击下一步</span><br><span class="line"></span><br><span class="line">时间字段 选择 @timestamp</span><br><span class="line">点击 创建索引模式 按钮</span><br><span class="line"></span><br><span class="line">由于部署的单节点，产生副本后索引状态会变成 yellow，打开 dev tools，取消所有索引的副本数</span><br><span class="line">PUT _all/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;number_of_replicas&quot;: 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">为了标准化日志中的 map 类型，以及解决链接索引生命周期策略，我们需要修改默认模板</span><br><span class="line">PUT _template/logstash </span><br><span class="line">&#123; </span><br><span class="line">    &quot;order&quot;: 1, </span><br><span class="line">    &quot;index_patterns&quot;: [ </span><br><span class="line">      &quot;logstash-*&quot; </span><br><span class="line">    ], </span><br><span class="line">    &quot;settings&quot;: &#123; </span><br><span class="line">      &quot;index&quot;: &#123; </span><br><span class="line">      &quot;lifecycle&quot; : &#123; </span><br><span class="line">          &quot;name&quot; : &quot;logstash-history-ilm-policy&quot; </span><br><span class="line">        &#125;, </span><br><span class="line">        &quot;number_of_shards&quot;: &quot;2&quot;, </span><br><span class="line">        &quot;refresh_interval&quot;: &quot;5s&quot;, </span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;0&quot; </span><br><span class="line">      &#125; </span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;mappings&quot;: &#123; </span><br><span class="line">        &quot;properties&quot;: &#123; </span><br><span class="line">          &quot;@timestamp&quot;: &#123; </span><br><span class="line">            &quot;type&quot;: &quot;date&quot; </span><br><span class="line">          &#125;, </span><br><span class="line">          &quot;applog&quot;: &#123; </span><br><span class="line">            &quot;dynamic&quot;: true, </span><br><span class="line">            &quot;properties&quot;: &#123; </span><br><span class="line">              &quot;cost&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;float&quot; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;func&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;method&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot; </span><br><span class="line">              &#125; </span><br><span class="line">            &#125; </span><br><span class="line">          &#125;, </span><br><span class="line">          &quot;k8s&quot;: &#123; </span><br><span class="line">            &quot;dynamic&quot;: true, </span><br><span class="line">            &quot;properties&quot;: &#123; </span><br><span class="line">              &quot;namespace&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;keyword&quot; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;container&quot;: &#123; </span><br><span class="line">                &quot;dynamic&quot;: true, </span><br><span class="line">                &quot;properties&quot;: &#123; </span><br><span class="line">                  &quot;name&quot;: &#123; </span><br><span class="line">                    &quot;type&quot;: &quot;keyword&quot; </span><br><span class="line">                  &#125; </span><br><span class="line">                &#125; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;labels&quot;: &#123; </span><br><span class="line">                &quot;dynamic&quot;: true, </span><br><span class="line">                &quot;properties&quot;: &#123; </span><br><span class="line">                  &quot;srv&quot;: &#123; </span><br><span class="line">                    &quot;type&quot;: &quot;keyword&quot; </span><br><span class="line">                  &#125; </span><br><span class="line">                &#125; </span><br><span class="line">              &#125; </span><br><span class="line">            &#125; </span><br><span class="line">          &#125;, </span><br><span class="line">          &quot;geoip&quot;: &#123; </span><br><span class="line">            &quot;dynamic&quot;: true, </span><br><span class="line">            &quot;properties&quot;: &#123; </span><br><span class="line">              &quot;ip&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;ip&quot; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;latitude&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;float&quot; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;location&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;geo_point&quot; </span><br><span class="line">              &#125;, </span><br><span class="line">              &quot;longitude&quot;: &#123; </span><br><span class="line">                &quot;type&quot;: &quot;float&quot; </span><br><span class="line">              &#125; </span><br><span class="line">            &#125; </span><br><span class="line">          &#125; </span><br><span class="line">      &#125; </span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;aliases&quot;: &#123;&#125; </span><br><span class="line">  &#125; </span><br><span class="line"></span><br><span class="line">最后即可通过 discover 进行搜索了</span><br></pre></td></tr></table></figure>

<h1 id="四、Kubernetes可视化界面"><a href="#四、Kubernetes可视化界面" class="headerlink" title="四、Kubernetes可视化界面"></a>四、Kubernetes可视化界面</h1><h2 id="4-1-Kubernetes-Dashboard"><a href="#4-1-Kubernetes-Dashboard" class="headerlink" title="4.1 Kubernetes Dashboard"></a>4.1 Kubernetes Dashboard</h2><h3 id="4-1-1-安装"><a href="#4-1-1-安装" class="headerlink" title="4.1.1 安装"></a>4.1.1 安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># 下载官方部署配置文件</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml</span><br><span class="line"></span><br><span class="line"># 修改属性</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort   #新增</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"># 创建资源</span><br><span class="line">kubectl apply -f recommend.yaml</span><br><span class="line"></span><br><span class="line"># 查看资源是否已经就绪</span><br><span class="line">kubectl get all -n kubernetes-dashboard -o wide</span><br><span class="line"></span><br><span class="line"># 访问测试</span><br><span class="line">https://节点ip:端口</span><br></pre></td></tr></table></figure>

<h3 id="4-1-2-配置所有权限账号"><a href="#4-1-2-配置所有权限账号" class="headerlink" title="4.1.2 配置所有权限账号"></a>4.1.2 配置所有权限账号</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 创建账号配置文件</span><br><span class="line">touch dashboard-admin.yaml</span><br><span class="line"></span><br><span class="line"># 配置文件</span><br><span class="line">apiVersion: v1 </span><br><span class="line">kind: ServiceAccount </span><br><span class="line">metadata: </span><br><span class="line">  labels: </span><br><span class="line">    k8s-app: kubernetes-dashboard </span><br><span class="line">  name: dashboard-admin </span><br><span class="line">  namespace: kubernetes-dashboard </span><br><span class="line">--- </span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1 </span><br><span class="line">kind: ClusterRoleBinding </span><br><span class="line">metadata: </span><br><span class="line">  name: dashboard-admin-cluster-role </span><br><span class="line">roleRef: </span><br><span class="line">  apiGroup: rbac.authorization.k8s.io </span><br><span class="line">  kind: ClusterRole </span><br><span class="line">  name: cluster-admin </span><br><span class="line">subjects: </span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: dashboard-admin</span><br><span class="line">    namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"># 创建资源</span><br><span class="line">kubectl  apply -f dashboard-admin.yaml</span><br><span class="line"></span><br><span class="line"># 查看账号信息</span><br><span class="line">kubectl describe serviceaccount dashboard-admin -n kubernetes-dashboard</span><br><span class="line"></span><br><span class="line"># 获取账号的 token 登录 dashboard</span><br><span class="line">kubectl describe secrets dashboard-admin-token-5crbd -n kubernetes-dashboard</span><br></pre></td></tr></table></figure>

<h3 id="4-1-3-Dashboard-的使用"><a href="#4-1-3-Dashboard-的使用" class="headerlink" title="4.1.3 Dashboard 的使用"></a>4.1.3 Dashboard 的使用</h3><h2 id="4-2-kubesphere"><a href="#4-2-kubesphere" class="headerlink" title="4.2 kubesphere"></a>4.2 kubesphere</h2><p><a target="_blank" rel="noopener" href="https://kubesphere.io/zh/">https://kubesphere.io/zh/</a></p>
<p>KubeSphere 愿景是打造一个以 Kubernetes 为内核的云原生分布式操作系统，它的架构可以非常方便地使第三方应用与云原生生态组件进行即插即用（plug-and-play）的集成，支持云原生应用在多云与多集群的统一分发和运维管理。</p>
<h3 id="4-2-1-本地存储动态PVC"><a href="#4-2-1-本地存储动态PVC" class="headerlink" title="4.2.1 本地存储动态PVC"></a>4.2.1 本地存储动态PVC</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 在所有节点安装 iSCSI 协议客户端（OpenEBS 需要该协议提供存储支持）</span><br><span class="line">yum install iscsi-initiator-utils -y</span><br><span class="line"># 设置开机启动</span><br><span class="line">systemctl enable --now iscsid</span><br><span class="line"># 启动服务</span><br><span class="line">systemctl start iscsid</span><br><span class="line"># 查看服务状态</span><br><span class="line">systemctl status iscsid</span><br><span class="line"></span><br><span class="line"># 安装 OpenEBS </span><br><span class="line">kubectl apply -f https://openebs.github.io/charts/openebs-operator.yaml</span><br><span class="line"></span><br><span class="line"># 查看状态（下载镜像可能需要一些时间）</span><br><span class="line">kubectl get all -n openebs</span><br><span class="line"></span><br><span class="line"># 在主节点创建本地 storage class</span><br><span class="line">kubectl apply -f default-storage-class.yaml</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-安装"><a href="#4-2-2-安装" class="headerlink" title="4.2.2 安装"></a>4.2.2 安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 安装资源</span><br><span class="line">kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/kubesphere-installer.yaml</span><br><span class="line">kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.3.1/cluster-configuration.yaml</span><br><span class="line"></span><br><span class="line"># 检查安装日志</span><br><span class="line">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l &#x27;app in (ks-install, ks-installer)&#x27; -o jsonpath=&#x27;&#123;.items[0].metadata.name&#125;&#x27;) -f</span><br><span class="line"></span><br><span class="line"># 查看端口</span><br><span class="line">kubectl get svc/ks-console -n kubesphere-system</span><br><span class="line"></span><br><span class="line"># 默认端口是 30880，如果是云服务商，或开启了防火墙，记得要开放该端口</span><br><span class="line"></span><br><span class="line"># 登录控制台访问，账号密码：admin/P@88w0rd</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3-启用可插拔组件"><a href="#4-2-3-启用可插拔组件" class="headerlink" title="4.2.3 启用可插拔组件"></a>4.2.3 启用可插拔组件</h3><p><a target="_blank" rel="noopener" href="https://kubesphere.io/zh/docs/v3.3/pluggable-components/">https://kubesphere.io/zh/docs/v3.3/pluggable-components/</a></p>
<h2 id="4-3-Rancher"><a href="#4-3-Rancher" class="headerlink" title="4.3 Rancher"></a>4.3 Rancher</h2><p><a target="_blank" rel="noopener" href="https://www.rancher.cn/">https://www.rancher.cn/</a></p>
<h2 id="4-4-Kuboard"><a href="#4-4-Kuboard" class="headerlink" title="4.4 Kuboard"></a>4.4 Kuboard</h2><p><a target="_blank" rel="noopener" href="https://www.kuboard.cn/">https://www.kuboard.cn/</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/15/K8S%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/" data-id="clzi2h9b20000l47n6ipu44fm" data-title="K8S运维管理" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-K8S实战进阶" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/" class="article-date">
  <time class="dt-published" datetime="2024-04-01T05:58:00.000Z" itemprop="datePublished">2024-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/">K8S实战进阶</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、搭建Kubernetes集群"><a href="#一、搭建Kubernetes集群" class="headerlink" title="一、搭建Kubernetes集群"></a>一、搭建Kubernetes集群</h1><h2 id="1-1-搭建方案"><a href="#1-1-搭建方案" class="headerlink" title="1.1 搭建方案"></a>1.1 搭建方案</h2><h3 id="1-1-1-minikube"><a href="#1-1-1-minikube" class="headerlink" title="1.1.1 minikube"></a>1.1.1 minikube</h3><p><a target="_blank" rel="noopener" href="https://minikube.sigs.k8s.io/">minikube</a> 是一个工具， 能让你在本地运行 Kubernetes。 minikube 在你的个人计算机（包括 Windows、macOS 和 Linux PC）上运行一个一体化（all-in-one）或多节点的本地 Kubernetes 集群，以便你来尝试 Kubernetes 或者开展每天的开发工作。</p>
<p><a target="_blank" rel="noopener" href="https://minikube.sigs.k8s.io/docs/start/">官方安装文档</a></p>
<h3 id="1-1-2-kubeadm"><a href="#1-1-2-kubeadm" class="headerlink" title="1.1.2 kubeadm"></a>1.1.2 kubeadm</h3><p>你可以使用 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/">kubeadm</a> 工具来创建和管理 Kubernetes 集群。 该工具能够执行必要的动作并用一种用户友好的方式启动一个可用的、安全的集群。</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">安装 kubeadm</a> 展示了如何安装 kubeadm 的过程。一旦安装了 kubeadm， 你就可以使用它来<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">创建一个集群</a>。</p>
<h4 id="服务器要求"><a href="#服务器要求" class="headerlink" title="服务器要求"></a>服务器要求</h4><p>IP地址：</p>
<ul>
<li>k8s-master：192.168.122.100</li>
<li>k8s-node1：192.168.122.110</li>
<li>k8s-node2：192.168.122.120</li>
</ul>
<p>最低配置：2核、2G内存、20G硬盘</p>
<p>需要联网，不能联网的话需要提供对应镜像的私有仓库</p>
<h4 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h4><p>操作系统：Debian 12</p>
<p>Docker版本：Docker version 26.0.0</p>
<p>K8S版本：1.23.17（1.24移除了docker支持）</p>
<h4 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h4><ol>
<li><p>初始操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#关闭防火墙</span><br><span class="line">systemctl stop firewalld    #停止firewalld服务</span><br><span class="line">systemctl disable firewalld    #firewalld禁止自启</span><br><span class="line"></span><br><span class="line">ufw disable    #ufw禁用</span><br><span class="line"></span><br><span class="line">#关闭selinux</span><br><span class="line">sed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config  #永久</span><br><span class="line">setenforce 0    #临时</span><br><span class="line"></span><br><span class="line">#关闭swap（关闭swap后，需要重启主机）</span><br><span class="line">swapoff -a    #临时</span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab    #永久</span><br><span class="line">free -h    #查看内存</span><br><span class="line"></span><br><span class="line">#根据规划设置主机名</span><br><span class="line">vim /etc/hostname</span><br><span class="line"></span><br><span class="line">#将桥接的IPv4流量传递到iptablesd的链路</span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system    #生效</span><br><span class="line"></span><br><span class="line">#时间同步</span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate ntp.aliyun.com</span><br><span class="line"></span><br><span class="line">apt install -y ntp</span><br><span class="line">ntpdate ntp.aliyun.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装基础软件（所有节点）</p>
<ol>
<li><p>安装docker</p>
<p><a target="_blank" rel="noopener" href="https://docs.docker.com/engine/">docker安装官方文档</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#卸载旧版本docker</span><br><span class="line">for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done</span><br><span class="line"></span><br><span class="line">#设置Docker的存储库</span><br><span class="line"># Add Docker&#x27;s official GPG key:</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install ca-certificates curl</span><br><span class="line">sudo install -m 0755 -d /etc/apt/keyrings</span><br><span class="line">sudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc</span><br><span class="line">sudo chmod a+r /etc/apt/keyrings/docker.asc</span><br><span class="line"></span><br><span class="line"># Add the repository to Apt sources:</span><br><span class="line">echo \</span><br><span class="line">  &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \</span><br><span class="line">  $(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;) stable&quot; | \</span><br><span class="line">  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">#安装Docker包</span><br><span class="line">sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line"></span><br><span class="line">#配置docker镜像加速</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://URL.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加阿里云软件源</p>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/mirror/kubernetes">阿里云镜像站安装文档</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#设置kubernetes存储库</span><br><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line"></span><br><span class="line">curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - </span><br><span class="line"></span><br><span class="line"># 排错：</span><br><span class="line"># 执行curl命令报错：curl: (23) Failed writing body</span><br><span class="line"># 解决方案：curl -s -N https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"># 执行命令报错：E: gnupg, gnupg2 and gnupg1 do not seem to be installed, but one of them is required for this operation</span><br><span class="line"># 解决方案：apt-get install -y gnupg2</span><br><span class="line"># 弹出警告：Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).（apt-key已弃用）</span><br><span class="line"># 解决方案：建议无视或者curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo gpg --no-default-keyring --keyring gnupg-ring:/etc/apt/trusted.gpg.d/apt-key.gpg --import</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装kubeadm、kubelet、kubectl</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#安装kubernetes</span><br><span class="line">apt-get update</span><br><span class="line">apt-cache madison kubelet    #查询版本号</span><br><span class="line">apt-get install -y kubelet=1.23.17-00 kubeadm=1.23.17-00 kubectl=1.23.17-00</span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">kubectl version</span><br><span class="line"></span><br><span class="line">#设置开机自启</span><br><span class="line">systemctl enable kubelet.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看docker设备信息</span><br><span class="line">docker info | grep Driver</span><br><span class="line">Cgroup Driver: systemd</span><br><span class="line"></span><br><span class="line"># 如果显示以下信息则需要更改</span><br><span class="line">docker info | grep Driver</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line"></span><br><span class="line"># 配置关闭 Docker 的 cgroups</span><br><span class="line">vim /etc/docker/daemon.json  加入以下内容</span><br><span class="line">&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line"></span><br><span class="line"># 重启 docker</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>部署Kubernetes Master</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#初始化master节点</span><br><span class="line">kubeadm init \</span><br><span class="line">      --apiserver-advertise-address=192.168.122.100 \</span><br><span class="line">      --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">      --kubernetes-version v1.23.17 \</span><br><span class="line">      --service-cidr=10.96.0.0/12 \</span><br><span class="line">      --pod-network-cidr=10.244.0.0/16</span><br><span class="line">      </span><br><span class="line">#安装成功后，复制如下配置并执行</span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
</li>
<li><p>加入Kubernetes Node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#分别在 k8s-node1 和 k8s-node2 执行</span><br><span class="line">kubeadm join 192.168.122.100:6443 --token 47pvys.orya0t0d8fjcqhwj \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:314d290d2734a305e4a7220067f38f34dd0f6cdf349b983f09dba99a7843ce6f</span><br><span class="line">        </span><br><span class="line"># 如果初始化的 token 不小心清空了，可以通过如下命令获取或者重新申请</span><br><span class="line"># 如果 token 已经过期，就重新申请</span><br><span class="line">kubeadm token create</span><br><span class="line"></span><br><span class="line"># token 没有过期可以通过如下命令获取</span><br><span class="line">kubeadm token list</span><br><span class="line"></span><br><span class="line"># 获取 --discovery-token-ca-cert-hash 值，得到值后需要在前面拼接上 sha256:</span><br><span class="line">openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | \</span><br><span class="line">openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>部署CNI网络插件</p>
<p>可选择Flannel、Calico、Canal 和 Weave</p>
<p><a target="_blank" rel="noopener" href="https://github.com/flannel-io/flannel">Flannel官方文档与项目地址</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.tigera.io/">Calico官方文档</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/projectcalico/calico">Calico项目地址</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#在master节点上执行</span><br><span class="line">#下载 calico 配置文件（也可以使用Flannel、Canal和Weave）</span><br><span class="line">curl https://calico-v3-25.netlify.app/archive/v3.25/manifests/calico.yaml -O</span><br><span class="line"></span><br><span class="line"># 修改 calico.yaml 文件中的 CALICO_IPV4POOL_CIDR 配置，修改为与初始化的 cidr 相同（默认注释状态，会使用初始化时指定pod网络状态的配置）</span><br><span class="line"></span><br><span class="line"># Calico默认会拉取docker.io中的镜像，可以删除镜像 docker.io/ 前缀，避免下载过慢导致失败</span><br><span class="line">sed -i &#x27;s#docker.io/##g&#x27; calico.yaml</span><br><span class="line"></span><br><span class="line">#构建Calico网络</span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试Kubernetes集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#创建部署</span><br><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line"></span><br><span class="line">#暴露端口</span><br><span class="line">kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line"></span><br><span class="line">#查看 pod 以及服务信息</span><br><span class="line">kubectl get pod,svc</span><br><span class="line"></span><br><span class="line">#宿主机访问测试</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="1-1-3-二进制安装"><a href="#1-1-3-二进制安装" class="headerlink" title="1.1.3 二进制安装"></a>1.1.3 二进制安装</h3><p>利用 k8s 官方 github 仓库下载二进制包安装，安装过程较复杂，但相对较为稳定，推荐生产环境使用。</p>
<h3 id="1-1-4-命令行工具安装"><a href="#1-1-4-命令行工具安装" class="headerlink" title="1.1.4 命令行工具安装"></a>1.1.4 命令行工具安装</h3><h2 id="1-2-命令行工具kubectl"><a href="#1-2-命令行工具kubectl" class="headerlink" title="1.2 命令行工具kubectl"></a>1.2 命令行工具kubectl</h2><p>Kubernetes 提供 kubectl 是使用 Kubernetes API 与 Kubernetes 集群的<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/glossary/?all=true#term-control-plane">控制面</a>进行通信的命令行工具。</p>
<p>这个工具叫做 kubectl。</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands">更多命令</a></p>
<h3 id="1-2-1-命令自动补全"><a href="#1-2-1-命令自动补全" class="headerlink" title="1.2.1 命令自动补全"></a>1.2.1 命令自动补全</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apt install bash-completion</span><br><span class="line"></span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line"></span><br><span class="line">#所有用户自动补全</span><br><span class="line">kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl &gt; /dev/null</span><br><span class="line"></span><br><span class="line">#当前用户自动补全</span><br><span class="line">echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="1-2-2-在任意节点使用kubectl"><a href="#1-2-2-在任意节点使用kubectl" class="headerlink" title="1.2.2 在任意节点使用kubectl"></a>1.2.2 在任意节点使用kubectl</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 1. 将 master 节点中 /etc/kubernetes/admin.conf 拷贝到需要运行的服务器的 /etc/kubernetes 目录中</span><br><span class="line">scp /etc/kubernetes/admin.conf root@k8s-node1:/etc/kubernetes</span><br><span class="line">scp /etc/kubernetes/admin.conf root@k8s-node2:/etc/kubernetes</span><br><span class="line"></span><br><span class="line"># 2. 在对应的服务器上配置环境变量</span><br><span class="line">echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>

<h3 id="1-2-3-资源操作"><a href="#1-2-3-资源操作" class="headerlink" title="1.2.3 资源操作"></a>1.2.3 资源操作</h3><h4 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f ./my-manifest.yaml           # 创建资源</span><br><span class="line">$ kubectl create -f ./my1.yaml -f ./my2.yaml     # 使用多个文件创建资源</span><br><span class="line">$ kubectl create -f ./dir                        # 使用目录下的所有清单文件来创建资源</span><br><span class="line">$ kubectl create -f https://git.io/xxx         # 使用 url 来创建资源</span><br><span class="line">$ kubectl run nginx --image=nginx                # 启动一个 nginx 实例</span><br><span class="line">$ kubectl explain pods,svc                       # 获取 pod 和 svc 的文档</span><br><span class="line"></span><br><span class="line"># 从 stdin 输入中创建多个 YAML 对象</span><br><span class="line">$ cat &lt;&lt;EOF | kubectl create -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox-sleep</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;1000000&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox-sleep-less</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;1000&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 创建包含几个 key 的 Secret</span><br><span class="line">$ cat &lt;&lt;EOF | kubectl create -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: mysecret</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  password: $(echo &quot;s33msi4&quot; | base64)</span><br><span class="line">  username: $(echo &quot;jane&quot; | base64)</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="显示和查找资源"><a href="#显示和查找资源" class="headerlink" title="显示和查找资源"></a>显示和查找资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># Get commands with basic output</span><br><span class="line">$ kubectl get services                          # 列出所有 namespace 中的所有 service</span><br><span class="line">$ kubectl get pods --all-namespaces             # 列出所有 namespace 中的所有 pod</span><br><span class="line">$ kubectl get pods -o wide                      # 列出所有 pod 并显示详细信息</span><br><span class="line">$ kubectl get deployment my-dep                 # 列出指定 deployment</span><br><span class="line">$ kubectl get pods --include-uninitialized      # 列出该 namespace 中的所有 pod 包括未初始化的</span><br><span class="line"></span><br><span class="line"># 使用详细输出来描述命令</span><br><span class="line">$ kubectl describe nodes my-node</span><br><span class="line">$ kubectl describe pods my-pod</span><br><span class="line"></span><br><span class="line">$ kubectl get services --sort-by=.metadata.name # List Services Sorted by Name</span><br><span class="line"></span><br><span class="line"># 根据重启次数排序列出 pod</span><br><span class="line">$ kubectl get pods --sort-by=&#x27;.status.containerStatuses[0].restartCount&#x27;</span><br><span class="line"></span><br><span class="line"># 获取所有具有 app=cassandra 的 pod 中的 version 标签</span><br><span class="line">$ kubectl get pods --selector=app=cassandra rc -o \</span><br><span class="line">  jsonpath=&#x27;&#123;.items[*].metadata.labels.version&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># 获取所有节点的 ExternalIP</span><br><span class="line">$ kubectl get nodes -o jsonpath=&#x27;&#123;.items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)].address&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># 列出属于某个 PC 的 Pod 的名字</span><br><span class="line"># “jq”命令用于转换复杂的 jsonpath，参考 https://stedolan.github.io/jq/</span><br><span class="line">$ sel=$&#123;$(kubectl get rc my-rc --output=json | jq -j &#x27;.spec.selector | to_entries | .[] | &quot;\(.key)=\(.value),&quot;&#x27;)%?&#125;</span><br><span class="line">$ echo $(kubectl get pods --selector=$sel --output=jsonpath=&#123;.items..metadata.name&#125;)</span><br><span class="line"></span><br><span class="line"># 查看哪些节点已就绪</span><br><span class="line">$ JSONPATH=&#x27;&#123;range .items[*]&#125;&#123;@.metadata.name&#125;:&#123;range @.status.conditions[*]&#125;&#123;@.type&#125;=&#123;@.status&#125;;&#123;end&#125;&#123;end&#125;&#x27; \</span><br><span class="line"> &amp;&amp; kubectl get nodes -o jsonpath=&quot;$JSONPATH&quot; | grep &quot;Ready=True&quot;</span><br><span class="line"></span><br><span class="line"># 列出当前 Pod 中使用的 Secret</span><br><span class="line">$ kubectl get pods -o json | jq &#x27;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&#x27; | grep -v null | sort | uniq</span><br></pre></td></tr></table></figure>

<h4 id="更新资源"><a href="#更新资源" class="headerlink" title="更新资源"></a>更新资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rolling-update frontend-v1 -f frontend-v2.json           # 滚动更新 pod frontend-v1</span><br><span class="line">$ kubectl rolling-update frontend-v1 frontend-v2 --image=image:v2  # 更新资源名称并更新镜像</span><br><span class="line">$ kubectl rolling-update frontend --image=image:v2                 # 更新 frontend pod 中的镜像</span><br><span class="line">$ kubectl rolling-update frontend-v1 frontend-v2 --rollback        # 退出已存在的进行中的滚动更新</span><br><span class="line">$ cat pod.json | kubectl replace -f -                              # 基于 stdin 输入的 JSON 替换 pod</span><br><span class="line"></span><br><span class="line"># 强制替换，删除后重新创建资源。会导致服务中断。</span><br><span class="line">$ kubectl replace --force -f ./pod.json</span><br><span class="line"></span><br><span class="line"># 为 nginx RC 创建服务，启用本地 80 端口连接到容器上的 8000 端口</span><br><span class="line">$ kubectl expose rc nginx --port=80 --target-port=8000</span><br><span class="line"></span><br><span class="line"># 更新单容器 pod 的镜像版本（tag）到 v4</span><br><span class="line">$ kubectl get pod mypod -o yaml | sed &#x27;s/\(image: myimage\):.*$/\1:v4/&#x27; | kubectl replace -f -</span><br><span class="line"></span><br><span class="line">$ kubectl label pods my-pod new-label=awesome                      # 添加标签</span><br><span class="line">$ kubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq       # 添加注解</span><br><span class="line">$ kubectl autoscale deployment foo --min=2 --max=10                # 自动扩展 deployment “foo”</span><br></pre></td></tr></table></figure>

<h4 id="修补资源"><a href="#修补资源" class="headerlink" title="修补资源"></a>修补资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl patch node k8s-node-1 -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;unschedulable&quot;:true&#125;&#125;&#x27; # 部分更新节点</span><br><span class="line"></span><br><span class="line"># 更新容器镜像； spec.containers[*].name 是必须的，因为这是合并的关键字</span><br><span class="line">$ kubectl patch pod valid-pod -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;containers&quot;:[&#123;&quot;name&quot;:&quot;kubernetes-serve-hostname&quot;,&quot;image&quot;:&quot;new image&quot;&#125;]&#125;&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># 使用具有位置数组的 json 补丁更新容器镜像</span><br><span class="line">$ kubectl patch pod valid-pod --type=&#x27;json&#x27; -p=&#x27;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/containers/0/image&quot;, &quot;value&quot;:&quot;new image&quot;&#125;]&#x27;</span><br><span class="line"></span><br><span class="line"># 使用具有位置数组的 json 补丁禁用 deployment 的 livenessProbe</span><br><span class="line">$ kubectl patch deployment valid-deployment  --type json   -p=&#x27;[&#123;&quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/livenessProbe&quot;&#125;]&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="编辑资源"><a href="#编辑资源" class="headerlink" title="编辑资源"></a>编辑资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl edit svc/docker-registry                      # 编辑名为 docker-registry 的 service</span><br><span class="line">$ KUBE_EDITOR=&quot;nano&quot; kubectl edit svc/docker-registry   # 使用其它编辑器</span><br></pre></td></tr></table></figure>

<h4 id="scale资源"><a href="#scale资源" class="headerlink" title="scale资源"></a>scale资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale --replicas=3 rs/foo                                 # Scale a replicaset named &#x27;foo&#x27; to 3</span><br><span class="line">$ kubectl scale --replicas=3 -f foo.yaml                            # Scale a resource specified in &quot;foo.yaml&quot; to 3</span><br><span class="line">$ kubectl scale --current-replicas=2 --replicas=3 deployment/mysql  # If the deployment named mysql&#x27;s current size is 2, scale mysql to 3</span><br><span class="line">$ kubectl scale --replicas=5 rc/foo rc/bar rc/baz                   # Scale multiple replication controllers</span><br></pre></td></tr></table></figure>

<h4 id="删除资源"><a href="#删除资源" class="headerlink" title="删除资源"></a>删除资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale --replicas=3 rs/foo                                 # Scale a replicaset named &#x27;foo&#x27; to 3</span><br><span class="line">$ kubectl scale --replicas=3 -f foo.yaml                            # Scale a resource specified in &quot;foo.yaml&quot; to 3</span><br><span class="line">$ kubectl scale --current-replicas=2 --replicas=3 deployment/mysql  # If the deployment named mysql&#x27;s current size is 2, scale mysql to 3</span><br><span class="line">$ kubectl scale --replicas=5 rc/foo rc/bar rc/baz                   # Scale multiple replication controllers</span><br></pre></td></tr></table></figure>

<h3 id="1-2-4-Pod与集群"><a href="#1-2-4-Pod与集群" class="headerlink" title="1.2.4 Pod与集群"></a>1.2.4 Pod与集群</h3><h4 id="与运行的Pod交互"><a href="#与运行的Pod交互" class="headerlink" title="与运行的Pod交互"></a>与运行的Pod交互</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl logs my-pod                                 # dump 输出 pod 的日志（stdout）</span><br><span class="line">$ kubectl logs my-pod -c my-container                 # dump 输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用）</span><br><span class="line">$ kubectl logs -f my-pod                              # 流式输出 pod 的日志（stdout）</span><br><span class="line">$ kubectl logs -f my-pod -c my-container              # 流式输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用）</span><br><span class="line">$ kubectl run -i --tty busybox --image=busybox -- sh  # 交互式 shell 的方式运行 pod</span><br><span class="line">$ kubectl attach my-pod -i                            # 连接到运行中的容器</span><br><span class="line">$ kubectl port-forward my-pod 5000:6000               # 转发 pod 中的 6000 端口到本地的 5000 端口</span><br><span class="line">$ kubectl exec my-pod -- ls /                         # 在已存在的容器中执行命令（只有一个容器的情况下）</span><br><span class="line">$ kubectl exec my-pod -c my-container -- ls /         # 在已存在的容器中执行命令（pod 中有多个容器的情况下）</span><br><span class="line">$ kubectl top pod POD_NAME --containers               # 显示指定 pod 和容器的指标度量</span><br></pre></td></tr></table></figure>

<h4 id="与节点和集群交互"><a href="#与节点和集群交互" class="headerlink" title="与节点和集群交互"></a>与节点和集群交互</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl cordon my-node                                                # 标记 my-node 不可调度</span><br><span class="line">$ kubectl drain my-node                                                 # 清空 my-node 以待维护</span><br><span class="line">$ kubectl uncordon my-node                                              # 标记 my-node 可调度</span><br><span class="line">$ kubectl top node my-node                                              # 显示 my-node 的指标度量</span><br><span class="line">$ kubectl cluster-info                                                  # 显示 master 和服务的地址</span><br><span class="line">$ kubectl cluster-info dump                                             # 将当前集群状态输出到 stdout                                    </span><br><span class="line">$ kubectl cluster-info dump --output-directory=/path/to/cluster-state   # 将当前集群状态输出到 /path/to/cluster-state</span><br><span class="line"></span><br><span class="line"># 如果该键和影响的污点（taint）已存在，则使用指定的值替换</span><br><span class="line">$ kubectl taint nodes foo dedicated=special-user:NoSchedule</span><br></pre></td></tr></table></figure>

<h3 id="1-2-5-资源类型与别名"><a href="#1-2-5-资源类型与别名" class="headerlink" title="1.2.5 资源类型与别名"></a>1.2.5 资源类型与别名</h3><table>
<thead>
<tr>
<th>资源类型</th>
<th>缩写别名</th>
</tr>
</thead>
<tbody><tr>
<td><code>clusters</code></td>
<td></td>
</tr>
<tr>
<td><code>componentstatuses</code></td>
<td><code>cs</code></td>
</tr>
<tr>
<td><code>configmaps</code></td>
<td><code>cm</code></td>
</tr>
<tr>
<td><code>daemonsets</code></td>
<td><code>ds</code></td>
</tr>
<tr>
<td><code>deployments</code></td>
<td><code>deploy</code></td>
</tr>
<tr>
<td><code>endpoints</code></td>
<td><code>ep</code></td>
</tr>
<tr>
<td><code>event</code></td>
<td><code>ev</code></td>
</tr>
<tr>
<td><code>horizontalpodautoscalers</code></td>
<td><code>hpa</code></td>
</tr>
<tr>
<td><code>ingresses</code></td>
<td><code>ing</code></td>
</tr>
<tr>
<td><code>jobs</code></td>
<td></td>
</tr>
<tr>
<td><code>limitranges</code></td>
<td><code>limits</code></td>
</tr>
<tr>
<td><code>namespaces</code></td>
<td><code>ns</code></td>
</tr>
<tr>
<td><code>networkpolicies</code></td>
<td></td>
</tr>
<tr>
<td><code>nodes</code></td>
<td><code>no</code></td>
</tr>
<tr>
<td><code>statefulsets</code></td>
<td></td>
</tr>
<tr>
<td><code>persistentvolumeclaims</code></td>
<td><code>pvc</code></td>
</tr>
<tr>
<td><code>persistentvolumes</code></td>
<td><code>pv</code></td>
</tr>
<tr>
<td><code>pods</code></td>
<td><code>po</code></td>
</tr>
<tr>
<td><code>podsecuritypolicies</code></td>
<td><code>psp</code></td>
</tr>
<tr>
<td><code>podtemplates</code></td>
<td></td>
</tr>
<tr>
<td><code>replicasets</code></td>
<td><code>rs</code></td>
</tr>
<tr>
<td><code>replicationcontrollers</code></td>
<td><code>rc</code></td>
</tr>
<tr>
<td><code>resourcequotas</code></td>
<td><code>quota</code></td>
</tr>
<tr>
<td><code>cronjob</code></td>
<td></td>
</tr>
<tr>
<td><code>secrets</code></td>
<td></td>
</tr>
<tr>
<td><code>serviceaccount</code></td>
<td><code>sa</code></td>
</tr>
<tr>
<td><code>services</code></td>
<td><code>svc</code></td>
</tr>
<tr>
<td><code>storageclasses</code></td>
<td></td>
</tr>
<tr>
<td><code>thirdpartyresources</code></td>
<td></td>
</tr>
</tbody></table>
<h3 id="1-2-6-格式化输出"><a href="#1-2-6-格式化输出" class="headerlink" title="1.2.6 格式化输出"></a>1.2.6 格式化输出</h3><ul>
<li>输出json格式：-o json</li>
<li>仅打印资源名称：-o name</li>
<li>以纯文本格式输出所有信息：-o wide</li>
<li>输出yaml格式：-o yaml</li>
</ul>
<h2 id="1-3-API概述"><a href="#1-3-API概述" class="headerlink" title="1.3 API概述"></a>1.3 API概述</h2><p>官网文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/using-api/">https://kubernetes.io/zh-cn/docs/reference/using-api/</a></p>
<p>REST API 是 Kubernetes 系统的重要部分，组件之间的所有操作和通信均由 API Server 处理的 REST AP I调用，大多数情况下， API 定义和实现都符合标准的 HTTP REST 格式，可以通过 <a target="_blank" rel="noopener" href="http://docs.kubernetes.org.cn/61.html">kubectl</a> 命令管理工具或其他命令行工具来执行。</p>
<h3 id="1-3-1-类型"><a href="#1-3-1-类型" class="headerlink" title="1.3.1 类型"></a>1.3.1 类型</h3><h4 id="Alpha"><a href="#Alpha" class="headerlink" title="Alpha"></a>Alpha</h4><ul>
<li>包含 alpha 名称的版本（例如v1alpha1）。</li>
<li>该软件可能包含错误。启用一个功能可能会导致 bug。默认情况下，功能可能会被禁用。</li>
<li>随时可能会丢弃对该功能的支持，恕不另行通知。</li>
<li>API 可能在以后的软件版本中以不兼容的方式更改，恕不另行通知。</li>
<li>该软件建议仅在短期测试集群中使用，因为错误的风险增加和缺乏长期支持。</li>
</ul>
<h4 id="Beta"><a href="#Beta" class="headerlink" title="Beta"></a>Beta</h4><ul>
<li>包含 <strong>beta</strong> 名称的版本（例如 <strong>v2beta3</strong> ）。</li>
<li>该软件经过很好的测试。启用功能被认为是安全的。默认情况下功能是开启的。</li>
<li>细节可能会改变，但功能在后续版本不会被删除</li>
<li>对象的模式或语义在随后的 beta 版本或 Stable 版本中可能以不兼容的方式发生变化。如果这种情况发生时，官方会提供迁移操作指南。这可能需要删除、编辑和重新创建API对象。</li>
<li>该版本在后续可能会更改一些不兼容地方，所以建议用于非关键业务，如果你有多个可以独立升级的集群，你也可以放宽此限制。</li>
<li><strong>大家使用过的 Beta 版本后，可以多给社区反馈，如果此版本在后续更新后将不会有太大变化。</strong></li>
</ul>
<h4 id="Stable"><a href="#Stable" class="headerlink" title="Stable"></a>Stable</h4><ul>
<li>该版本名称命名方式：<strong>vX</strong> 这里 <strong>X</strong> 是一个整数。</li>
<li>Stable 版本的功能特性，将出现在后续发布的软件版本中。</li>
</ul>
<h3 id="1-3-2-访问控制"><a href="#1-3-2-访问控制" class="headerlink" title="1.3.2 访问控制"></a>1.3.2 访问控制</h3><h4 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h4><h4 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h4><h3 id="1-3-3-废弃api说明"><a href="#1-3-3-废弃api说明" class="headerlink" title="1.3.3 废弃api说明"></a>1.3.3 废弃api说明</h3><p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/using-api/deprecation-guide/">https://kubernetes.io/zh-cn/docs/reference/using-api/deprecation-guide/</a></p>
<h1 id="二、深入pod"><a href="#二、深入pod" class="headerlink" title="二、深入pod"></a>二、深入pod</h1><h2 id="2-1-Pod配置文件"><a href="#2-1-Pod配置文件" class="headerlink" title="2.1 Pod配置文件"></a>2.1 Pod配置文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1 # api 文档版本</span><br><span class="line">kind: Pod  # 资源对象类型，也可以配置为像Deployment、StatefulSet这一类的对象</span><br><span class="line">metadata: # Pod 相关的元数据，用于描述 Pod 的数据</span><br><span class="line">  name: nginx-demo # Pod 的名称</span><br><span class="line">  labels: # 定义 Pod 的标签</span><br><span class="line">    type: app # 自定义 label 标签，名字为 type，值为 app</span><br><span class="line">    test: 1.0.0 # 自定义 label 标签，描述 Pod 版本号</span><br><span class="line">  namespace: &#x27;default&#x27; # 命名空间的配置</span><br><span class="line">spec: # 期望 Pod 按照这里面的描述进行创建</span><br><span class="line">  containers: # 对于 Pod 中的容器描述</span><br><span class="line">  - name: nginx # 容器的名称</span><br><span class="line">    image: nginx:1.7.9 # 指定容器的镜像</span><br><span class="line">    imagePullPolicy: IfNotPresent # 镜像拉取策略，指定如果本地有就用本地的，如果没有就拉取远程的</span><br><span class="line">    command: # 指定容器启动时执行的命令</span><br><span class="line">    - nginx</span><br><span class="line">    - -g</span><br><span class="line">    - &#x27;daemon off;&#x27; # nginx -g &#x27;daemon off;&#x27;</span><br><span class="line">    workingDir: /usr/share/nginx/html # 定义容器启动后的工作目录</span><br><span class="line">    ports:</span><br><span class="line">    - name: http # 端口名称</span><br><span class="line">      containerPort: 80 # 描述容器内要暴露什么端口</span><br><span class="line">      protocol: TCP # 描述该端口是基于哪种协议通信的</span><br><span class="line">    - env: # 环境变量</span><br><span class="line">      name: JVM_OPTS # 环境变量名称</span><br><span class="line">      value: &#x27;-Xms128m -Xmx128m&#x27; # 环境变量的值</span><br><span class="line">    reousrces:</span><br><span class="line">      requests: # 最少需要多少资源</span><br><span class="line">        cpu: 100m # 限制 cpu 最少使用 0.1 个核心</span><br><span class="line">        memory: 128Mi # 限制内存最少使用 128兆</span><br><span class="line">      limits: # 最多可以用多少资源</span><br><span class="line">        cpu: 200m # 限制 cpu 最多使用 0.2 个核心</span><br><span class="line">        memory: 256Mi # 限制 最多使用 256兆</span><br><span class="line">  restartPolicy: OnFailure # 重启策略，只有失败的情况才会重启</span><br></pre></td></tr></table></figure>

<h2 id="2-2-探针"><a href="#2-2-探针" class="headerlink" title="2.2 探针"></a>2.2 探针</h2><h3 id="2-2-1-类型"><a href="#2-2-1-类型" class="headerlink" title="2.2.1 类型"></a>2.2.1 类型</h3><h4 id="StartupProbe"><a href="#StartupProbe" class="headerlink" title="StartupProbe"></a>StartupProbe</h4><p>k8s 1.16 版本新增的探针，用于判断应用程序是否已经启动了。</p>
<p>当配置了 startupProbe 后，会先禁用其他探针，直到 startupProbe 成功后，其他探针才会继续。</p>
<p>作用：由于有时候不能准确预估应用一定是多长时间启动成功，因此配置另外两种方式不方便配置初始化时长来检测，而配置了 statupProbe 后，只有在应用启动成功了，才会执行另外两种探针，可以更加方便的结合使用另外两种探针使用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">startupProbe: # 应用启动探针配置</span><br><span class="line">  httpGet: # 探测方式，基于 http 请求探测</span><br><span class="line">    path: /api/startup # http请求路径</span><br><span class="line">    port: 80 # 请求端口</span><br></pre></td></tr></table></figure>

<h4 id="LivenessProbe"><a href="#LivenessProbe" class="headerlink" title="LivenessProbe"></a>LivenessProbe</h4><p>用于探测容器中的应用是否运行，如果探测失败，kubelet 会根据配置的重启策略进行重启，若没有配置，默认就认为容器启动成功，不会执行重启策略。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  failureThreshold: 5</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /health</span><br><span class="line">    port: 8080</span><br><span class="line">    scheme: HTTP</span><br><span class="line">  initialDelaySeconds: 60</span><br><span class="line">  periodSeconds: 10</span><br><span class="line">  successThreshold: 1</span><br><span class="line">  timeoutSeconds: 5</span><br></pre></td></tr></table></figure>

<h4 id="ReadinessProbe"><a href="#ReadinessProbe" class="headerlink" title="ReadinessProbe"></a>ReadinessProbe</h4><p>用于探测容器内的程序是否健康，它的返回值如果返回 success，那么就认为该容器已经完全启动，并且该容器是可以接收外部流量的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">readinessProbe:</span><br><span class="line">  failureThreshold: 3 # 失败多少次才算真正失败</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /ready</span><br><span class="line">    port: 8181</span><br><span class="line">    scheme: HTTP</span><br><span class="line">  periodSeconds: 10 # 间隔时间</span><br><span class="line">  successThreshold: 1 # 多少次监测成功算成功</span><br><span class="line">  timeoutSeconds: 1 # 请求的超时时间</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2探测方式"><a href="#2-2-2探测方式" class="headerlink" title="2.2.2探测方式"></a>2.2.2探测方式</h3><h4 id="ExecAction"><a href="#ExecAction" class="headerlink" title="ExecAction"></a>ExecAction</h4><p>在容器内部执行一个命令，如果返回值为 0，则任务容器时健康的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  exec:</span><br><span class="line">    command:</span><br><span class="line">      - cat</span><br><span class="line">      - /health</span><br></pre></td></tr></table></figure>

<h4 id="TCPSocketAction"><a href="#TCPSocketAction" class="headerlink" title="TCPSocketAction"></a>TCPSocketAction</h4><p>通过 tcp 连接监测容器内端口是否开放，如果开放则证明该容器健康</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  tcpSocket:</span><br><span class="line">    port: 80</span><br></pre></td></tr></table></figure>

<h4 id="HTTPGetAction"><a href="#HTTPGetAction" class="headerlink" title="HTTPGetAction"></a>HTTPGetAction</h4><p>生产环境用的较多的方式，发送 HTTP 请求到容器内的应用程序，如果接口返回的状态码在 200~400 之间，则认为容器健康。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  failureThreshold: 5</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /health</span><br><span class="line">    port: 8080</span><br><span class="line">    scheme: HTTP</span><br><span class="line">    httpHeaders:</span><br><span class="line">      - name: xxx</span><br><span class="line">        value: xxx</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-参数配置"><a href="#2-2-3-参数配置" class="headerlink" title="2.2.3 参数配置"></a>2.2.3 参数配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">initialDelaySeconds: 60 # 初始化时间</span><br><span class="line">timeoutSeconds: 2 # 超时时间</span><br><span class="line">periodSeconds: 5 # 监测间隔时间</span><br><span class="line">successThreshold: 1 # 检查 1 次成功就表示成功</span><br><span class="line">failureThreshold: 2 # 监测失败 2 次就表示失败</span><br></pre></td></tr></table></figure>

<h2 id="2-3-生命周期"><a href="#2-3-生命周期" class="headerlink" title="2.3 生命周期"></a>2.3 生命周期</h2><p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_pods_life_cycle.png" alt="pod的生命周期"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">lifecycle:</span><br><span class="line">  postStart: # 容创建完成后执行的动作，不能保证该操作一定在容器的 command 之前执行，一般不使用</span><br><span class="line">    exec: # 可以是 exec / httpGet / tcpSocket</span><br><span class="line">      command:</span><br><span class="line">        - sh</span><br><span class="line">        - -c</span><br><span class="line">        - &#x27;mkdir /data&#x27;</span><br><span class="line">  preStop: # 在容器停止前执行的动作</span><br><span class="line">    httpGet: # 发送一个 http 请求</span><br><span class="line">      path: /</span><br><span class="line">      port: 80</span><br><span class="line">    exec: # 执行一个命令</span><br><span class="line">      command:</span><br><span class="line">        - sh</span><br><span class="line">        - -c</span><br><span class="line">        - sleep 9</span><br></pre></td></tr></table></figure>

<h3 id="2-3-1-Pod退出流程"><a href="#2-3-1-Pod退出流程" class="headerlink" title="2.3.1 Pod退出流程"></a>2.3.1 Pod退出流程</h3><h4 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h4><ol>
<li><p>Endpoint删除pod的ip地址</p>
</li>
<li><p>Pod变成Terminating状态</p>
<p>变为删除中的状态后，会给 pod 一个宽限期，让 pod 去执行一些清理或销毁操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">配置参数：</span><br><span class="line"></span><br><span class="line"># 作用与 pod 中的所有容器</span><br><span class="line">terminationGracePeriodSeconds: 30</span><br><span class="line">containers:</span><br><span class="line">  - xxx</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行perStop的指令</p>
</li>
</ol>
<h3 id="2-3-2-PreStop的应用"><a href="#2-3-2-PreStop的应用" class="headerlink" title="2.3.2 PreStop的应用"></a>2.3.2 PreStop的应用</h3><p>如果应用销毁操作耗时需要比较长，可以在 preStop 按照如下方式进行配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">preStop:</span><br><span class="line">  exec:</span><br><span class="line">    command:</span><br><span class="line">      - sh</span><br><span class="line">      - -c</span><br><span class="line">      - &#x27;sleep 20; kill pgrep java&#x27;</span><br></pre></td></tr></table></figure>

<p>但是需要注意，由于 k8s 默认给 pod 的停止宽限时间为 30s，如果我们停止操作会超过 30s 时，不要光设置 sleep 50，还要将 terminationGracePeriodSeconds: 30 也更新成更长的时间，否则 k8s 最多只会在这个时间的基础上再宽限几秒，不会真正等待 50s</p>
<p><strong>注册中心下线</strong></p>
<p><strong>数据清理</strong></p>
<p><strong>数据销毁</strong></p>
<h1 id="三、资源调度"><a href="#三、资源调度" class="headerlink" title="三、资源调度"></a>三、资源调度</h1><h2 id="3-1-Label和Slelctor"><a href="#3-1-Label和Slelctor" class="headerlink" title="3.1 Label和Slelctor"></a>3.1 Label和Slelctor</h2><h3 id="3-1-1-标签（Label）"><a href="#3-1-1-标签（Label）" class="headerlink" title="3.1.1 标签（Label）"></a>3.1.1 标签（Label）</h3><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>在各类资源的 <code>metadata.labels</code> 中进行配置</p>
<h4 id="kubectl"><a href="#kubectl" class="headerlink" title="kubectl"></a>kubectl</h4><p>临时创建label：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label po &lt;资源名称&gt; app=hello -n namespace</span><br></pre></td></tr></table></figure>

<p>修改已经存在的标签：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label po &lt;资源名称&gt; app=hello2 --overwrite</span><br></pre></td></tr></table></figure>

<p>查看label：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># selector 按照 label 单值查找节点</span><br><span class="line">kubectl get po -A -l app=hello</span><br><span class="line"></span><br><span class="line"># 查看所有节点的 labels</span><br><span class="line">kubectl get po --show-labels</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-选择器（Selector）"><a href="#3-1-2-选择器（Selector）" class="headerlink" title="3.1.2 选择器（Selector）"></a>3.1.2 选择器（Selector）</h3><h4 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h4><p>在各对象的配置 <code>spec.selector</code> 或其他可以写 <code>selector</code> 的属性中编写</p>
<h4 id="kubectl-1"><a href="#kubectl-1" class="headerlink" title="kubectl"></a>kubectl</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 匹配单个值，查找 app=hello 的 pod</span><br><span class="line">kubectl get po -A -l app=hello</span><br><span class="line"></span><br><span class="line"># 匹配多个值</span><br><span class="line">kubectl get po -A -l &#x27;k8s-app in (metrics-server, kubernetes-dashboard)&#x27;</span><br><span class="line">或 </span><br><span class="line"></span><br><span class="line"># 查找 version!=1 and app=nginx 的 pod 信息</span><br><span class="line">kubectl get po -l version!=1,app=nginx</span><br><span class="line"></span><br><span class="line"># 不等值 + 语句</span><br><span class="line">kubectl get po -A -l version!=1,&#x27;app in (busybox, nginx)&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-Deployment"><a href="#3-2-Deployment" class="headerlink" title="3.2 Deployment"></a>3.2 Deployment</h2><h3 id="3-2-1-功能"><a href="#3-2-1-功能" class="headerlink" title="3.2.1 功能"></a>3.2.1 功能</h3><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">创建一个 deployment</span><br><span class="line">kubectl create deploy nginx-deploy --image=nginx:1.7.9</span><br><span class="line"></span><br><span class="line">或执行</span><br><span class="line">kubectl create -f xxx.yaml --record</span><br><span class="line">--record 会在 annotation 中记录当前命令创建或升级了资源，后续可以查看做过哪些变动操作。</span><br><span class="line"></span><br><span class="line">将创建的 deployment 以 yaml 的格式输出</span><br><span class="line">kubectl get deploy nginx-deploy -o yaml</span><br><span class="line"></span><br><span class="line">查看部署信息</span><br><span class="line">kubectl get deployments</span><br><span class="line"></span><br><span class="line">查看 rs</span><br><span class="line">kubectl get rs</span><br><span class="line"></span><br><span class="line">查看 pod 以及展示标签，可以看到是关联的那个 rs</span><br><span class="line">kubectl get pods --show-labels</span><br></pre></td></tr></table></figure>

<h4 id="滚动更新"><a href="#滚动更新" class="headerlink" title="滚动更新"></a>滚动更新</h4><p>只有修改了 deployment 配置文件中的 template 中的属性后，才会触发更新操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">修改 nginx 版本号</span><br><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line"></span><br><span class="line">或者通过 kubectl edit deployment/nginx-deployment 进行修改</span><br><span class="line"></span><br><span class="line">查看滚动更新的过程</span><br><span class="line">kubectl rollout status deploy &lt;deployment_name&gt;</span><br><span class="line"></span><br><span class="line">查看部署描述，最后展示发生的事件列表也可以看到滚动更新过程</span><br><span class="line">kubectl describe deploy &lt;deployment_name&gt;</span><br><span class="line"></span><br><span class="line">通过 kubectl get deployments 获取部署信息，UP-TO-DATE 表示已经有多少副本达到了配置中要求的数目</span><br><span class="line"></span><br><span class="line">通过 kubectl get rs 可以看到增加了一个新的 rs</span><br><span class="line"></span><br><span class="line">通过 kubectl get pods 可以看到所有 pod 关联的 rs 变成了新的</span><br></pre></td></tr></table></figure>

<p><strong>多个滚动更新并行</strong></p>
<p>假设当前有 5 个 nginx:1.7.9 版本，你想将版本更新为 1.9.1，当更新成功第三个以后，你马上又将期望更新的版本改为 1.9.2，那么此时会立马删除之前的三个，并且立马开启更新 1.9.2 的任务</p>
<h4 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h4><p>有时候你可能想回退一个Deployment，例如，当Deployment不稳定时，比如一直crash looping。</p>
<p>默认情况下，kubernetes会在系统中保存前两次的Deployment的rollout历史记录，以便你可以随时会退（你可以修改revision history limit来更改保存的revision数）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">案例：</span><br><span class="line">更新 deployment 时参数不小心写错，如 nginx:1.9.1 写成了 nginx:1.91</span><br><span class="line">kubectl set image deployment/nginx-deploy nginx=nginx:1.91</span><br><span class="line"></span><br><span class="line">监控滚动升级状态，由于镜像名称错误，下载镜像失败，因此更新过程会卡住</span><br><span class="line">kubectl rollout status deployments nginx-deploy</span><br><span class="line"></span><br><span class="line">结束监听后，获取 rs 信息，我们可以看到新增的 rs 副本数是 2 个</span><br><span class="line">kubectl get rs</span><br><span class="line"></span><br><span class="line">通过 kubectl get pods 获取 pods 信息，我们可以看到关联到新的 rs 的 pod，状态处于 ImagePullBackOff 状态</span><br><span class="line"></span><br><span class="line">为了修复这个问题，我们需要找到需要回退的 revision 进行回退</span><br><span class="line">通过 kubectl rollout history deployment/nginx-deploy 可以获取 revison 的列表</span><br><span class="line"></span><br><span class="line">通过 kubectl rollout history deployment/nginx-deploy --revision=2 可以查看详细信息</span><br><span class="line"></span><br><span class="line">确认要回退的版本后，可以通过 kubectl rollout undo deployment/nginx-deploy 可以回退到上一个版本</span><br><span class="line"></span><br><span class="line">也可以回退到指定的 revision</span><br><span class="line">kubectl rollout undo deployment/nginx-deploy --to-revision=2</span><br><span class="line"></span><br><span class="line">再次通过 kubectl get deployment 和 kubectl describe deployment 可以看到，我们的版本已经回退到对应的 revison 上了</span><br><span class="line"></span><br><span class="line">可以通过设置 .spec.revisonHistoryLimit 来指定 deployment 保留多少 revison，如果设置为 0，则不允许 deployment 回退了。</span><br></pre></td></tr></table></figure>

<h4 id="扩容缩容"><a href="#扩容缩容" class="headerlink" title="扩容缩容"></a>扩容缩容</h4><p>通过 kube scale 命令可以进行自动扩容&#x2F;缩容，以及通过 kube edit 编辑 replcas 也可以实现扩容&#x2F;缩容</p>
<p>扩容与缩容只是直接创建副本数，没有更新 pod template 因此不会创建新的 rs</p>
<h4 id="暂停与恢复"><a href="#暂停与恢复" class="headerlink" title="暂停与恢复"></a>暂停与恢复</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">由于每次对 pod template 中的信息发生修改后，都会触发更新 deployment 操作，那么此时如果频繁修改信息，就会产生多次更新，而实际上只需要执行最后一次更新即可，当出现此类情况时我们就可以暂停 deployment 的 rollout</span><br><span class="line"></span><br><span class="line">通过 kubectl rollout pause deployment &lt;name&gt; 就可以实现暂停，直到你下次恢复后才会继续进行滚动更新</span><br><span class="line"></span><br><span class="line">尝试对容器进行修改，然后查看是否发生更新操作了</span><br><span class="line">kubectl set image deploy &lt;name&gt; nginx=nginx:1.17.9</span><br><span class="line">kubectl get po </span><br><span class="line"></span><br><span class="line">通过以上操作可以看到实际并没有发生修改，此时我们再次进行修改一些属性，如限制 nginx 容器的最大cpu为 0.2 核，最大内存为 128M，最小内存为 64M，最小 cpu 为 0.1 核</span><br><span class="line">kubectl set resources deploy &lt;deploy_name&gt; -c &lt;container_name&gt; --limits=cpu=200m,memory=128Mi --requests=cpu100m,memory=64Mi</span><br><span class="line"></span><br><span class="line">通过格式化输出 kubectl get deploy &lt;name&gt; -oyaml，可以看到配置确实发生了修改，再通过 kubectl get po 可以看到 pod 没有被更新</span><br><span class="line"></span><br><span class="line">那么此时我们再恢复 rollout，通过命令 kubectl rollout deploy &lt;name&gt;</span><br><span class="line"></span><br><span class="line">恢复后，我们再次查看 rs 和 po 信息，我们可以看到就开始进行滚动更新操作了</span><br><span class="line">kubectl get rs</span><br><span class="line">kubectl get po</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-配置文件"><a href="#3-2-2-配置文件" class="headerlink" title="3.2.2 配置文件"></a>3.2.2 配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1 # deployment api 版本</span><br><span class="line">kind: Deployment # 资源类型为 deployment</span><br><span class="line">metadata: # 元信息</span><br><span class="line">  labels: # 标签</span><br><span class="line">    app: nginx-deploy # 具体的 key: value 配置形式</span><br><span class="line">  name: nginx-deploy # deployment 的名字</span><br><span class="line">  namespace: default # 所在的命名空间</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1 # 期望副本数</span><br><span class="line">  revisionHistoryLimit: 10 # 进行滚动更新后，保留的历史版本数</span><br><span class="line">  selector: # 选择器，用于找到匹配的 RS</span><br><span class="line">    matchLabels: # 按照标签匹配</span><br><span class="line">      app: nginx-deploy # 匹配的标签key/value</span><br><span class="line">  strategy: # 更新策略</span><br><span class="line">    rollingUpdate: # 滚动更新配置</span><br><span class="line">      maxSurge: 25% # 进行滚动更新时，更新的个数最多可以超过期望副本数的个数/比例</span><br><span class="line">      maxUnavailable: 25% # 进行滚动更新时，最大不可用比例更新比例，表示在所有副本数中，最多可以有多少个不更新成功</span><br><span class="line">    type: RollingUpdate # 更新类型，采用滚动更新</span><br><span class="line">  template: # pod 模板</span><br><span class="line">    metadata: # pod 的元信息</span><br><span class="line">      labels: # pod 的标签</span><br><span class="line">        app: nginx-deploy</span><br><span class="line">    spec: # pod 期望信息</span><br><span class="line">      containers: # pod 的容器</span><br><span class="line">      - image: nginx:1.7.9 # 镜像</span><br><span class="line">        imagePullPolicy: IfNotPresent # 拉取策略</span><br><span class="line">        name: nginx # 容器名称</span><br><span class="line">      restartPolicy: Always # 重启策略</span><br><span class="line">      terminationGracePeriodSeconds: 30 # 删除操作最多宽限多长时间</span><br></pre></td></tr></table></figure>

<h2 id="3-3-StatefulSet"><a href="#3-3-StatefulSet" class="headerlink" title="3.3 StatefulSet"></a>3.3 StatefulSet</h2><h3 id="3-3-1-功能"><a href="#3-3-1-功能" class="headerlink" title="3.3.1 功能"></a>3.3.1 功能</h3><h4 id="创建-1"><a href="#创建-1" class="headerlink" title="创建"></a>创建</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f web.yaml</span><br><span class="line"></span><br><span class="line"># 查看 service 和 statefulset =&gt; sts</span><br><span class="line">kubectl get service nginx</span><br><span class="line">kubectl get statefulset web</span><br><span class="line"></span><br><span class="line"># 查看 PVC 信息</span><br><span class="line">kubectl get pvc</span><br><span class="line"></span><br><span class="line"># 查看创建的 pod，这些 pod 是有序的</span><br><span class="line">kubectl get pods -l app=nginx</span><br><span class="line"></span><br><span class="line"># 查看这些 pod 的 dns</span><br><span class="line"># 运行一个 pod，基础镜像为 busybox 工具包，利用里面的 nslookup 可以看到 dns 信息</span><br><span class="line">kubectl run -i --tty --image busybox dns-test --restart=Never --rm /bin/sh</span><br><span class="line">nslookup web-0.nginx</span><br></pre></td></tr></table></figure>

<h4 id="扩容缩容-1"><a href="#扩容缩容-1" class="headerlink" title="扩容缩容"></a>扩容缩容</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 扩容缩容</span><br><span class="line">$ kubectl scale statefulset web --replicas=5</span><br><span class="line"></span><br><span class="line"># 扩容缩容</span><br><span class="line">$ kubectl patch statefulset web -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;replicas&quot;:3&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="镜像更新"><a href="#镜像更新" class="headerlink" title="镜像更新"></a>镜像更新</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 镜像更新（目前还不支持直接更新 image，需要 patch 来间接实现）</span><br><span class="line"></span><br><span class="line">kubectl patch sts web --type=&#x27;json&#x27; -p=&#x27;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;nginx:1.9.1&quot;&#125;]&#x27;</span><br></pre></td></tr></table></figure>

<h5 id="RollingUpdate"><a href="#RollingUpdate" class="headerlink" title="RollingUpdate"></a>RollingUpdate</h5><p>StatefulSet 也可以采用滚动更新策略，同样是修改 pod template 属性后会触发更新，但是由于 pod 是有序的，在 StatefulSet 中更新时是基于 pod 的顺序倒序更新的</p>
<h6 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h6><p>利用滚动更新中的 partition 属性，可以实现简易的灰度发布的效果</p>
<p>例如我们有 5 个 pod，如果当前 partition 设置为 3，那么此时滚动更新时，只会更新那些 序号 &gt;&#x3D; 3 的 pod</p>
<p>利用该机制，我们可以通过控制 partition 的值，来决定只更新其中一部分 pod，确认没有问题后再主键增大更新的 pod 数量，最终实现全部 pod 更新</p>
<h5 id="OnDelete"><a href="#OnDelete" class="headerlink" title="OnDelete"></a>OnDelete</h5><p>只有在 pod 被删除时会进行更新操作</p>
<h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 删除 StatefulSet 和 Headless Service</span><br><span class="line"># 级联删除：删除 statefulset 时会同时删除 pods</span><br><span class="line">kubectl delete statefulset web</span><br><span class="line"># 非级联删除：删除 statefulset 时不会删除 pods，删除 sts 后，pods 就没人管了，此时再删除 pod 不会重建的</span><br><span class="line">kubectl deelte sts web --cascade=false</span><br><span class="line"># 删除 service</span><br><span class="line">kubectl delete service nginx</span><br></pre></td></tr></table></figure>

<h4 id="删除pvc"><a href="#删除pvc" class="headerlink" title="删除pvc"></a>删除pvc</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># StatefulSet删除后PVC还会保留着，数据不再使用的话也需要删除</span><br><span class="line">$ kubectl delete pvc www-web-0 www-web-1</span><br></pre></td></tr></table></figure>

<h3 id="3-3-2-配置文件"><a href="#3-3-2-配置文件" class="headerlink" title="3.3.2 配置文件"></a>3.3.2 配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    name: web</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet # StatefulSet 类型的资源</span><br><span class="line">metadata:</span><br><span class="line">  name: web # StatefulSet 对象的名字</span><br><span class="line">spec:</span><br><span class="line">  serviceName: &quot;nginx&quot; # 使用哪个 service 来管理 dns</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector：</span><br><span class="line">    matchLabels：</span><br><span class="line">      app：nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports: # 容器内部要暴露的端口</span><br><span class="line">        - containerPort: 80 # 具体暴露的端口号</span><br><span class="line">          name: web # 该端口配置的名字</span><br><span class="line">        volumeMounts: # 加载数据卷</span><br><span class="line">        - name: www # 指定加载哪个数据卷</span><br><span class="line">          mountPath: /usr/share/nginx/html # 加载到容器的哪个目录</span><br><span class="line">  volumeClaimTemplates: # 数据卷模板</span><br><span class="line">  - metadata: # 数据卷描述</span><br><span class="line">      name: www # 数据卷的名称</span><br><span class="line">      annotations: # 数据卷的注解</span><br><span class="line">        volume.alpha.kubernetes.io/storage-class: anything</span><br><span class="line">    spec: # 数据卷的规约</span><br><span class="line">      accessModes: [ &quot;ReadWriteOnce&quot; ] # 访问模式</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: 1Gi</span><br></pre></td></tr></table></figure>

<h2 id="3-4-DaemonSet"><a href="#3-4-DaemonSet" class="headerlink" title="3.4 DaemonSet"></a>3.4 DaemonSet</h2><h3 id="3-4-1-配置文件"><a href="#3-4-1-配置文件" class="headerlink" title="3.4.1 配置文件"></a>3.4.1 配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet # 创建DaemonSet 资源</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd # 名字</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: logging</span><br><span class="line">        id: fluentd</span><br><span class="line">      name: fluentd</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: fluentd-es</span><br><span class="line">        image: agilestacks/fluentd-elasticsearch:v1.3.0</span><br><span class="line">        env: # 环境变量的key</span><br><span class="line">         - name: FLUENTD_ARGS # 环境变量的 key</span><br><span class="line">           value: -qq # 环境变量的value</span><br><span class="line">        volumeMounts: #加载数据卷，避免数据丢失</span><br><span class="line">         - name: containers #数据卷的名字</span><br><span class="line">           mountPath: /var/lib/docker/containers # 将数据卷挂载到容器内的哪个目录</span><br><span class="line">         - name: varlog</span><br><span class="line">           mountPath: /varlog</span><br><span class="line">      volumes: # 定义数据卷</span><br><span class="line">         - hostPath: #数据卷类型，主机路径的模式，也就是与node共享目录</span><br><span class="line">             path: /var/lib/docker/containers # node中的共享目录</span><br><span class="line">           name: containers 定义的数据卷的名称</span><br><span class="line">         - hostPath:</span><br><span class="line">             path: /var/log</span><br><span class="line">           name: varlog</span><br></pre></td></tr></table></figure>

<h3 id="3-4-2-指定Node节点"><a href="#3-4-2-指定Node节点" class="headerlink" title="3.4.2 指定Node节点"></a>3.4.2 指定Node节点</h3><p>DaemonSet 会忽略 Node 的 unschedulable 状态，有两种方式来指定 Pod 只运行在指定的 Node 节点上：</p>
<ul>
<li><p>nodeSelector：只调度到匹配指定 label 的 Node 上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">先为 Node 打上标签</span><br><span class="line">kubectl label nodes k8s-node1 svc_type=microsvc</span><br><span class="line"></span><br><span class="line">然后再 daemonset 配置中设置 nodeSelector</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        svc_type: microsvc</span><br></pre></td></tr></table></figure>
</li>
<li><p>nodeAffinity：功能更丰富的 Node 选择器，比如支持集合操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">nodeAffinity 目前支持两种：requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution，分别代表必须满足条件和优选条件。</span><br><span class="line"></span><br><span class="line">比如下面的例子代表调度到包含标签 wolfcode.cn/framework-name 并且值为 spring 或 springboot 的 Node 上，并且优选还带有标签 another-node-label-key=another-node-label-value 的Node。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-node-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    nodeAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        nodeSelectorTerms:</span><br><span class="line">        - matchExpressions:</span><br><span class="line">          - key: wolfcode.cn/framework-name</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - spring</span><br><span class="line">            - springboot</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - weight: 1</span><br><span class="line">        preference:</span><br><span class="line">          matchExpressions:</span><br><span class="line">          - key: another-node-label-key</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - another-node-label-value</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-node-affinity</span><br><span class="line">    image: pauseyyf/pause</span><br></pre></td></tr></table></figure>
</li>
<li><p>podAffinity：调度到满足条件的 Pod 所在的 Node 上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">podAffinity 基于 Pod 的标签来选择 Node，仅调度到满足条件Pod 所在的 Node 上，支持 podAffinity 和 podAntiAffinity。这个功能比较绕，以下面的例子为例：</span><br><span class="line">    如果一个 “Node 所在空间中包含至少一个带有 auth=oauth2 标签且运行中的 Pod”，那么可以调度到该 Node</span><br><span class="line">    不调度到 “包含至少一个带有 auth=jwt 标签且运行中 Pod”的 Node 上</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-pod-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    podAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - labelSelector:</span><br><span class="line">          matchExpressions:</span><br><span class="line">          - key: auth</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - oauth2</span><br><span class="line">        topologyKey: failure-domain.beta.kubernetes.io/zone</span><br><span class="line">    podAntiAffinity:</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - weight: 100</span><br><span class="line">        podAffinityTerm:</span><br><span class="line">          labelSelector:</span><br><span class="line">            matchExpressions:</span><br><span class="line">            - key: auth</span><br><span class="line">              operator: In</span><br><span class="line">              values:</span><br><span class="line">              - jwt</span><br><span class="line">          topologyKey: kubernetes.io/hostname</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-pod-affinity</span><br><span class="line">    image: pauseyyf/pause</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-4-3-滚动更新"><a href="#3-4-3-滚动更新" class="headerlink" title="3.4.3 滚动更新"></a>3.4.3 滚动更新</h3><p>不建议使用 RollingUpdate，建议使用 OnDelete 模式，这样避免频繁更新 ds</p>
<h2 id="3-5-HPA自动扩-缩容"><a href="#3-5-HPA自动扩-缩容" class="headerlink" title="3.5 HPA自动扩&#x2F;缩容"></a>3.5 HPA自动扩&#x2F;缩容</h2><p>通过观察 pod 的 cpu、内存使用率或自定义 metrics 指标进行自动的扩容或缩容 pod 的数量。</p>
<p>通常用于 Deployment，不适用于无法扩&#x2F;缩容的对象，如 DaemonSet</p>
<p>控制管理器每隔30s（可以通过–horizontal-pod-autoscaler-sync-period修改）查询metrics的资源使用情况</p>
<h3 id="3-5-1-开启指标服务"><a href="#3-5-1-开启指标服务" class="headerlink" title="3.5.1 开启指标服务"></a>3.5.1 开启指标服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 下载 metrics-server 组件配置文件</span><br><span class="line">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml -O metrics-server-components.yaml</span><br><span class="line"></span><br><span class="line"># 修改镜像地址为国内的地址</span><br><span class="line">sed -i &#x27;s/k8s.gcr.io\/metrics-server/registry.cn-hangzhou.aliyuncs.com\/google_containers/g&#x27; metrics-server-components.yaml</span><br><span class="line"></span><br><span class="line"># 修改容器的 tls 配置，不验证 tls，在 containers 的 args 参数中增加 --kubelet-insecure-tls 参数</span><br><span class="line"></span><br><span class="line"># 安装组件</span><br><span class="line">kubectl apply -f metrics-server-components.yaml</span><br><span class="line"></span><br><span class="line"># 查看 pod 状态</span><br><span class="line">kubectl get pods --all-namespaces | grep metrics</span><br></pre></td></tr></table></figure>

<h3 id="3-5-2-cpu、内存指标监控"><a href="#3-5-2-cpu、内存指标监控" class="headerlink" title="3.5.2 cpu、内存指标监控"></a>3.5.2 cpu、内存指标监控</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">实现 cpu 或内存的监控，首先有个前提条件是该对象必须配置了 resources.requests.cpu 或 resources.requests.memory 才可以，可以配置当 cpu/memory 达到上述配置的百分比后进行扩容或缩容</span><br><span class="line"></span><br><span class="line">创建一个 HPA：</span><br><span class="line">先准备一个好一个有做资源限制的 deployment</span><br><span class="line">执行命令 kubectl autoscale deploy nginx-deploy --cpu-percent=20 --min=2 --max=5</span><br><span class="line">通过 kubectl get hpa 可以获取 HPA 信息</span><br><span class="line"></span><br><span class="line">测试：找到对应服务的 service，编写循环测试脚本提升内存与 cpu 负载</span><br><span class="line">while true; do wget -q -O- http://&lt;ip:port&gt; &gt; /dev/null ; done</span><br><span class="line"></span><br><span class="line">可以通过多台机器执行上述命令，增加负载，当超过负载后可以查看 pods 的扩容情况 kubectl get pods</span><br><span class="line"></span><br><span class="line">查看 pods 资源使用情况</span><br><span class="line">kubectl top pods</span><br><span class="line"></span><br><span class="line">扩容测试完成后，再关闭循环执行的指令，让 cpu 占用率降下来，然后过 5 分钟后查看自动缩容情况</span><br></pre></td></tr></table></figure>

<h3 id="3-5-3-自定义metrics"><a href="#3-5-3-自定义metrics" class="headerlink" title="3.5.3 自定义metrics"></a>3.5.3 自定义metrics</h3><ul>
<li>控制管理器开启–horizontal-pod-autoscaler-use-rest-clients</li>
<li>控制管理器的–apiserver指向<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kube-aggregator">API Server Aggregator</a></li>
<li>在API Server Aggregator中注册自定义的metrics API</li>
</ul>
<h1 id="四、服务发布"><a href="#四、服务发布" class="headerlink" title="四、服务发布"></a>四、服务发布</h1><h2 id="4-1-Service"><a href="#4-1-Service" class="headerlink" title="4.1 Service"></a>4.1 Service</h2><p>负责东西流量（同层级&#x2F;内部服务网络通信）的通信</p>
<h3 id="4-1-1-Service的定义"><a href="#4-1-1-Service的定义" class="headerlink" title="4.1.1 Service的定义"></a>4.1.1 Service的定义</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-svc</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-svc</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort # NodePort可外部通过节点IP访问，ClusterIP仅内部访问</span><br><span class="line">  ports:</span><br><span class="line">  - name: http # service 端口配置的名称</span><br><span class="line">    protocol: TCP # 端口绑定的协议，支持 TCP、UDP、SCTP，默认为 TCP</span><br><span class="line">    port: 80 # service 自己的端口</span><br><span class="line">    targetPort: 9527 # 目标 pod 的端口</span><br><span class="line">    nodePort: 31000 # type为NodePort时可配置，不指定会在30000-32767里随机一个端口</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 443</span><br><span class="line">  selector: # 选中当前 service 匹配哪些 pod，对哪些 pod 的东西流量进行代理</span><br><span class="line">    app: nginx</span><br></pre></td></tr></table></figure>

<h4 id="命令操作"><a href="#命令操作" class="headerlink" title="命令操作"></a>命令操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 创建 service</span><br><span class="line">kubectl create -f nginx-svc.yaml</span><br><span class="line"></span><br><span class="line"># 查看 service 信息，通过 service 的 cluster ip 进行访问</span><br><span class="line">kubectl get svc </span><br><span class="line"></span><br><span class="line"># 查看 pod 信息，通过 pod 的 ip 进行访问</span><br><span class="line">kubectl get po -o wide</span><br><span class="line"></span><br><span class="line"># 创建其他 pod 通过 service name 进行访问（推荐）</span><br><span class="line">kubectl exec -it busybox -- sh</span><br><span class="line">curl http://nginx-svc</span><br><span class="line"></span><br><span class="line"># 默认在当前 namespace 中访问，如果需要跨 namespace 访问 pod，则在 service name 后面加上 .&lt;namespace&gt; 即可</span><br><span class="line">curl http://nginx-svc.default</span><br></pre></td></tr></table></figure>

<h4 id="Endpoint"><a href="#Endpoint" class="headerlink" title="Endpoint"></a>Endpoint</h4><h3 id="4-1-2代理k8s外部服务"><a href="#4-1-2代理k8s外部服务" class="headerlink" title="4.1.2代理k8s外部服务"></a>4.1.2代理k8s外部服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">实现方式：</span><br><span class="line">编写 service 配置文件时，不指定 selector 属性</span><br><span class="line">自己创建 endpoint</span><br><span class="line">endpoint 配置：</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-svc-external # 与 service 一致</span><br><span class="line">  name: nginx-svc-external # 与 service 一致</span><br><span class="line">  namespace: default # 与 service 一致</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: &lt;target ip&gt; # 目标 ip 地址</span><br><span class="line">  ports: # 与 service 一致</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br></pre></td></tr></table></figure>

<ul>
<li>各环境访问名称统一</li>
<li>访问k8s集群外的其他服务</li>
<li>项目迁移</li>
</ul>
<h3 id="4-1-3反向代理外部域名"><a href="#4-1-3反向代理外部域名" class="headerlink" title="4.1.3反向代理外部域名"></a>4.1.3反向代理外部域名</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: wolfcode-external-domain</span><br><span class="line">  name: wolfcode-external-domain</span><br><span class="line">spec:</span><br><span class="line">  type: ExternalName</span><br><span class="line">  externalName: www.wolfcode.cn</span><br></pre></td></tr></table></figure>

<h3 id="4-1-4-常用类型"><a href="#4-1-4-常用类型" class="headerlink" title="4.1.4 常用类型"></a>4.1.4 常用类型</h3><h4 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h4><p>只能在集群内部使用，不配置类型的话默认就是 ClusterIP</p>
<h4 id="ExternalName"><a href="#ExternalName" class="headerlink" title="ExternalName"></a>ExternalName</h4><p>返回定义的 CNAME 别名，可以配置为域名</p>
<h4 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h4><p>会在所有安装了 kube-proxy 的节点都绑定一个端口，此端口可以代理至对应的 Pod，集群外部可以使用任意节点 ip + NodePort 的端口号访问到集群中对应 Pod 中的服务。</p>
<p>当类型设置为 NodePort 后，可以在 ports 配置中增加 nodePort 配置指定端口，需要在下方的端口范围内，如果不指定会随机指定端口</p>
<p>端口范围：30000~32767</p>
<p>端口范围配置在 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service 文件中</p>
<h4 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h4><p>使用云服务商（阿里云、腾讯云等）提供的负载均衡器服务</p>
<h2 id="4-2-Ingress"><a href="#4-2-Ingress" class="headerlink" title="4.2 Ingress"></a>4.2 Ingress</h2><p>Ingress 大家可以理解为也是一种 LB 的抽象，它的实现也是支持 nginx、haproxy 等负载均衡服务的</p>
<h3 id="4-2-1-安装ingress-nginx"><a href="#4-2-1-安装ingress-nginx" class="headerlink" title="4.2.1 安装ingress-nginx"></a>4.2.1 安装ingress-nginx</h3><p><a target="_blank" rel="noopener" href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm">https://kubernetes.github.io/ingress-nginx/deploy/#using-helm</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.添加ingress-nginx官方helm仓库</span><br><span class="line">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx</span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line">2.查找所有的版本</span><br><span class="line">helm search repo ingress-nginx/ingress-nginx -l</span><br><span class="line"></span><br><span class="line">3.下载</span><br><span class="line">helm fetch ingress-nginx/ingress-nginx --version 4.5.2</span><br><span class="line"></span><br><span class="line">4.解压缩</span><br><span class="line">tar zxvf ingress-nginx-4.5.2.tgz</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">进入ingress-nginx目录修改values.yaml参数配置</span><br><span class="line"></span><br><span class="line">1.修改dnsPolicy的值为ClusterFirstWithHostNet</span><br><span class="line">    # By default, while using host network, name resolution uses the host&#x27;s DNS. If you wish nginx-controller</span><br><span class="line">    # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.</span><br><span class="line">    #dnsPolicy: ClusterFirst</span><br><span class="line">    dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">    </span><br><span class="line">2.修改hostNetwork的值为true</span><br><span class="line">    # -- Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),</span><br><span class="line">    # since CNI and hostport don&#x27;t mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920</span><br><span class="line">    # is merged</span><br><span class="line">    #hostNetwork: false</span><br><span class="line">    hostNetwork: true</span><br><span class="line">    </span><br><span class="line">3.修改kind的值为DaemonSet</span><br><span class="line">    # -- Use a `DaemonSet` or `Deployment`</span><br><span class="line">    #kind: Deployment</span><br><span class="line">    kind: DaemonSet</span><br><span class="line">    </span><br><span class="line">4.在nodeSelector下添加ingress: &quot;true&quot;  # 增加选择器，如果 node 上有 ingress=true 就部署</span><br><span class="line">    nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">        ingress: &quot;true&quot;</span><br><span class="line">        </span><br><span class="line">5.修改type的值为ClusterIP  # 将 service 中的 type 由 LoadBalancer 修改为 ClusterIP，如果服务器是云平台才用 LoadBalancer</span><br><span class="line">        ## Ref: https://kubernetes.io/docs/concepts/services-networking/dual-stack/</span><br><span class="line">        ipFamilies:</span><br><span class="line">            - IPv4</span><br><span class="line">        ports:</span><br><span class="line">            http: 80</span><br><span class="line">            https: 443</span><br><span class="line">        targetPorts:</span><br><span class="line">            http: http</span><br><span class="line">            https: https</span><br><span class="line">        #type: LoadBalancer</span><br><span class="line">        type: ClusterIP</span><br><span class="line">        </span><br><span class="line">6.修改enabled的值为false</span><br><span class="line">        ## Additional annotations to the admission webhooks.</span><br><span class="line">        ## These annotations will be added to the ValidatingWebhookConfiguration and</span><br><span class="line">        ## the Jobs Spec of the admission webhooks.</span><br><span class="line">        #enabled: true</span><br><span class="line">        enabled: false</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">给node打标签</span><br><span class="line">kubectl label nodes k8s-node1 ingress=true</span><br><span class="line"></span><br><span class="line">新建命令空间</span><br><span class="line">kubectl create namespace ingress-nginx</span><br><span class="line"></span><br><span class="line">安装ingress-nginx</span><br><span class="line">cd ingress-nginx/</span><br><span class="line">helm install ingress-nginx -n ingress-nginx .</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-基本使用"><a href="#4-2-2-基本使用" class="headerlink" title="4.2.2 基本使用"></a>4.2.2 基本使用</h3><h4 id="创建一个ingress"><a href="#创建一个ingress" class="headerlink" title="创建一个ingress"></a>创建一个ingress</h4><p>文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/">https://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress # 资源类型为 Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-test</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: &quot;nginx&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class="line">spec:</span><br><span class="line">  rules: # ingress 规则配置，可以配置多个</span><br><span class="line">  - host: www.xiaoyu.com # 域名配置，可以使用通配符 *</span><br><span class="line">    http:</span><br><span class="line">      paths: # 相当于 nginx 的 location 配置，可以配置多个</span><br><span class="line">      - pathType: Prefix # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service: </span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port: </span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /api # 等价于 nginx 中的 location 的路径前缀匹配</span><br></pre></td></tr></table></figure>

<h4 id="多域名配置"><a href="#多域名配置" class="headerlink" title="多域名配置"></a>多域名配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress # 资源类型为 Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-test</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: &quot;nginx&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class="line">spec:</span><br><span class="line">  rules: # ingress 规则配置，可以配置多个</span><br><span class="line">  - host: www.xiaoyu.com # 域名配置，可以使用通配符 *</span><br><span class="line">    http:</span><br><span class="line">      paths: # 相当于 nginx 的 location 配置，可以配置多个</span><br><span class="line">      - pathType: Prefix # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service: </span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port: </span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /api # 等价于 nginx 中的 location 的路径前缀匹配</span><br><span class="line">      - pathType: Exec # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配&gt;，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port:</span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /</span><br><span class="line">  - host: api.xiaoyu.com # 域名配置，可以使用通配符 *</span><br><span class="line">    http:</span><br><span class="line">      paths: # 相当于 nginx 的 location 配置，可以配置多个</span><br><span class="line">      - pathType: Prefix # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配&gt;，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port:</span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /</span><br></pre></td></tr></table></figure>

<h1 id="五、配置与存储"><a href="#五、配置与存储" class="headerlink" title="五、配置与存储"></a>五、配置与存储</h1><h2 id="5-1-配置管理"><a href="#5-1-配置管理" class="headerlink" title="5.1 配置管理"></a>5.1 配置管理</h2><h3 id="5-1-1-ConfigMap"><a href="#5-1-1-ConfigMap" class="headerlink" title="5.1.1 ConfigMap"></a>5.1.1 ConfigMap</h3><p><strong>创建</strong></p>
<p>使用 <code>kubectl create configmap -h</code> 查看示例，构建 configmap 对象</p>
<p><strong>使用ConfigMap</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">创建configmap：</span><br><span class="line">vim db.properties</span><br><span class="line">username=root</span><br><span class="line">password=admin</span><br><span class="line"></span><br><span class="line">vim redis.properties</span><br><span class="line">host: 127.0.0.1</span><br><span class="line">port: 6379</span><br><span class="line"></span><br><span class="line">kubectl create cm test-dir-config --from-file=./</span><br><span class="line"></span><br><span class="line">kubectl create configmap test-env-config --from-literal=JAVA_OPTS_TEST=&#x27;-Xms512m -Xmx512m&#x27; --from-literal=APP_NAME=&#x27;springboot-env-test&#x27;</span><br><span class="line"></span><br><span class="line">编写配置文件：</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-cm-pod</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: Never</span><br><span class="line">  containers:</span><br><span class="line">  - name: env-test</span><br><span class="line">    image: alpine</span><br><span class="line">    command: [&quot;bin/sh&quot;,&quot;-c&quot;,&quot;env;sleep 3600&quot;]</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    env:</span><br><span class="line">    - name: JAVA_VM_OPTS</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config # configMap的名字</span><br><span class="line">          key: JAVA_OPTS_TEST # 表示从 name 的 configMap 中获取名字为 key 的 value，将其赋值给本地环境变量 JAVA_OPTS_TEST</span><br><span class="line">    - name: APP</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config</span><br><span class="line">          key: APP_NAME</span><br><span class="line">    volumMounts: # 加载数据卷</span><br><span class="line">    - name: db-config # 表示加载volumes 属性中哪个数据卷</span><br><span class="line">      mountPath: &quot;/usr/local/mysql/conf&quot; # 想要将数据卷中的文件加载到哪个目录下</span><br><span class="line">      readOnly: true # 是否只读</span><br><span class="line">  volumes: # 数据卷挂载 configMap、secret</span><br><span class="line">  - name: db-config # 数据卷的名字，随意设置</span><br><span class="line">    configMap: # 数据卷类型为configMap</span><br><span class="line">      name: test-dir-config # configMap的名字，必须跟想要加载的configMap 相同</span><br><span class="line">      items: #对 configMap 中的 key 进行映射，如果不指定，默认会将 configMap中所有 key 全部转换为一个个同名的文件</span><br><span class="line">      - key: &quot;db.properties&quot; # configMap中的key</span><br><span class="line">        path: &quot;db.properties&quot; # 将该 key 的值转换为文件         </span><br><span class="line">          </span><br><span class="line">创建pod：</span><br><span class="line">kubectl create -f test-cm-pod.yaml</span><br><span class="line"></span><br><span class="line">测试查看打印的环境变量中是否有JAVA_VM_OPTS和APP：</span><br><span class="line">kubectl logs -f test-cm-pod</span><br><span class="line"></span><br><span class="line">测试查看/usr/local/mysql/conf下是否有db.properties文件</span><br><span class="line">kubectl exec -it test-cm-pod -- sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2-加密数据配置Secret"><a href="#5-1-2-加密数据配置Secret" class="headerlink" title="5.1.2 加密数据配置Secret"></a>5.1.2 加密数据配置Secret</h3><p>与 ConfigMap 类似，用于存储配置信息，但是主要用于存储敏感信息、需要加密的信息，Secret 可以提供数据加密、解密功能。</p>
<p>在创建 Secret 时，要注意如果要加密的字符中，包含了有特殊字符，需要使用转义符转移，例如 $ 转移后为 $，也可以对特殊字符使用单引号描述，这样就不需要转移例如 1$289*-! 转换为 ‘1$289*-!’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret -h</span><br><span class="line">kubectl create secret docker-registry -h</span><br><span class="line">kubectl create secret docker-registry sec-test --docker-username=admin --docker-password=test --docker-email=test@test.com</span><br><span class="line"></span><br><span class="line">编写配置文件</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-image-pull-pod</span><br><span class="line">spec:</span><br><span class="line">  imagePullSecrets: # 配置登录docker registry的secret</span><br><span class="line">  name: test-secret</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: 192.168.112.110:8858/test/nginx:latest</span><br><span class="line">    command: [&quot;bin/sh&quot;,&quot;-c&quot;,&quot;env;sleep 3600&quot;]</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    env:</span><br><span class="line">    - name: JAVA_VM_OPTS</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config # configMap的名字</span><br><span class="line">          key: JAVA_OPTS_TEST # 表示从 name 的 configMap 中获取名字为 key 的 value，将其赋值给本地环境变量 JAVA_OPTS_TEST</span><br><span class="line">    - name: APP</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config</span><br><span class="line">          key: APP_NAME</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="5-1-3-SubPath的使用"><a href="#5-1-3-SubPath的使用" class="headerlink" title="5.1.3 SubPath的使用"></a>5.1.3 SubPath的使用</h3><p>使用 ConfigMap 或 Secret 挂载到目录的时候，会将容器中源目录给覆盖掉，此时我们可能只想覆盖目录中的某一个文件，但是这样的操作会覆盖整个文件，因此需要使用到 SubPath</p>
<p>配置方式：</p>
<ol>
<li>定义 volumes 时需要增加 items 属性，配置 key 和 path，且 path 的值不能从 &#x2F; 开始</li>
<li>在容器内的 volumeMounts 中增加 subPath 属性，该值与 volumes 中 items.path 的值相同</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl create configmap nginx-conf-cm --from-file=./nginx.conf</span><br><span class="line"></span><br><span class="line">containers:</span><br><span class="line">  ......</span><br><span class="line">  volumeMounts: # 挂载数据卷</span><br><span class="line">  - mountPath: &#x27;/etc/nginx&#x27; # 挂载的路径</span><br><span class="line">    name: nginx-conf # 使用哪个 configmap 或 secret</span><br><span class="line">    subPath: etc/nginx/nginx.conf # 与 volumes.[0].items.path 相同</span><br><span class="line">volumes:</span><br><span class="line">- name: nginx-conf # 数据卷的名称</span><br><span class="line">  configMap: #数据卷类型为configmap</span><br><span class="line">    name: nginx-conf-cm # configMap 名字</span><br><span class="line">    items: # subPath 配置，要将configmap中的哪些数据挂载进来</span><br><span class="line">      key: nginx.conf # 指定要挂载哪个key</span><br><span class="line">      path: nginx.conf # 挂载后该key重命名为什么名字</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4-配置的热更新"><a href="#5-1-4-配置的热更新" class="headerlink" title="5.1.4 配置的热更新"></a>5.1.4 配置的热更新</h3><p>我们通常会将项目的配置文件作为 configmap 然后挂载到 pod，那么如果更新 configmap 中的配置，会不会更新到 pod 中呢？</p>
<p>这得分成几种情况：<br>默认方式：会更新，更新周期是更新时间 + 缓存时间<br>subPath：不会更新<br>变量形式：如果 pod 中的一个变量是从 configmap 或 secret 中得到，同样也是不会更新的</p>
<p>对于 subPath 的方式，我们可以取消 subPath 的使用，将配置文件挂载到一个不存在的目录，避免目录的覆盖，然后再利用软连接的形式，将该文件链接到目标位置</p>
<p>但是如果目标位置原本就有文件，可能无法创建软链接，此时可以基于前面讲过的 postStart 操作执行删除命令，将默认的吻技安删除即可</p>
<h4 id="5-1-4-1-通过edit命令直接修改configmap"><a href="#5-1-4-1-通过edit命令直接修改configmap" class="headerlink" title="5.1.4.1 通过edit命令直接修改configmap"></a>5.1.4.1 通过edit命令直接修改configmap</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit cm test-dir-config</span><br></pre></td></tr></table></figure>

<h4 id="5-1-4-2-通过replace替换"><a href="#5-1-4-2-通过replace替换" class="headerlink" title="5.1.4.2 通过replace替换"></a>5.1.4.2 通过replace替换</h4><p>由于 configmap 我们创建通常都是基于文件创建，并不会编写 yaml 配置文件，因此修改时我们也是直接修改配置文件，而 replace 是没有 <code>--from-file</code> 参数的，因此无法实现基于源配置文件的替换，此时我们可以利用下方的命令实现</p>
<p># 该命令的重点在于 <code>--dry-run</code> 参数，该参数的意思打印 yaml 文件，但不会将该文件发送给 apiserver，再结合 -oyaml 输出 yaml 文件就可以得到一个配置好但是没有发给 apiserver 的文件，然后再结合 replace 监听控制台输出得到 yaml 数据即可实现替换</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create cm --from-file=nginx.conf --dry-run -oaml | kubectl replace -f-</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5-不可变的Secret和ConfigMap"><a href="#5-1-5-不可变的Secret和ConfigMap" class="headerlink" title="5.1.5 不可变的Secret和ConfigMap"></a>5.1.5 不可变的Secret和ConfigMap</h3><p>对于一些敏感服务的配置文件，在线上有时是不允许修改的，此时在配置 configmap 时可以设置 <code> immutable: true</code>来禁止修改</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">...</span><br><span class="line">immutable: true</span><br></pre></td></tr></table></figure>

<h2 id="5-2-持久化存储"><a href="#5-2-持久化存储" class="headerlink" title="5.2 持久化存储"></a>5.2 持久化存储</h2><h3 id="5-2-1-Volumes"><a href="#5-2-1-Volumes" class="headerlink" title="5.2.1 Volumes"></a>5.2.1 Volumes</h3><h4 id="Hostpath"><a href="#Hostpath" class="headerlink" title="Hostpath"></a>Hostpath</h4><p>将节点上的文件或目录挂载到 Pod 上，此时该目录会变成持久化存储目录，即使 Pod 被删除后重启，也可以重新加载到该目录，该目录下的文件不会丢失</p>
<h5 id="配置文件-2"><a href="#配置文件-2" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-volume-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-volume</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd # 挂载到容器的哪个目录</span><br><span class="line">      name: test-volume # 挂载哪个 volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    hostPath: # 与主机共享目录，加载主机中的指定目录到容器中</span><br><span class="line">      path: /data # 节点中的目录</span><br><span class="line">      type: Directory # 检查类型，在挂载前对挂载目录做什么检查操作，有多种选项，默认为空字符串，不做任何检查</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">类型：</span><br><span class="line">空字符串：默认类型，不做任何检查</span><br><span class="line">DirectoryOrCreate：如果给定的 path 不存在，就创建一个 755 的空目录</span><br><span class="line">Directory：这个目录必须存在</span><br><span class="line">FileOrCreate：如果给定的文件不存在，则创建一个空文件，权限为 644</span><br><span class="line">File：这个文件必须存在</span><br><span class="line">Socket：UNIX 套接字，必须存在</span><br><span class="line">CharDevice：字符设备，必须存在</span><br><span class="line">BlockDevice：块设备，必须存在</span><br></pre></td></tr></table></figure>

<h4 id="EmptyDir"><a href="#EmptyDir" class="headerlink" title="EmptyDir"></a>EmptyDir</h4><p>EmptyDir 主要用于一个 Pod 中不同的 Container 共享数据使用的，由于只是在 Pod 内部使用，因此与其他 volume 比较大的区别是，当 Pod 如果被删除了，那么 emptyDir 也会被删除。</p>
<p>存储介质可以是任意类型，如 SSD、磁盘或网络存储。可以将 emptyDir.medium 设置为 Memory 让 k8s 使用 tmpfs（内存支持文件系统），速度比较快，但是重启 tmpfs 节点时，数据会被清除，且设置的大小会计入到 Container 的内存限制中。</p>
<h5 id="配置文件-3"><a href="#配置文件-3" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: empty-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-emptydir1</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /cache</span><br><span class="line">      name: cache-volume</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-emptydir2</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /share</span><br><span class="line">      name: cache-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: cache-volume</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">    </span><br><span class="line">测试</span><br><span class="line">kubectl exec -it empty-test-pod -c nginx-emptydir1 -- sh</span><br></pre></td></tr></table></figure>

<h3 id="5-2-2-NFS挂载"><a href="#5-2-2-NFS挂载" class="headerlink" title="5.2.2 NFS挂载"></a>5.2.2 NFS挂载</h3><p>nfs 卷能将 NFS (网络文件系统) 挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，nfs 卷的内容在删除 Pod 时会被保存，卷只是被卸载。 这意味着 nfs 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。</p>
<h4 id="安装nfs"><a href="#安装nfs" class="headerlink" title="安装nfs"></a>安装nfs</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 安装 nfs</span><br><span class="line">apt-get install nfs-common nfs-kernel-server -y</span><br><span class="line">#yum install nfs-utils -y</span><br><span class="line"></span><br><span class="line"># 创建共享目录</span><br><span class="line">mkdir -p /data/nfs</span><br><span class="line">cd /data/nfs</span><br><span class="line">mkdir rw</span><br><span class="line">mkdir ro</span><br><span class="line"></span><br><span class="line"># 设置共享目录 export</span><br><span class="line">vim /etc/exports</span><br><span class="line">/data/nfs/rw 192.168.122.0/24(insecure,rw,sync,no_subtree_check,no_root_squash)</span><br><span class="line">/data/nfs/ro 192.168.122.0/24(insecure,ro,sync,no_subtree_check,no_root_squash)</span><br><span class="line"></span><br><span class="line"># 启动 nfs</span><br><span class="line">systemctl start nfs-kernel-server.service</span><br><span class="line">#systemctl start nfs-server</span><br><span class="line"></span><br><span class="line"># 查看 nfs 版本</span><br><span class="line">cat /proc/fs/nfsd/versions</span><br><span class="line"></span><br><span class="line"># 到其他测试节点安装 nfs-utils 并加载测试</span><br><span class="line">mkdir -p /mnt/nfs/rw</span><br><span class="line">mount -t nfs 192.168.122.120:/data/nfs/rw /mnt/nfs/rw</span><br></pre></td></tr></table></figure>

<h4 id="配置文件-4"><a href="#配置文件-4" class="headerlink" title="配置文件"></a>配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nfs-test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /data</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    nfs:</span><br><span class="line">      server: 192.168.122.120 # 网络存储服务地址</span><br><span class="line">      path: /data/nfs/rw # 网络存储路径</span><br><span class="line">      readOnly: false # 是否只读</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">测试在其他node节点创建文件并在pod中查看</span><br></pre></td></tr></table></figure>

<h3 id="5-2-3-PV与PVC"><a href="#5-2-3-PV与PVC" class="headerlink" title="5.2.3 PV与PVC"></a>5.2.3 PV与PVC</h3><p><strong>持久卷（PersistentVolume，PV）</strong> 是集群中的一块存储，可以由管理员事先制备， 或者使用<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/">存储类（Storage Class）</a>来动态制备。 持久卷是集群资源，就像节点也是集群资源一样。PV 持久卷和普通的 Volume 一样， 也是使用卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 此 API 对象中记述了存储的实现细节，无论其背后是 NFS、iSCSI 还是特定于云平台的存储系统。</p>
<p><strong>持久卷申领（PersistentVolumeClaim，PVC）</strong> 表达的是用户对存储的请求。概念上与 Pod 类似。 Pod 会耗用节点资源，而 PVC 申领会耗用 PV 资源。Pod 可以请求特定数量的资源（CPU 和内存）；同样 PVC 申领也可以请求特定的大小和访问模式 （例如，可以要求 PV 卷能够以 ReadWriteOnce、ReadOnlyMany 或 ReadWriteMany 模式之一来挂载，参见<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#access-modes">访问模式</a>）。</p>
<h4 id="5-2-3-1-生命周期"><a href="#5-2-3-1-生命周期" class="headerlink" title="5.2.3.1 生命周期"></a>5.2.3.1 生命周期</h4><h5 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h5><h6 id="静态构建"><a href="#静态构建" class="headerlink" title="静态构建"></a>静态构建</h6><p>集群管理员创建若干 PV 卷。这些卷对象带有真实存储的细节信息， 并且对集群用户可用（可见）。PV 卷对象存在于 Kubernetes API 中，可供用户消费（使用）。</p>
<h6 id="动态构建"><a href="#动态构建" class="headerlink" title="动态构建"></a>动态构建</h6><p>如果集群中已经有的 PV 无法满足 PVC 的需求，那么集群会根据 PVC 自动构建一个 PV，该操作是通过 StorageClass 实现的。</p>
<p>想要实现这个操作，前提是 PVC 必须设置 StorageClass，否则会无法动态构建该 PV，可以通过启用 DefaultStorageClass 来实现 PV 的构建。</p>
<h5 id="绑定"><a href="#绑定" class="headerlink" title="绑定"></a>绑定</h5><p>当用户创建一个 PVC 对象后，主节点会监测新的 PVC 对象，并且寻找与之匹配的 PV 卷，找到 PV 卷后将二者绑定在一起。</p>
<p>如果找不到对应的 PV，则需要看 PVC 是否设置 StorageClass 来决定是否动态创建 PV，若没有配置，PVC 就会一致处于未绑定状态，直到有与之匹配的 PV 后才会申领绑定关系。</p>
<h5 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h5><p>Pod 将 PVC 当作存储卷来使用，集群会通过 PVC 找到绑定的 PV，并为 Pod 挂载该卷。</p>
<p>Pod 一旦使用 PVC 绑定 PV 后，为了保护数据，避免数据丢失问题，PV 对象会受到保护，在系统中无法被删除。</p>
<h5 id="回收策略"><a href="#回收策略" class="headerlink" title="回收策略"></a>回收策略</h5><p>当用户不再使用其存储卷时，他们可以从 API 中将 PVC 对象删除， 从而允许该资源被回收再利用。PersistentVolume 对象的回收策略告诉集群， 当其被从申领中释放时如何处理该数据卷。 目前，数据卷可以被 Retained（保留）、Recycled（回收）或 Deleted（删除）。</p>
<h6 id="保留（Retain）"><a href="#保留（Retain）" class="headerlink" title="保留（Retain）"></a>保留（Retain）</h6><p>回收策略 Retain 使得用户可以手动回收资源。当 PersistentVolumeClaim 对象被删除时，PersistentVolume 卷仍然存在，对应的数据卷被视为”已释放（released）”。 由于卷上仍然存在这前一申领人的数据，该卷还不能用于其他申领。 管理员可以通过下面的步骤来手动回收该卷：</p>
<ol>
<li>删除 PersistentVolume 对象。与之相关的、位于外部基础设施中的存储资产 （例如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）在 PV 删除之后仍然存在。</li>
<li>根据情况，手动清除所关联的存储资产上的数据。</li>
<li>手动删除所关联的存储资产。</li>
</ol>
<p>如果你希望重用该存储资产，可以基于存储资产的定义创建新的 PersistentVolume 卷对象。</p>
<h6 id="删除（Delete）"><a href="#删除（Delete）" class="headerlink" title="删除（Delete）"></a>删除（Delete）</h6><p>对于支持 Delete 回收策略的卷插件，删除动作会将 PersistentVolume 对象从 Kubernetes 中移除，同时也会从外部基础设施（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）中移除所关联的存储资产。 动态制备的卷会继承<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#reclaim-policy">其 StorageClass 中设置的回收策略</a>， 该策略默认为 Delete。管理员需要根据用户的期望来配置 StorageClass； 否则 PV 卷被创建之后必须要被编辑或者修补。</p>
<h6 id="回收（Recycle）"><a href="#回收（Recycle）" class="headerlink" title="回收（Recycle）"></a>回收（Recycle）</h6><p><strong>警告：</strong> 回收策略 Recycle 已被废弃。取而代之的建议方案是使用动态制备。</p>
<p>如果下层的卷插件支持，回收策略 Recycle 会在卷上执行一些基本的擦除 （rm -rf &#x2F;thevolume&#x2F;*）操作，之后允许该卷用于新的 PVC 申领。</p>
<h4 id="5-2-3-2-PV"><a href="#5-2-3-2-PV" class="headerlink" title="5.2.3.2 PV"></a>5.2.3.2 PV</h4><h5 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h5><p><strong>Available：</strong> 空闲，未被绑定</p>
<p><strong>Bound：</strong> 已经被PVC绑定</p>
<p><strong>Released：</strong> PVC被删除，资源已回收，但是PV未被重新使用</p>
<p><strong>Failed：</strong> 自动回收失败</p>
<h5 id="配置文件-5"><a href="#配置文件-5" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0001</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi # pv 的容量</span><br><span class="line">  volumeMode: Filesystem # 存储类型为文件系统</span><br><span class="line">  accessModes: # 访问模式：ReadWriteOnce、ReadWriteMany、ReadOnlyMany</span><br><span class="line">    - ReadWriteOnce # 可被单节点独写</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle # 回收策略</span><br><span class="line">  storageClassName: slow # 创建 PV 的存储类名，需要与 pvc 的相同</span><br><span class="line">  mountOptions: # 加载配置</span><br><span class="line">    - hard</span><br><span class="line">    - nfsvers=4.1</span><br><span class="line">  nfs: # 连接到 nfs</span><br><span class="line">    path: /data/nfs/rw/test-pv # 存储路径</span><br><span class="line">    server: 192.168.113.121 # nfs 服务地址</span><br></pre></td></tr></table></figure>

<h4 id="5-2-3-3-PVC"><a href="#5-2-3-3-PVC" class="headerlink" title="5.2.3.3 PVC"></a>5.2.3.3 PVC</h4><h5 id="Pod绑定PVC"><a href="#Pod绑定PVC" class="headerlink" title="Pod绑定PVC"></a>Pod绑定PVC</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">在 pod 的挂载容器配置中，增加 pvc 挂载</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pvc-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-volume</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pod</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: nfs-pvc # pvc 的名称</span><br></pre></td></tr></table></figure>

<h5 id="配置文件-6"><a href="#配置文件-6" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce # 权限需要与对应的 pv 相同</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi # 资源可以小于 pv 的，但是不能大于，如果大于就会匹配不到 pv</span><br><span class="line">  storageClassName: slow # 名字需要与对应的 pv 相同</span><br><span class="line">#  selector: # 使用选择器选择对应的 pv</span><br><span class="line">#    matchLabels:</span><br><span class="line">#      release: &quot;stable&quot;</span><br><span class="line">#    matchExpressions:</span><br><span class="line">#      - &#123;key: environment, operator: In, values: [dev]&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-2-3-4-StorageClass"><a href="#5-2-3-4-StorageClass" class="headerlink" title="5.2.3.4 StorageClass"></a>5.2.3.4 StorageClass</h4><h5 id="制备器（Provisioner）"><a href="#制备器（Provisioner）" class="headerlink" title="制备器（Provisioner）"></a>制备器（Provisioner）</h5><p>每个 StorageClass 都有一个制备器（Provisioner），用来决定使用哪个卷插件制备 PV。</p>
<h5 id="NFS动态制备案例"><a href="#NFS动态制备案例" class="headerlink" title="NFS动态制备案例"></a>NFS动态制备案例</h5><p>参考文档1：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/storage/storage-classes/">https://kubernetes.io/docs/concepts/storage/storage-classes/</a></p>
<p>参考文档2：<a target="_blank" rel="noopener" href="https://github.com/kubernetes-csi/csi-driver-nfs#readme">https://github.com/kubernetes-csi/csi-driver-nfs#readme</a></p>
<p>使用helm安装特定版本csi-driver-nfs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add csi-driver-nfs https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts</span><br><span class="line">helm install csi-driver-nfs csi-driver-nfs/csi-driver-nfs --namespace kube-system --version v4.7.0</span><br></pre></td></tr></table></figure>

<p>创建storage class</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-csi</span><br><span class="line">provisioner: nfs.csi.k8s.io</span><br><span class="line">parameters:</span><br><span class="line">  server: 192.168.122.120    # 改为自己的 nfs server</span><br><span class="line">  share: /data/nfs/rw    # 改为自己的nfs 共享路径</span><br><span class="line">  # csi.storage.k8s.io/provisioner-secret is only needed for providing mountOptions in DeleteVolume</span><br><span class="line">  # csi.storage.k8s.io/provisioner-secret-name: &quot;mount-options&quot;</span><br><span class="line">  # csi.storage.k8s.io/provisioner-secret-namespace: &quot;default&quot;</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">volumeBindingMode: Immediate</span><br><span class="line">mountOptions:</span><br><span class="line">  - nfsvers=4.1</span><br></pre></td></tr></table></figure>

<p>创建PVC</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/deploy/example/pvc-nfs-csi-dynamic.yaml</span><br><span class="line"></span><br><span class="line"># pvc-nfs-csi-dynamic.yaml文件内容：</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-nfs-dynamic</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 10Gi</span><br><span class="line">  storageClassName: nfs-csi</span><br></pre></td></tr></table></figure>

<p>动态PVC测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-pv-test-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 300Mi</span><br><span class="line">  storageClassName: nfs-csi</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pvc</span><br><span class="line">kubectl get pv</span><br><span class="line">ls /data/nfs/rw</span><br></pre></td></tr></table></figure>



<p><strong>注：以下部分由于quay.io&#x2F;external_storage&#x2F;nfs-client-provisioner:latest镜像截至2024&#x2F;5&#x2F;8已有6年未更新，新版docker已不支持该版镜像；其他镜像源经过测试也无法使用故删除</strong></p>
<h5 id="NFS动态制备案例-1"><a href="#NFS动态制备案例-1" class="headerlink" title="NFS动态制备案例"></a><del>NFS动态制备案例</del></h5><h6 id="nfs-provisioner"><a href="#nfs-provisioner" class="headerlink" title="nfs-provisioner"></a><del>nfs-provisioner</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app: nfs-client-provisioner</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-client-provisioner</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          #image: quay.io/external_storage/nfs-client-provisioner:latest # 原镜像，被墙，无法直接访问</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: 192.168.122.120</span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /data/nfs/rw</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: 192.168.122.120</span><br><span class="line">            path: /data/nfs/rw</span><br></pre></td></tr></table></figure>

<h6 id="StorageClass配置"><a href="#StorageClass配置" class="headerlink" title="StorageClass配置"></a><del>StorageClass配置</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">  namespace: kube-system</span><br><span class="line">provisioner: fuseim.pri/ifs # 外部制备器提供者，编写为提供者的名称</span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: &quot;false&quot; # 是否存档，false 表示不存档，会删除 oldPath 下面的数据，true 表示存档，会重命名路径</span><br><span class="line">reclaimPolicy: Retain # 回收策略，默认为 Delete 可以配置为 Retain</span><br><span class="line">volumeBindingMode: Immediate # 默认为 Immediate，表示创建 PVC 立即进行绑定，只有 azuredisk 和 AWSelasticblockstore 支持其他值</span><br></pre></td></tr></table></figure>

<h6 id="RBAC配置"><a href="#RBAC配置" class="headerlink" title="RBAC配置"></a><del>RBAC配置</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: run-nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">创建rbac</span><br><span class="line">kubectl apply -f rbac.yaml</span><br><span class="line"></span><br><span class="line">创建deployment</span><br><span class="line">kubectl apply -f deployment.yaml</span><br><span class="line"></span><br><span class="line">创建storage class</span><br><span class="line">kubectl apply -f storageclass.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="PVC处于Pending状态"><a href="#PVC处于Pending状态" class="headerlink" title="PVC处于Pending状态"></a><del>PVC处于Pending状态</del></h6><p><del>在 k8s 1.20 之后，出于对性能和统一 apiserver 调用方式的初衷，移除了对 SelfLink 的支持，而默认上面指定的 provisioner 版本需要 SelfLink 功能，因此 PVC 无法进行自动制备。</del></p>
<ul>
<li><p><del>配置SelfLink</del></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">修改 apiserver 配置文件</span><br><span class="line">vim /etc/kubernetes/manifests/kube-apiserver.yaml</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - --feature-gates=RemoveSelfLink=false # 新增该行</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">修改后重新应用该配置</span><br><span class="line">kubectl apply -f /etc/kubernetes/manifests/kube-apiserver.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p><del>不需要SelfLink的provisioner</del></p>
<p><del>将 provisioner 修改为如下镜像之一即可</del></p>
<p><del><a target="_blank" rel="noopener" href="http://gcr.io/k8s-staging-sig-storage/nfs-subdir-external-provisioner:v4.0.0">gcr.io&#x2F;k8s-staging-sig-storage&#x2F;nfs-subdir-external-provisioner:v4.0.0</a></del></p>
<p><del><a target="_blank" rel="noopener" href="http://registry.cn-beijing.aliyuncs.com/pylixm/nfs-subdir-external-provisioner:v4.0.0">registry.cn-beijing.aliyuncs.com&#x2F;pylixm&#x2F;nfs-subdir-external-provisioner:v4.0.0</a></del></p>
</li>
</ul>
<h6 id="PVC测试配置"><a href="#PVC测试配置" class="headerlink" title="PVC测试配置"></a><del>PVC测试配置</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-pv-test-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 300Mi</span><br><span class="line">  storageClassName: managed-nfs-storage</span><br></pre></td></tr></table></figure>

<h1 id="六、高级调度"><a href="#六、高级调度" class="headerlink" title="六、高级调度"></a>六、高级调度</h1><h2 id="6-1-CronJob计划任务"><a href="#6-1-CronJob计划任务" class="headerlink" title="6.1 CronJob计划任务"></a>6.1 CronJob计划任务</h2><h3 id="cron表达式"><a href="#cron表达式" class="headerlink" title="cron表达式"></a>cron表达式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># ┌───────────── 分钟 (0 - 59)</span><br><span class="line"># │ ┌───────────── 小时 (0 - 23)</span><br><span class="line"># │ │ ┌───────────── 月的某天 (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── 月份 (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）</span><br><span class="line"># │ │ │ │ │                          或者是 sun，mon，tue，web，thu，fri，sat</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * *</span><br></pre></td></tr></table></figure>

<h3 id="配置文件-7"><a href="#配置文件-7" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">spec:</span><br><span class="line">  concurrencyPolicy: Allow # 并发调度策略：Allow 允许并发调度，Forbid：不允许并发执行，Replace：如果之前的任务还没执行完，就直接执行新的，放弃上一个任务</span><br><span class="line">  failedJobsHistoryLimit: 1 # 保留多少个失败的任务</span><br><span class="line">  successfulJobsHistoryLimit: 3 # 保留多少个成功的任务</span><br><span class="line">  suspend: false # 是否挂起任务，若为 true 则该任务不会执行</span><br><span class="line">#  startingDeadlineSeconds: 30 # 间隔多长时间检测失败的任务并重新执行，时间不能小于 10</span><br><span class="line">  schedule: &quot;* * * * *&quot; # 调度策略</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - name: hello</span><br><span class="line">            image: busybox:1.28</span><br><span class="line">            imagePullPolicy: IfNotPresent</span><br><span class="line">            command:</span><br><span class="line">            - /bin/sh</span><br><span class="line">            - -c</span><br><span class="line">            - date; echo Hello from the Kubernetes cluster</span><br><span class="line">          restartPolicy: OnFailure</span><br></pre></td></tr></table></figure>

<h2 id="6-2-初始化容器InitContainer"><a href="#6-2-初始化容器InitContainer" class="headerlink" title="6.2 初始化容器InitContainer"></a>6.2 初始化容器InitContainer</h2><p>在真正的容器启动之前，先启动 InitContainer，在初始化容器中完成真实容器所需的初始化操作，完成后再启动真实的容器。</p>
<p>相对于 postStart 来说，首先 InitController 能够保证一定在 EntryPoint 之前执行，而 postStart 不能，其次 postStart 更适合去执行一些命令操作，而 InitController 实际就是一个容器，可以在其他基础容器环境下执行更复杂的初始化功能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在 pod 创建的模板中配置 initContainers 参数：</span><br><span class="line">spec:</span><br><span class="line">  initContainers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo &#x27;inited;&#x27; &gt;&gt; ~/.init&quot;]</span><br><span class="line">    name: init-test</span><br></pre></td></tr></table></figure>

<h2 id="6-3-污点与容忍"><a href="#6-3-污点与容忍" class="headerlink" title="6.3 污点与容忍"></a>6.3 污点与容忍</h2><p>k8s 集群中可能管理着非常庞大的服务器，这些服务器可能是各种各样不同类型的，比如机房、地理位置、配置等，有些是计算型节点，有些是存储型节点，此时我们希望能更好的将 pod 调度到与之需求更匹配的节点上。</p>
<p>此时就需要用到污点（Taint）和容忍（Toleration），这些配置都是 key: value 类型的。</p>
<h3 id="6-3-1-污点（Taint）"><a href="#6-3-1-污点（Taint）" class="headerlink" title="6.3.1 污点（Taint）"></a>6.3.1 污点（Taint）</h3><p>污点：是标注在节点上的，当我们在一个节点上打上污点以后，k8s 会认为尽量不要将 pod 调度到该节点上，除非该 pod 上面表示可以容忍该污点，且一个节点可以打多个污点，此时则需要 pod 容忍所有污点才会被调度该节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 为节点打上污点</span><br><span class="line">kubectl taint node k8s-master key=value:NoSchedule</span><br><span class="line"></span><br><span class="line"># 移除污点</span><br><span class="line">kubectl taint node k8s-master key=value:NoSchedule-</span><br><span class="line"></span><br><span class="line"># 查看污点</span><br><span class="line">kubectl describe no k8s-master</span><br></pre></td></tr></table></figure>

<p>污点的影响：<br>NoSchedule：不能容忍的 pod 不能被调度到该节点，但是已经存在的节点不会被驱逐<br>NoExecute：不能容忍的节点会被立即清除，能容忍且没有配置 <strong>tolerationSeconds</strong> 属性，则可以一直运行，设置了 <strong>tolerationSeconds</strong>: 3600 属性，则该 pod 还能继续在该节点运行 3600 秒</p>
<h4 id="NoSchedule"><a href="#NoSchedule" class="headerlink" title="NoSchedule"></a>NoSchedule</h4><p>如果不能容忍该污点，那么 Pod 就无法调度到该节点上</p>
<h4 id="NoExecute"><a href="#NoExecute" class="headerlink" title="NoExecute"></a>NoExecute</h4><ul>
<li>如果 Pod 不能忍受这类污点，Pod 会马上被驱逐。</li>
<li>如果 Pod 能够忍受这类污点，但是在容忍度定义中没有指定 tolerationSeconds， 则 Pod 还会一直在这个节点上运行。</li>
<li>如果 Pod 能够忍受这类污点，而且指定了 tolerationSeconds， 则 Pod 还能在这个节点上继续运行这个指定的时间长度。</li>
</ul>
<h3 id="6-3-2-容忍（Toleration）"><a href="#6-3-2-容忍（Toleration）" class="headerlink" title="6.3.2 容忍（Toleration）"></a>6.3.2 容忍（Toleration）</h3><p>容忍：是标注在 pod 上的，当 pod 被调度时，如果没有配置容忍，则该 pod 不会被调度到有污点的节点上，只有该 pod 上标注了满足某个节点的所有污点，则会被调度到这些节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># pod 的 spec 下面配置容忍</span><br><span class="line">tolerations:</span><br><span class="line">- key: &quot;污点的 key&quot;</span><br><span class="line">  value: &quot;污点的 value&quot;</span><br><span class="line">  offect: &quot;NoSchedule&quot; # 污点产生的影响</span><br><span class="line">  operator: &quot;Equal&quot; # 表是 value 与污点的 value 要相等，也可以设置为 Exists 表示存在 key 即可，此时可以不用配置 value</span><br></pre></td></tr></table></figure>

<h4 id="Equal"><a href="#Equal" class="headerlink" title="Equal"></a>Equal</h4><p>比较操作类型为 Equal，则意味着必须与污点值做匹配，key&#x2F;value都必须相同，才表示能够容忍该污点</p>
<h4 id="Exists"><a href="#Exists" class="headerlink" title="Exists"></a>Exists</h4><p>容忍与污点的比较只比较 key，不比较 value，不关心 value 是什么东西，只要 key 存在，就表示可以容忍。</p>
<h2 id="6-4-亲和力"><a href="#6-4-亲和力" class="headerlink" title="6.4 亲和力"></a>6.4 亲和力</h2><h3 id="6-4-1-NodeAffinity"><a href="#6-4-1-NodeAffinity" class="headerlink" title="6.4.1 NodeAffinity"></a>6.4.1 NodeAffinity</h3><p>节点亲和力：进行 pod 调度时，优先调度到符合条件的亲和力节点上</p>
<h4 id="RequiredDuringSchedulingIgnoredDuringExecution"><a href="#RequiredDuringSchedulingIgnoredDuringExecution" class="headerlink" title="RequiredDuringSchedulingIgnoredDuringExecution"></a>RequiredDuringSchedulingIgnoredDuringExecution</h4><p>硬亲和力，即支持必须部署在指定的节点上，也支持必须不部署在指定的节点上</p>
<h4 id="PreferredDuringSchedulingIgnoredDuringExecution"><a href="#PreferredDuringSchedulingIgnoredDuringExecution" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExecution"></a>PreferredDuringSchedulingIgnoredDuringExecution</h4><p>软亲和力：尽量部署在满足条件的节点上，或尽量不要部署在被匹配的节点上</p>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><h5 id="匹配类型"><a href="#匹配类型" class="headerlink" title="匹配类型"></a>匹配类型</h5><ul>
<li>In：部署在满足条件的节点上</li>
<li>Noth：匹配不在条件中的节点，实现节点反亲和性</li>
<li>Exists：只要存在 key 名字就可以，不关心值是什么</li>
<li>DoesNotExist：匹配指定 key 名不存在的节点，实现节点反亲和性</li>
<li>Gt：value 为数值，且节点上的值小于指定的条件</li>
<li>Lt：value 为数值，且节点上的值大于指定条件</li>
</ul>
<h5 id="配置模板"><a href="#配置模板" class="headerlink" title="配置模板"></a>配置模板</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-node-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity: # 亲和力配置</span><br><span class="line">    nodeAffinity: # 节点亲和力</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution: # 节点必须匹配下方配置</span><br><span class="line">        nodeSelectorTerms: # 选择器</span><br><span class="line">        - matchExpressions: # 匹配表达式</span><br><span class="line">          - key: topology.kubernetes.io/zone # 匹配 label 的 key</span><br><span class="line">            operator: In # 匹配方式，只要匹配成功下方的一个 value 即可</span><br><span class="line">            values:</span><br><span class="line">            - antarctica-east1 # 匹配的 value</span><br><span class="line">            - antarctica-west1 # 匹配的 value</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution: # 节点尽量匹配下方配置</span><br><span class="line">      - weight: 1 # 权重[1,100]，按照匹配规则对所有节点累加权重，最终之和会加入优先级评分，优先级越高被调度的可能性越高</span><br><span class="line">        preference:</span><br><span class="line">          matchExpressions: # 匹配表达式</span><br><span class="line">          - key: another-node-label-key # label 的 key</span><br><span class="line">            operator: In # 匹配方式，满足一个即可</span><br><span class="line">            values:</span><br><span class="line">            - another-node-label-value # 匹配的 value</span><br><span class="line">#      - weight: 20</span><br><span class="line">        ......</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-node-affinity</span><br><span class="line">    image: pause:2.0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">为node打标签</span><br><span class="line">kubectl label nodes k8s-node1 security=S1</span><br></pre></td></tr></table></figure>

<h3 id="6-4-2-PodAffinity"><a href="#6-4-2-PodAffinity" class="headerlink" title="6.4.2 PodAffinity"></a>6.4.2 PodAffinity</h3><p>Pod 亲和力：将与指定 pod 亲和力相匹配的 pod 部署在同一节点。</p>
<h4 id="RequiredDuringSchedulingIgnoredDuringExecution-1"><a href="#RequiredDuringSchedulingIgnoredDuringExecution-1" class="headerlink" title="RequiredDuringSchedulingIgnoredDuringExecution"></a>RequiredDuringSchedulingIgnoredDuringExecution</h4><p>必须将应用部署在一块</p>
<h4 id="PreferredDuringSchedulingIgnoredDuringExecution-1"><a href="#PreferredDuringSchedulingIgnoredDuringExecution-1" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExecution"></a>PreferredDuringSchedulingIgnoredDuringExecution</h4><p>尽量将应用部署在一块</p>
<h4 id="配置模板-1"><a href="#配置模板-1" class="headerlink" title="配置模板"></a>配置模板</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-pod-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity: # 亲和力配置</span><br><span class="line">    podAffinity: # pod 亲和力配置</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution: # 当前 pod 必须匹配到对应条件 pod 所在的 node 上</span><br><span class="line">      - labelSelector: # 标签选择器</span><br><span class="line">          matchExpressions: # 匹配表达式</span><br><span class="line">          - key: security # 匹配的 key</span><br><span class="line">            operator: In # 匹配方式</span><br><span class="line">            values: # 匹配其中的一个 value</span><br><span class="line">            - S1</span><br><span class="line">        topologyKey: topology.kubernetes.io/zone</span><br><span class="line">    podAntiAffinity: # pod 反亲和力配置</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution: # 尽量不要将当前节点部署到匹配下列参数的 pod 所在的 node 上</span><br><span class="line">      - weight: 100 # 权重</span><br><span class="line">        podAffinityTerm: # pod 亲和力配置条件</span><br><span class="line">          labelSelector: # 标签选择器</span><br><span class="line">            matchExpressions: # 匹配表达式</span><br><span class="line">            - key: security # 匹配的 key</span><br><span class="line">              operator: In # 匹配的方式</span><br><span class="line">              values:</span><br><span class="line">              - S2 # 匹配的 value</span><br><span class="line">          topologyKey: topology.kubernetes.io/zone</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-pod-affinity</span><br><span class="line">    image: pause:2.0</span><br></pre></td></tr></table></figure>

<h3 id="6-4-3-PodAntiAffinity"><a href="#6-4-3-PodAntiAffinity" class="headerlink" title="6.4.3 PodAntiAffinity"></a>6.4.3 PodAntiAffinity</h3><p>Pod 反亲和力：根据策略尽量部署或不部署到一块</p>
<h4 id="RequiredDuringSchedulingIgnoredDuringExecution-2"><a href="#RequiredDuringSchedulingIgnoredDuringExecution-2" class="headerlink" title="RequiredDuringSchedulingIgnoredDuringExecution"></a>RequiredDuringSchedulingIgnoredDuringExecution</h4><p>不要将应用与之匹配的部署到一块</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">podAffinity:</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">  - labelSelector:</span><br><span class="line">      matchExpressions:</span><br><span class="line">      - key: security</span><br><span class="line">        operator: In</span><br><span class="line">        values:</span><br><span class="line">        - S1</span><br><span class="line">    topologyKey: topology.kubernetes.io/zone</span><br></pre></td></tr></table></figure>

<h4 id="PreferredDuringSchedulingIgnoredDuringExecution-2"><a href="#PreferredDuringSchedulingIgnoredDuringExecution-2" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExecution"></a>PreferredDuringSchedulingIgnoredDuringExecution</h4><p>尽量不要将应用部署到一块</p>
<h1 id="七、身份认证与权限"><a href="#七、身份认证与权限" class="headerlink" title="七、身份认证与权限"></a>七、身份认证与权限</h1><p>Kubernetes 中提供了良好的多租户认证管理机制，如 RBAC、ServiceAccount 还有各种策略等。</p>
<p>通过该文件可以看到已经配置了 RBAC 访问控制<br>&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service</p>
<h2 id="7-1-认证"><a href="#7-1-认证" class="headerlink" title="7.1 认证"></a>7.1 认证</h2><p>所有 Kubernetes 集群有两类用户：由 Kubernetes 管理的<a target="_blank" rel="noopener" href="http://docs.kubernetes.org.cn/84.html">Service Accounts</a> （服务账户）和（Users Accounts） 普通账户。</p>
<p>普通账户是假定被外部或独立服务管理的，由管理员分配 keys，用户像使用 Keystone 或 google 账号一样，被存储在包含 usernames 和 passwords 的 list 的文件里。</p>
<p><em>需要注意：在 Kubernetes 中不能通过 API 调用将普通用户添加到集群中</em>。</p>
<ul>
<li>普通帐户是针对（人）用户的，服务账户针对 Pod 进程。</li>
<li>普通帐户是全局性。在集群所有namespaces中，名称具有惟一性。</li>
<li>通常，群集的普通帐户可以与企业数据库同步，新的普通帐户创建需要特殊权限。服务账户创建目的是更轻量化，允许集群用户为特定任务创建服务账户。</li>
<li>普通帐户和服务账户的审核注意事项不同。</li>
<li>对于复杂系统的配置包，可以包括对该系统的各种组件的服务账户的定义。</li>
</ul>
<h3 id="7-1-1-User-Accounts"><a href="#7-1-1-User-Accounts" class="headerlink" title="7.1.1 User Accounts"></a>7.1.1 User Accounts</h3><h3 id="7-1-2-Service-Accounts"><a href="#7-1-2-Service-Accounts" class="headerlink" title="7.1.2 Service Accounts"></a>7.1.2 Service Accounts</h3><h4 id="Service-Account-自动化"><a href="#Service-Account-自动化" class="headerlink" title="Service Account 自动化"></a>Service Account 自动化</h4><h5 id="Service-Account-Admission-Controller"><a href="#Service-Account-Admission-Controller" class="headerlink" title="Service Account Admission Controller"></a>Service Account Admission Controller</h5><p>通过 <a target="_blank" rel="noopener" href="http://docs.kubernetes.org.cn/144.html">Admission Controller</a> 插件来实现对 pod 修改，它是 apiserver 的一部分。创建或更新 pod 时会同步进行修改 pod。当插件处于激活状态（在大多数发行版中都默认情况）创建或修改 pod 时，会按以下操作执行：</p>
<ol>
<li>如果 pod 没有设置 ServiceAccount，则将 ServiceAccount 设置为 default。</li>
<li>确保 pod 引用的 ServiceAccount 存在，否则将会拒绝请求。</li>
<li>如果 pod 不包含任何 ImagePullSecrets，则将ServiceAccount 的 ImagePullSecrets 会添加到 pod 中。</li>
<li>为包含 API 访问的 Token 的 pod 添加了一个 volume。</li>
<li>把 volumeSource 添加到安装在 pod 的每个容器中，挂载在 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount。</li>
</ol>
<h5 id="Token-Countroller"><a href="#Token-Countroller" class="headerlink" title="Token Countroller"></a>Token Countroller</h5><p>TokenController 作为 controller-manager 的一部分运行。异步行为:</p>
<ul>
<li>观察 serviceAccount 的创建，并创建一个相应的 Secret 来允许 API 访问。</li>
<li>观察 serviceAccount 的删除，并删除所有相应的ServiceAccountToken Secret</li>
<li>观察 secret 添加，并确保关联的 ServiceAccount 存在，并在需要时向 secret 中添加一个 Token。</li>
<li>观察 secret 删除，并在需要时对应 ServiceAccount 的关联</li>
</ul>
<h5 id="Service-Account-Controller"><a href="#Service-Account-Controller" class="headerlink" title="Service Account Controller"></a>Service Account Controller</h5><p>Service Account Controller 在 namespaces 里管理ServiceAccount，并确保每个有效的 namespaces 中都存在一个名为 “default” 的 ServiceAccount。</p>
<h2 id="7-2-授权（RBAC）"><a href="#7-2-授权（RBAC）" class="headerlink" title="7.2 授权（RBAC）"></a>7.2 授权（RBAC）</h2><h3 id="7-2-1-Role"><a href="#7-2-1-Role" class="headerlink" title="7.2.1 Role"></a>7.2.1 Role</h3><p>代表一个角色，会包含一组权限，没有拒绝规则，只是附加允许。它是 Namespace 级别的资源，只能作用与 Namespace 之内。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看已有的角色信息</span><br><span class="line">kubectl get role -n ingress-nginx -oyaml</span><br></pre></td></tr></table></figure>

<h4 id="配置文件-8"><a href="#配置文件-8" class="headerlink" title="配置文件"></a>配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class="line">  name: nginx-ingress</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roles:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  - pods</span><br><span class="line">  - secrets</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resourceNames:</span><br><span class="line">  - ingress-controller-label-nginx</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - update</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - create</span><br></pre></td></tr></table></figure>

<h3 id="7-2-2-ClusterRole"><a href="#7-2-2-ClusterRole" class="headerlink" title="7.2.2 ClusterRole"></a>7.2.2 ClusterRole</h3><p>功能与 Role 一样，区别是资源类型为集群类型，而 Role 只在 Namespace</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看某个集群角色的信息</span><br><span class="line">kubectl get clusterrole view -oyaml</span><br></pre></td></tr></table></figure>

<h3 id="7-2-3-RoleBinding"><a href="#7-2-3-RoleBinding" class="headerlink" title="7.2.3 RoleBinding"></a>7.2.3 RoleBinding</h3><p>Role 或 ClusterRole 只是用于制定权限集合，具体作用与什么对象上，需要使用 RoleBinding 来进行绑定。</p>
<p>作用于 Namespace 内，可以将 Role 或 ClusterRole 绑定到 User、Group、Service Account 上。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看 rolebinding 信息</span><br><span class="line">kubectl get rolebinding --all-namespaces</span><br><span class="line"></span><br><span class="line"># 查看指定 rolebinding 的配置信息</span><br><span class="line">kubectl get rolebinding &lt;role_binding_name&gt; --all-namespaces -oyaml</span><br></pre></td></tr></table></figure>

<h4 id="配置文件-9"><a href="#配置文件-9" class="headerlink" title="配置文件"></a>配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  ......</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name nginx-ingress-role</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: nginx-ingress-serviceaccount</span><br><span class="line">  namespace: ingress-nginx</span><br></pre></td></tr></table></figure>

<h3 id="7-2-4-ClusterRoleBinding"><a href="#7-2-4-ClusterRoleBinding" class="headerlink" title="7.2.4 ClusterRoleBinding"></a>7.2.4 ClusterRoleBinding</h3><p>与 RoleBinding 相同，但是作用于集群之上，可以绑定到该集群下的任意 User、Group 或 Service Account </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/" data-id="clzi26lgi0000gy7n0xnt83rf" data-title="K8S实战进阶" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-K8S核心概念" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/01/K8S%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/" class="article-date">
  <time class="dt-published" datetime="2024-04-01T04:58:00.000Z" itemprop="datePublished">2024-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/04/01/K8S%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/">K8S核心概念</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、认识Kubernetes"><a href="#一、认识Kubernetes" class="headerlink" title="一、认识Kubernetes"></a>一、认识Kubernetes</h1><h2 id="1-1-什么是Kubernetes？"><a href="#1-1-什么是Kubernetes？" class="headerlink" title="1.1 什么是Kubernetes？"></a>1.1 什么是Kubernetes？</h2><p>Kubernetes 是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes 的目标是让部署容器化的应用简单并且高效（powerful），Kubernetes 提供了应用部署，规划，更新，维护的一种机制。</p>
<p>Kubernetes 这个名字源于希腊语，意为“舵手”或“飞行员”。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。 Kubernetes 建立在 <a target="_blank" rel="noopener" href="https://research.google/pubs/pub43438">Google 大规模运行生产工作负载十几年经验</a>的基础上， 结合了社区中最优秀的想法和实践。</p>
<h2 id="1-2-为什么需要Kubernetes？"><a href="#1-2-为什么需要Kubernetes？" class="headerlink" title="1.2 为什么需要Kubernetes？"></a>1.2 为什么需要Kubernetes？</h2><h3 id="1-2-1-应用部署的三大阶段"><a href="#1-2-1-应用部署的三大阶段" class="headerlink" title="1.2.1 应用部署的三大阶段"></a>1.2.1 应用部署的三大阶段</h3><ul>
<li><p><strong>传统部署：</strong> 程序员&#x2F;运维工程师手动操作部署应用，直接将应用部署在目标机器上，由于资源不隔离，容易出现资源争抢、依赖冲突等各方面问题。</p>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_Traditional_deployments.png" alt="传统部署"></p>
</li>
<li><p><strong>虚拟化部署：</strong> 利用 OpenStask &#x2F; VMware 等虚拟化技术，将一台目标机器虚拟化为多个虚拟机器，按照需求将应用部署到不同的虚拟机中，对虚拟机进行动态的水平扩容等管理操作。</p>
<p>相对传统部署自动化、资源隔离的能力提升了，带来的问题是虚拟化的逻辑过重，导致效率不高，且耗费资源较多。</p>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_Virtualized_deployments.png" alt="虚拟化部署"></p>
</li>
<li><p><strong>容器化部署：</strong> 可以理解为轻量级的虚拟化，完美弥补虚拟化技术过重的问题，且由于直接共享主机硬件资源，只是通过系统提供的命名空间等技术实现资源隔离，损耗更小，且效率更高。</p>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_Containerized_deployments.png" alt="容器化部署"></p>
</li>
</ul>
<h3 id="1-2-2-K8S的特点"><a href="#1-2-2-K8S的特点" class="headerlink" title="1.2.2 K8S的特点"></a>1.2.2 K8S的特点</h3><ul>
<li><strong>自我修复</strong></li>
<li><strong>弹性伸缩</strong></li>
<li><strong>自动部署和回滚</strong></li>
<li><strong>服务发现和负载均衡</strong></li>
<li><strong>机密和配置管理</strong></li>
<li><strong>存储编排</strong></li>
<li><strong>批处理</strong></li>
</ul>
<h2 id="1-3-企业级容器调度平台"><a href="#1-3-企业级容器调度平台" class="headerlink" title="1.3 企业级容器调度平台"></a>1.3 企业级容器调度平台</h2><h3 id="1-3-1-Apache-Mesos"><a href="#1-3-1-Apache-Mesos" class="headerlink" title="1.3.1 Apache Mesos"></a>1.3.1 Apache Mesos</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><p>Mesos 是一个分布式调度系统内核，早于 Docker 产生，Mesos 作为资源管理器，从 DC&#x2F;OS (数据中心操作系统)的角度提供资源视图。主&#x2F;从结构工作模式，主节点分配任务，并用从节点上的 Executor 负责执行，通过 Zookeeper 给主节点提供服务注册、服务发现功能。通过 Framework Marathon 提供容器调度的能力。</p>
<h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><p>经过时间的检验，作为资源管理器的 Apache Mesos 在容器之前就已经出现很久了，支持运行容器化化和非容器化的工作负载。可以支持应用程序的健康检查，开放的架构。支持多个框架和多个调度器，通过不同的 Framework 可以运行 Haddop&#x2F;Spark&#x2F;MPI等多种不同的任务。</p>
<p>支持超大型规模的节点管理，模拟测试支持超过 5w+ 节点，在大规模上拥有较大优势。</p>
<h3 id="1-3-2-Docker-Swarm"><a href="#1-3-2-Docker-Swarm" class="headerlink" title="1.3.2 Docker Swarm"></a>1.3.2 Docker Swarm</h3><h4 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h4><p>Docker Swarm 是一个由 Docker 开发的调度框架。由 Docker 自身开发的好处之一就是标准 Docker API 的使用，Swarm 由多个代理（Agent）组成，把这些代理称之为节点（Node）。这些节点就是主机，这些主机在启动 Docker Daemon 的时候就会打开相应的端口，以此支持 Docker 远程 API。这些机器会根据 Swarm 调度器分配给它们的任务，拉取和运行不同的镜像。</p>
<h4 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h4><p>从 Docker1.12 版本开始，Swarm 随 Docker 一起默认安装发布。由于随 Docker 引擎一起发布，无需额外安装，配置简单。支持服务注册、服务发现，内置 Overlay Network 以及 Load Balancer。与 Docker CLI 非常类似的操作命令，对熟悉 Docker 的人非常容易上手学习。</p>
<p>入门门槛、学习成本较低，使用更便捷，适用于中小型系统。</p>
<h3 id="1-3-3-Google-Kubernetes"><a href="#1-3-3-Google-Kubernetes" class="headerlink" title="1.3.3 Google Kubernetes"></a>1.3.3 Google Kubernetes</h3><h4 id="基本概念-2"><a href="#基本概念-2" class="headerlink" title="基本概念"></a>基本概念</h4><p>Kubernetes 是基于 Google 在过去十五年来大量生产环境中运行工作负载的经验。Kubernetes 的实现参考了 Google 内部的资源调度框架，但并不是 Borg 的内部容器编排系统的开源，而是借鉴 Google 从运行 Borg 获得的经验教训，形成了 Kubernetes 项目。</p>
<p>Borg的架构图：</p>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_borg.png" alt="borg"></p>
<p>它使用 Label 和 Pod 的概念来将容器划分为逻辑单元。Pods 是同地协作（co-located）容器的集合，这些容器被共同部署和调度，形成了一个服务，这是 Kubernetes 和其他两个框架的主要区别。相比于基于相似度的容器调度方式（就像 Swarm 和Mesos），这个方法简化了对集群的管理。</p>
<h4 id="优势-2"><a href="#优势-2" class="headerlink" title="优势"></a>优势</h4><p>最流行等容器编排解决方案框架，基于 Google 庞大的生态圈及社区产生的产品。通过 Pods 这一抽象的概念，解决 Container 之间的依赖于通信问题。Pods，Services，Deployments 是独立部署的部分，可以通过 Selector 提供更多的灵活性。内置服务注册表和负载平衡。</p>
<p>适用度更广，功能更强大，相较于 Mesos 来说节点规模较小。</p>
<h1 id="二、集群架构与组件"><a href="#二、集群架构与组件" class="headerlink" title="二、集群架构与组件"></a>二、集群架构与组件</h1><h2 id="2-1-相关组件"><a href="#2-1-相关组件" class="headerlink" title="2.1 相关组件"></a>2.1 相关组件</h2><p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_architecture.jpg" alt="集群架构"></p>
<h3 id="2-1-1-控制面板组件（Master）"><a href="#2-1-1-控制面板组件（Master）" class="headerlink" title="2.1.1 控制面板组件（Master）"></a>2.1.1 控制面板组件（Master）</h3><p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_control_panel.png" alt="控制面板"></p>
<p><strong>api-server：</strong> API 服务器是 Kubernetes <a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/glossary/?all=true#term-control-plane">控制平面</a>的组件， 该组件负责公开了 Kubernetes API，负责处理接受请求的工作。 API 服务器是 Kubernetes 控制平面的前端。</p>
<p>Kubernetes API 服务器的主要实现是 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/command-line-tools-reference/kube-apiserver/">kube-apiserver</a>。 kube-apiserver 设计上考虑了水平扩缩，也就是说，它可通过部署多个实例来进行扩缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。</p>
<p><strong>kube-controller-manager：</strong> 控制器管理器：管理各个类型的控制器针对k8s中的各种资源进行管理。这些控制器包括：</p>
<ul>
<li>节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应</li>
<li>任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</li>
<li>端点分片控制器（EndpointSlice controller）：填充端点分片（EndpointSlice）对象（以提供 Service 和 Pod 之间的链接）。</li>
<li>服务账号控制器（ServiceAccount controller）：为新的命名空间创建默认的服务账号（ServiceAccount）。</li>
</ul>
<p><strong>cloud-controller-manager：</strong> 云控制器管理器：第三方云平台提供的控制器API对接管理功能。嵌入了特定于云平台的控制逻辑。 云控制器管理器（Cloud Controller Manager）允许你将你的集群连接到云提供商的 API 之上， 并将与该云平台交互的组件同与你的集群交互的组件分离开来。</p>
<p>cloud-controller-manager 仅运行特定于云平台的控制器。 因此如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的集群不需要有云控制器管理器。</p>
<p>与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的控制回路组合到同一个可执行文件中， 供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。</p>
<p><strong>kube-scheduler：</strong> 调度器：负责将Pod基于一定算法，将其调用到更合适的节点（服务器）上。</p>
<p><strong>etcd：</strong> 理解为k8s的数据库，提供了基于Raft算法实现自主的集群高可用。一致且高度可用的键值存储，用作 Kubernetes 的所有集群数据的后台数据库。</p>
<p>如果你的 Kubernetes 集群使用 etcd 作为其后台数据库， 请确保你针对这些数据有一份 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster">备份</a>计划。</p>
<p>你可以在官方<a target="_blank" rel="noopener" href="https://etcd.io/docs/">文档</a>中找到有关 etcd 的深入知识。</p>
<p>早期数据存放在内存，现在已经是持久化存储的了。</p>
<h3 id="2-1-2-节点组件（Node）"><a href="#2-1-2-节点组件（Node）" class="headerlink" title="2.1.2 节点组件（Node）"></a>2.1.2 节点组件（Node）</h3><p><strong>kubelet：</strong> kubelet 负责维护Pod的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理；</p>
<p><strong>kube-proxy：</strong> 网络代理，负责为 Service 提供 cluster 内部的服务发现和负载均衡（4层负载，基于iptables）。</p>
<p><strong>container-runtime：</strong>  负责镜像管理以及 Pod 和容器的真正运行（CRI）；</p>
<p>Kubernetes 支持许多容器运行环境，例如 <a target="_blank" rel="noopener" href="https://containerd.io/docs/">containerd</a>、 <a target="_blank" rel="noopener" href="https://cri-o.io/#what-is-cri-o">CRI-O</a> 以及 <a target="_blank" rel="noopener" href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md">Kubernetes CRI (容器运行环境接口)</a> 的其他任何实现。</p>
<h3 id="2-1-3-附加组件"><a href="#2-1-3-附加组件" class="headerlink" title="2.1.3 附加组件"></a>2.1.3 附加组件</h3><p><strong>kube-dns：</strong> 负责为整理集群提供DNS服务。</p>
<p><strong>Ingress Controller：</strong> 为服务提供外网入口。</p>
<p><strong>Heapster：</strong> 提供资源监控（可替换，如Prometheus）。</p>
<p><strong>Dashboard：</strong> 控制台，提供GUI。</p>
<p><strong>Federation：</strong> 提供跨可用区的集群。</p>
<p><strong>Fluentd-elasticsearch：</strong> 提供集群日志采集、存储与查询。</p>
<h2 id="2-2-分层架构"><a href="#2-2-分层架构" class="headerlink" title="2.2 分层架构"></a>2.2 分层架构</h2><p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_kubernetes_layers.jpg" alt="分层架构"></p>
<p><strong>生态系统：</strong> 在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴：</p>
<ul>
<li><p>Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等。</p>
</li>
<li><p>Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等。</p>
</li>
</ul>
<p><strong>接口层：</strong> kubectl命令行工具、客户端SDK以及集群联邦。</p>
<p><strong>管理层：</strong> 系统度量（如基础设施、容器和网络的度量），自动化（如自动化扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等）。</p>
<p><strong>应用层：</strong> 部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）。</p>
<p><strong>核心层：</strong> Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境。</p>
<h1 id="三、核心概念与专业术语"><a href="#三、核心概念与专业术语" class="headerlink" title="三、核心概念与专业术语"></a>三、核心概念与专业术语</h1><h2 id="3-1-服务的分类"><a href="#3-1-服务的分类" class="headerlink" title="3.1 服务的分类"></a>3.1 服务的分类</h2><h3 id="3-1-1-无状态"><a href="#3-1-1-无状态" class="headerlink" title="3.1.1 无状态"></a>3.1.1 无状态</h3><p><strong>代表应用：</strong> Nginx、Apache。</p>
<p><strong>优点：</strong> 对客户端透明，无依赖关系，可以高效实现扩容、迁移。</p>
<p><strong>缺点：</strong> 不能存储数据，需要额外的数据服务支撑。</p>
<h3 id="3-1-2-有状态"><a href="#3-1-2-有状态" class="headerlink" title="3.1.2 有状态"></a>3.1.2 有状态</h3><p><strong>代表应用：</strong> MySQL、Redis。</p>
<p><strong>优点：</strong> 可以独立存储数据，实现数据管理。</p>
<p><strong>缺点：</strong> 集群环境下需要实现主从、数据同步、备份、水平扩容复杂。</p>
<h2 id="3-2-资源和对象"><a href="#3-2-资源和对象" class="headerlink" title="3.2 资源和对象"></a>3.2 资源和对象</h2><p>Kubernetes 中的所有内容都被抽象为“资源”，如 Pod、Service、Node 等都是资源。“对象”就是“资源”的实例，是持久化的实体。如某个具体的 Pod、某个具体的 Node。Kubernetes 使用这些实体去表示整个集群的状态。</p>
<p> 对象的创建、删除、修改都是通过 “Kubernetes API”，也就是 “Api Server” 组件提供的 API 接口，这些是 RESTful 风格的 Api，与 k8s 的“万物皆对象”理念相符。命令行工具 “kubectl”，实际上也是调用 kubernetes api。</p>
<p> K8s 中的资源类别有很多种，kubectl 可以通过配置文件来创建这些 “对象”，配置文件更像是描述对象“属性”的文件，配置文件格式可以是 “JSON” 或 “YAML”，常用 “YAML”。</p>
<h3 id="3-2-1-资源的分类"><a href="#3-2-1-资源的分类" class="headerlink" title="3.2.1 资源的分类"></a>3.2.1 资源的分类</h3><h4 id="3-2-1-1-元数据型"><a href="#3-2-1-1-元数据型" class="headerlink" title="3.2.1.1 元数据型"></a>3.2.1.1 元数据型</h4><p>对于资源的元数据描述，每一个资源都可以适用元空间的数据（主要针对于Pod）。</p>
<p><strong>Horizontal Pod Autoscaler（HPA）：</strong> Pod 自动扩容：可以根据 CPU 使用率或自定义指标（metrics）自动对 Pod 进行扩&#x2F;缩容。</p>
<ul>
<li><p>控制管理器每隔30s（可以通过–horizontal-pod-autoscaler-sync-period修改）查询metrics的资源使用情况。</p>
</li>
<li><p>支持三种metrics类型：</p>
<ol>
<li>预定义metrics（比如Pod的CPU）以利用率的方式计算。</li>
<li>自定义的Pod metrics，以原始值（raw value）的方式计算。</li>
<li>自定义的object metrics。</li>
</ol>
</li>
<li><p>支持两种metrics查询方式：Heapster和自定义的REST API。</p>
</li>
<li><p>支持多metrics。</p>
</li>
</ul>
<p><strong>PodTemplate：</strong> Pod Template 是关于 Pod 的定义，但是被包含在其他的 Kubernetes 对象中（例如 Deployment、StatefulSet、DaemonSet 等控制器）。控制器通过 Pod Template 信息来创建 Pod。</p>
<p><strong>LimitRange：</strong> 可以对集群内 Request 和 Limits 的配置做一个全局的统一的限制，相当于批量设置了某一个范围内（某个命名空间）的 Pod 的资源使用限制。</p>
<h4 id="3-2-1-2-集群级"><a href="#3-2-1-2-集群级" class="headerlink" title="3.2.1.2 集群级"></a>3.2.1.2 集群级</h4><p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_k8s_cluster.png" alt="集群"></p>
<p><strong>Namespace：</strong> Kubernetes 支持多个虚拟集群，它们底层依赖于同一个物理集群，这些虚拟集群被称为命名空间。</p>
<p>作用是用于实现多团队&#x2F;环境的资源隔离。</p>
<p>命名空间 namespace 是 k8s 集群级别的资源，可以给不同的用户、租户、环境或项目创建对应的命名空间。</p>
<p>​            <strong>默认 namespace：</strong></p>
<ul>
<li>kube-system 主要用于运行系统级资源，存放 k8s 自身的组件</li>
<li>kube-public 此命名空间是自动创建的，并且可供所有用户（包括未经过身份验证的用户）读取。此命名空间主要用于集群使用，关联的一些资源在集群中是可见的并且可以公开读取。此命名空间的公共方面知识一个约定，但不是非要这么要求。</li>
<li>default 未指定名称空间的资源就是 default，即你在创建pod 时如果没有指定 namespace，则会默认使用 default</li>
</ul>
<p><strong>Node：</strong> 不像其他的资源（如 Pod 和 Namespace），Node 本质上不是Kubernetes 来创建的，Kubernetes 只是管理 Node 上的资源。虽然可以通过 Manifest 创建一个Node对象（如下 json 所示），但 Kubernetes 也只是去检查是否真的是有这么一个 Node，如果检查失败，也不会往上调度 Pod。</p>
<p><strong>ClusterRole：</strong> ClusterRole 是一组权限的集合，但与 Role 不同的是，ClusterRole 可以在包括所有 Namespace 和集群级别的资源或非资源类型进行鉴权。</p>
<p><strong>ClusterRoleBinding：</strong> 将 Subject 绑定到 ClusterRole，ClusterRoleBinding 将使规则在所有命名空间中生效。</p>
<h4 id="3-2-1-3-命名空间级（重点）"><a href="#3-2-1-3-命名空间级（重点）" class="headerlink" title="3.2.1.3 命名空间级（重点）"></a><u>3.2.1.3 命名空间级（重点）</u></h4><h5 id="工作负载型"><a href="#工作负载型" class="headerlink" title="工作负载型"></a>工作负载型</h5><h6 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h6><p>Pod（容器组）是 Kubernetes 中最小的可部署单元。一个 Pod（容器组）包含了一个应用程序容器（某些情况下是多个容器）、存储资源、一个唯一的网络 IP 地址、以及一些确定容器该如何运行的选项。Pod 容器组代表了 Kubernetes 中一个独立的应用程序运行实例，该实例可能由单个容器或者几个紧耦合在一起的容器组成。</p>
<p>Docker 是 Kubernetes Pod 中使用最广泛的容器引擎；Kubernetes Pod 同时也支持其他类型的容器引擎。<br>Kubernetes 集群中的 Pod 存在如下两种使用途径：</p>
<ul>
<li><p>一个 Pod 中只运行一个容器。”one-container-per-pod” 是 Kubernetes 中最常见的使用方式。此时，您可以认为 Pod 容器组是该容器的 wrapper，Kubernetes 通过 Pod 管理容器，而不是直接管理容器。</p>
</li>
<li><p>一个 Pod 中运行多个需要互相协作的容器。您可以将多个紧密耦合、共享资源且始终在一起运行的容器编排在同一个 Pod 中。同一个Pod中的资源是通过pause容器进行的，pause容器负责共享同一Pod中的网络、文件系统等资源。</p>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_namespace.webp" alt="命名空间"></p>
</li>
</ul>
<p><strong>副本（replicas）：</strong> 先引入“副本”的概念——一个 Pod 可以被复制成多份，每一份可被称之为一个“副本”，这些“副本”除了一些描述性的信息（Pod 的名字、uid 等）不一样以外，其它信息都是一样的，譬如 Pod 内部的容器、容器数量、容器里面运行的应用等的这些信息都是一样的，这些副本提供同样的功能。</p>
<p>Pod 的<em><strong>“控制器”</strong></em>通常包含一个名为 “replicas” 的属性。“replicas”属性则指定了特定 Pod 的副本的数量，当当前集群中该 Pod 的数量与该属性指定的值不一致时，k8s 会采取一些策略去使得当前状态满足配置的要求。</p>
<p><strong>控制器：</strong> 当 Pod 被创建出来，Pod 会被调度到集群中的节点上运行，Pod 会在该节点上一直保持运行状态，直到进程终止、Pod 对象被删除、Pod 因节点资源不足而被驱逐或者节点失效为止。Pod 并不会自愈，当节点失效，或者调度 Pod 的这一操作失败了，Pod 就该被删除。如此，单单用 Pod 来部署应用，是不稳定不安全的。</p>
<p>Kubernetes 使用更高级的资源对象 <em><strong>“控制器”</strong></em> 来实现对Pod的管理。控制器可以为您创建和管理多个 Pod，管理副本和上线，并在集群范围内提供自修复能力。 例如，如果一个节点失败，控制器可以在不同的节点上调度一样的替身来自动替换 Pod。</p>
<ol>
<li><p>适用无状态服务</p>
<ul>
<li><p><strong>ReplicationController（RC）：</strong> Replication Controller 简称 RC，RC 是 Kubernetes 系统中的核心概念之一，简单来说，RC 可以保证在任意时间运行 Pod 的副本数量，能够保证 Pod 总是可用的。如果实际 Pod 数量比指定的多那就结束掉多余的，如果实际数量比指定的少就新启动一些Pod，当 Pod 失败、被删除或者挂掉后，RC 都会去自动创建新的 Pod 来保证副本数量，所以即使只有一个 Pod，我们也应该使用 RC 来管理我们的 Pod。可以说，通过 ReplicationController，Kubernetes 实现了 Pod 的高可用性。</p>
</li>
<li><p><strong>ReplicaSet（RS）：</strong> RC （ReplicationController ）主要的作用就是用来确保容器应用的副本数始终保持在用户定义的副本数 。即如果有容器异常退出，会自动创建新的 Pod 来替代；而如果异常多出来的容器也会自动回收（已经成为过去时），在 v1.11 版本废弃。</p>
<p><strong>Kubernetes 官方建议使用 RS（ReplicaSet ） 替代 RC （ReplicationController ） 进行部署，RS 跟 RC 没有本质的不同，只是名字不一样，并且 RS 支持集合式的 selector。</strong></p>
<ol>
<li><p><strong>Label和Selector：</strong> label （标签）是附加到 Kubernetes 对象（比如 Pods）上的键值对，用于区分对象（比如Pod、Service）。 label 旨在用于指定对用户有意义且相关的对象的标识属性，但不直接对核心系统有语义含义。 label 可以用于组织和选择对象的子集。label 可以在创建时附加到对象，随后可以随时添加和修改。可以像 namespace 一样，使用 label 来获取某类对象，但 label 可以与 selector 一起配合使用，用表达式对条件加以限制，实现更精确、更灵活的资源查找。</p>
<p>label 与 selector 配合，可以实现对象的“关联”，“Pod 控制器” 与 Pod 是相关联的 —— “Pod 控制器”依赖于 Pod，可以给 Pod 设置 label，然后给“控制器”设置对应的 selector，这就实现了对象的关联。</p>
</li>
</ol>
</li>
<li><p><strong>Deployment：</strong> 针对RS（RS帮助我们动态更新Pod的副本数，可以通过selector来选择对哪些Pod生效，RS仅支持对Pod的扩容与缩容。）的更高层次的封装，提供了更丰富的部署相关的功能。</p>
<ol>
<li>创建ReplicaSet&#x2F;Pod</li>
<li>滚动升级&#x2F;回滚</li>
<li>平滑扩容和缩容</li>
<li>暂停与恢复Deployment</li>
</ol>
</li>
</ul>
</li>
<li><p>适用有状态服务</p>
<p><strong>StatefulSet：</strong> StatefulSet 中每个 Pod 的 DNS 格式为 statefulSetName-{0..N-1}.serviceName.namespace.svc.cluster.local</p>
<ul>
<li>serviceName 为 Headless Service 的名字</li>
<li>0..N-1 为 Pod 所在的序号，从 0 开始到 N-1</li>
<li>statefulSetName 为 StatefulSet 的名字</li>
<li>namespace 为服务所在的 namespace，Headless Servic 和 StatefulSet 必须在相同的 namespace</li>
<li>.cluster.local 为 Cluster Domain</li>
</ul>
<p>主要特点：</p>
<ul>
<li>稳定的持久化存储：即 Pod 重新调度后还是能访问到相同的持久化数据，基于 PVC 来实现</li>
<li>稳定的网络标志：稳定的网络标志，即 Pod 重新调度后其 PodName 和 HostName 不变，基于 Headless Service（即没有 Cluster IP 的 Service）来实现</li>
<li>有序部署，有序扩展：有序部署，有序扩展，即 Pod 是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从 0到 N-1，在下一个Pod 运行之前所有之前的 Pod 必须都是 Running 和 Ready 状态），基于 init containers 来实现</li>
<li>有序收缩，有序删除：即从 N-1 到 0</li>
</ul>
<p>组成：</p>
<ul>
<li><p>Headless Service：</p>
<p>用于定义网络标志（DNS domain）</p>
<p>Domain Name Server：域名服务<br>将域名与 ip 绑定映射关系</p>
<p>服务名 &#x3D;&gt; 访问路径（域名） &#x3D;&gt; ip</p>
</li>
<li><p>volumeClaimTemplate：用于创建 PersistentVolumes</p>
</li>
</ul>
<p>注意事项：</p>
<ul>
<li>kubernetes v1.5版本以上才支持</li>
<li>所有Pod的Volume必须使用PersistentVolume或者是管理员事先创建好</li>
<li>为了保证数据安全，删除StatefulSet时不会删除Volume</li>
<li>StatefulSet需要一个Headless Service来定义DNS domin,需要在StatefulSet之前创建好</li>
</ul>
</li>
<li><p>守护进程</p>
<p><strong>DeamonSet：</strong> DaemonSet 保证在每个 Node 上都运行一个容器副本，常用来部署一些集群的日志、监控或者其他系统管理应用。典型的应用包括：</p>
<ul>
<li>日志收集，比如 fluentd，logstash 等</li>
<li>系统监控，比如 Prometheus Node Exporter，collectd，New Relic agent，Ganglia gmond 等</li>
<li>系统程序，比如 kube-proxy, kube-dns, glusterd, ceph 等</li>
</ul>
</li>
<li><p>任务&#x2F;定时任务</p>
<p><strong>Job：</strong> 一次性任务，运行完成后Pod销毁，不再重新启动新容器。</p>
<p><strong>CronJob：</strong> CronJob 是在 Job 基础上加上了定时功能。</p>
</li>
</ol>
<h5 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h5><p><strong>Service：</strong> “Service” 简写 “svc”。Pod 不能直接提供给外网访问，而是应该使用 service。Service 就是把 Pod 暴露出来提供服务，Service 才是真正的“服务”，它的中文名就叫“服务”。</p>
<p>可以说 Service 是一个应用服务的抽象，定义了 Pod 逻辑集合和访问这个 Pod 集合的策略。Service 代理 Pod 集合，对外表现为一个访问入口，访问该入口的请求将经过负载均衡，转发到后端 Pod 中的容器。</p>
<p>Service实现K8S集群内部的网络调用，包括负载均衡（四层负载）（横向流量&#x2F;东西流量）。</p>
<p><strong>Ingress：</strong> Ingress 可以提供外网访问 Service 的能力。可以把某个请求地址映射、路由到特定的 service。</p>
<p>ingress 需要配合 ingress controller 一起使用才能发挥作用，ingress 只是相当于路由规则的集合而已，真正实现路由功能的，是 Ingress Controller，ingress controller 和其它 k8s 组件一样，也是在 Pod 中运行。</p>
<p>Ingress实现将K8S内部服务暴露给外网访问的服务，Ingress-nginx,实现反向代理，负载均衡（七层负载）（纵向流量&#x2F;南北流量）。</p>
<p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_Service_discovery.png" alt="服务发现"></p>
<h5 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h5><p><strong>Volume：</strong> 数据卷，共享 Pod 中容器使用的数据。用来放持久化的数据，比如数据库数据。</p>
<p><strong>CSI：</strong> Container Storage Interface 是由来自 Kubernetes、Mesos、Docker 等社区成员联合制定的一个行业标准接口规范，旨在将任意存储系统暴露给容器化应用程序。</p>
<p>CSI 规范定义了存储提供商实现 CSI 兼容的 Volume Plugin 的最小操作集和部署建议。CSI 规范的主要焦点是声明 Volume Plugin 必须实现的接口。</p>
<h5 id="特殊类型配置"><a href="#特殊类型配置" class="headerlink" title="特殊类型配置"></a>特殊类型配置</h5><p><strong>ConfigMap：</strong> 用来放配置，与 Secret 是类似的，只是 ConfigMap 放的是明文的数据，Secret 是密文存放。</p>
<p><strong>Secret：</strong> Secret 解决了密码、token、密钥等敏感数据的配置问题，而不需要把这些敏感数据暴露到镜像或者 Pod Spec 中。Secret 可以以 Volume 或者环境变量的方式使用。</p>
<p>​        <strong>Secret 有三种类型：</strong></p>
<ul>
<li>Service Account：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 &#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount 目录中；</li>
<li>Opaque：base64 编码格式的 Secret，用来存储密码、密钥等；</li>
<li>kubernetes.io&#x2F;dockerconfigjson：用来存储私有 docker registry 的认证信息。</li>
</ul>
<p><strong>DownwardAPI：</strong> downwardAPI 这个模式和其他模式不一样的地方在于它不是为了存放容器的数据也不是用来进行容器和宿主机的数据交换的，而是让 pod 里的容器能够直接获取到这个 pod 对象本身的一些信息。</p>
<p>downwardAPI 提供了两种方式用于将 pod 的信息注入到容器内部：</p>
<p>环境变量：用于单个变量，可以将 pod 信息和容器信息直接注入容器内部</p>
<p>volume 挂载：将 pod 信息生成为文件，直接挂载到容器内部中去</p>
<h5 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h5><p><strong>Role：</strong> Role 是一组权限的集合，例如 Role 可以包含列出 Pod 权限及列出 Deployment 权限，Role 用于给某个 Namespace 中的资源进行鉴权。</p>
<p><strong>RoleBinding：</strong> RoleBinding ：将 Subject 绑定到 Role，RoleBinding 使规则在命名空间内生效。</p>
<h3 id="3-2-2-资源清单"><a href="#3-2-2-资源清单" class="headerlink" title="3.2.2 资源清单"></a>3.2.2 资源清单</h3><p>创建 k8s 的对象都是通过 <a target="_blank" rel="noopener" href="https://yaml.org/">yaml</a> 文件的形式进行配置的。</p>
<h2 id="3-3-对象规约和状态"><a href="#3-3-对象规约和状态" class="headerlink" title="3.3 对象规约和状态"></a>3.3 对象规约和状态</h2><p>对象是用来完成一些任务的，是持久的，是有目的性的，因此 kubernetes 创建一个对象后，将持续地工作以确保对象存在。当然，kubernetes 并不只是维持对象的存在这么简单，kubernetes 还管理着对象的方方面面。每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置，他们分别是 “spec” 和 “status” 。</p>
<h3 id="3-2-1-规约（Spec）"><a href="#3-2-1-规约（Spec）" class="headerlink" title="3.2.1 规约（Spec）"></a>3.2.1 规约（Spec）</h3><p>“spec” 是 “规约”、“规格” 的意思，spec 是必需的，它描述了对象的期望状态（Desired State）—— 希望对象所具有的特征。当创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态，以及关于对象的一些基本信息（例如名称）。</p>
<h3 id="3-2-2-状态（Status）"><a href="#3-2-2-状态（Status）" class="headerlink" title="3.2.2 状态（Status）"></a>3.2.2 状态（Status）</h3><p>表示对象的实际状态，该属性由 k8s 自己维护，k8s 会通过一系列的控制器对对应对象进行管理，让对象尽可能的让实际状态与期望状态重合。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/01/K8S%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/" data-id="clzi1o86l0000687n9saj7lnf" data-title="K8S核心概念" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/1970/01/01/hello-world/" class="article-date">
  <time class="dt-published" datetime="1970-01-01T00:00:00.000Z" itemprop="datePublished">1970-01-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/1970/01/01/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/1970/01/01/hello-world/" data-id="clzgs6wsp0000ul7nfkczevcq" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/k8s/" style="font-size: 10px;">k8s</a> <a href="/tags/kubernetes/" style="font-size: 10px;">kubernetes</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/04/15/K8S%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86/">K8S运维管理</a>
          </li>
        
          <li>
            <a href="/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/">K8S实战进阶</a>
          </li>
        
          <li>
            <a href="/2024/04/01/K8S%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/">K8S核心概念</a>
          </li>
        
          <li>
            <a href="/1970/01/01/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>