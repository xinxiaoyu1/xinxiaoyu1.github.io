<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>K8S实战进阶 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="一、搭建Kubernetes集群1.1 搭建方案1.1.1 minikubeminikube 是一个工具， 能让你在本地运行 Kubernetes。 minikube 在你的个人计算机（包括 Windows、macOS 和 Linux PC）上运行一个一体化（all-in-one）或多节点的本地 Kubernetes 集群，以便你来尝试 Kubernetes 或者开展每天的开发工作。 官方安装文档">
<meta property="og:type" content="article">
<meta property="og:title" content="K8S实战进阶">
<meta property="og:url" content="http://example.com/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="一、搭建Kubernetes集群1.1 搭建方案1.1.1 minikubeminikube 是一个工具， 能让你在本地运行 Kubernetes。 minikube 在你的个人计算机（包括 Windows、macOS 和 Linux PC）上运行一个一体化（all-in-one）或多节点的本地 Kubernetes 集群，以便你来尝试 Kubernetes 或者开展每天的开发工作。 官方安装文档">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_pods_life_cycle.png">
<meta property="article:published_time" content="2024-04-01T05:58:00.000Z">
<meta property="article:modified_time" content="2024-08-06T06:45:09.565Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="k8s">
<meta property="article:tag" content="kubernetes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_pods_life_cycle.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-K8S实战进阶" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/" class="article-date">
  <time class="dt-published" datetime="2024-04-01T05:58:00.000Z" itemprop="datePublished">2024-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      K8S实战进阶
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="一、搭建Kubernetes集群"><a href="#一、搭建Kubernetes集群" class="headerlink" title="一、搭建Kubernetes集群"></a>一、搭建Kubernetes集群</h1><h2 id="1-1-搭建方案"><a href="#1-1-搭建方案" class="headerlink" title="1.1 搭建方案"></a>1.1 搭建方案</h2><h3 id="1-1-1-minikube"><a href="#1-1-1-minikube" class="headerlink" title="1.1.1 minikube"></a>1.1.1 minikube</h3><p><a target="_blank" rel="noopener" href="https://minikube.sigs.k8s.io/">minikube</a> 是一个工具， 能让你在本地运行 Kubernetes。 minikube 在你的个人计算机（包括 Windows、macOS 和 Linux PC）上运行一个一体化（all-in-one）或多节点的本地 Kubernetes 集群，以便你来尝试 Kubernetes 或者开展每天的开发工作。</p>
<p><a target="_blank" rel="noopener" href="https://minikube.sigs.k8s.io/docs/start/">官方安装文档</a></p>
<h3 id="1-1-2-kubeadm"><a href="#1-1-2-kubeadm" class="headerlink" title="1.1.2 kubeadm"></a>1.1.2 kubeadm</h3><p>你可以使用 <a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/">kubeadm</a> 工具来创建和管理 Kubernetes 集群。 该工具能够执行必要的动作并用一种用户友好的方式启动一个可用的、安全的集群。</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">安装 kubeadm</a> 展示了如何安装 kubeadm 的过程。一旦安装了 kubeadm， 你就可以使用它来<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">创建一个集群</a>。</p>
<h4 id="服务器要求"><a href="#服务器要求" class="headerlink" title="服务器要求"></a>服务器要求</h4><p>IP地址：</p>
<ul>
<li>k8s-master：192.168.122.100</li>
<li>k8s-node1：192.168.122.110</li>
<li>k8s-node2：192.168.122.120</li>
</ul>
<p>最低配置：2核、2G内存、20G硬盘</p>
<p>需要联网，不能联网的话需要提供对应镜像的私有仓库</p>
<h4 id="软件环境"><a href="#软件环境" class="headerlink" title="软件环境"></a>软件环境</h4><p>操作系统：Debian 12</p>
<p>Docker版本：Docker version 26.0.0</p>
<p>K8S版本：1.23.17（1.24移除了docker支持）</p>
<h4 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h4><ol>
<li><p>初始操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#关闭防火墙</span><br><span class="line">systemctl stop firewalld    #停止firewalld服务</span><br><span class="line">systemctl disable firewalld    #firewalld禁止自启</span><br><span class="line"></span><br><span class="line">ufw disable    #ufw禁用</span><br><span class="line"></span><br><span class="line">#关闭selinux</span><br><span class="line">sed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config  #永久</span><br><span class="line">setenforce 0    #临时</span><br><span class="line"></span><br><span class="line">#关闭swap（关闭swap后，需要重启主机）</span><br><span class="line">swapoff -a    #临时</span><br><span class="line">sed -ri &#x27;s/.*swap.*/#&amp;/&#x27; /etc/fstab    #永久</span><br><span class="line">free -h    #查看内存</span><br><span class="line"></span><br><span class="line">#根据规划设置主机名</span><br><span class="line">vim /etc/hostname</span><br><span class="line"></span><br><span class="line">#将桥接的IPv4流量传递到iptablesd的链路</span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sysctl --system    #生效</span><br><span class="line"></span><br><span class="line">#时间同步</span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate ntp.aliyun.com</span><br><span class="line"></span><br><span class="line">apt install -y ntp</span><br><span class="line">ntpdate ntp.aliyun.com</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装基础软件（所有节点）</p>
<ol>
<li><p>安装docker</p>
<p><a target="_blank" rel="noopener" href="https://docs.docker.com/engine/">docker安装官方文档</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">#卸载旧版本docker</span><br><span class="line">for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done</span><br><span class="line"></span><br><span class="line">#设置Docker的存储库</span><br><span class="line"># Add Docker&#x27;s official GPG key:</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install ca-certificates curl</span><br><span class="line">sudo install -m 0755 -d /etc/apt/keyrings</span><br><span class="line">sudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc</span><br><span class="line">sudo chmod a+r /etc/apt/keyrings/docker.asc</span><br><span class="line"></span><br><span class="line"># Add the repository to Apt sources:</span><br><span class="line">echo \</span><br><span class="line">  &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \</span><br><span class="line">  $(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;) stable&quot; | \</span><br><span class="line">  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null</span><br><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">#安装Docker包</span><br><span class="line">sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin</span><br><span class="line"></span><br><span class="line">#配置docker镜像加速</span><br><span class="line">sudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://URL.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加阿里云软件源</p>
<p><a target="_blank" rel="noopener" href="https://developer.aliyun.com/mirror/kubernetes">阿里云镜像站安装文档</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#设置kubernetes存储库</span><br><span class="line">apt-get update &amp;&amp; apt-get install -y apt-transport-https</span><br><span class="line"></span><br><span class="line">curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - </span><br><span class="line"></span><br><span class="line"># 排错：</span><br><span class="line"># 执行curl命令报错：curl: (23) Failed writing body</span><br><span class="line"># 解决方案：curl -s -N https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add -</span><br><span class="line"># 执行命令报错：E: gnupg, gnupg2 and gnupg1 do not seem to be installed, but one of them is required for this operation</span><br><span class="line"># 解决方案：apt-get install -y gnupg2</span><br><span class="line"># 弹出警告：Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).（apt-key已弃用）</span><br><span class="line"># 解决方案：建议无视或者curl -s https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo gpg --no-default-keyring --keyring gnupg-ring:/etc/apt/trusted.gpg.d/apt-key.gpg --import</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装kubeadm、kubelet、kubectl</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">#安装kubernetes</span><br><span class="line">apt-get update</span><br><span class="line">apt-cache madison kubelet    #查询版本号</span><br><span class="line">apt-get install -y kubelet=1.23.17-00 kubeadm=1.23.17-00 kubectl=1.23.17-00</span><br><span class="line"></span><br><span class="line">#测试</span><br><span class="line">kubectl version</span><br><span class="line"></span><br><span class="line">#设置开机自启</span><br><span class="line">systemctl enable kubelet.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看docker设备信息</span><br><span class="line">docker info | grep Driver</span><br><span class="line">Cgroup Driver: systemd</span><br><span class="line"></span><br><span class="line"># 如果显示以下信息则需要更改</span><br><span class="line">docker info | grep Driver</span><br><span class="line">Cgroup Driver: cgroupfs</span><br><span class="line"></span><br><span class="line"># 配置关闭 Docker 的 cgroups</span><br><span class="line">vim /etc/docker/daemon.json  加入以下内容</span><br><span class="line">&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line"></span><br><span class="line"># 重启 docker</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>部署Kubernetes Master</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#初始化master节点</span><br><span class="line">kubeadm init \</span><br><span class="line">      --apiserver-advertise-address=192.168.122.100 \</span><br><span class="line">      --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">      --kubernetes-version v1.23.17 \</span><br><span class="line">      --service-cidr=10.96.0.0/12 \</span><br><span class="line">      --pod-network-cidr=10.244.0.0/16</span><br><span class="line">      </span><br><span class="line">#安装成功后，复制如下配置并执行</span><br><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure>
</li>
<li><p>加入Kubernetes Node</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#分别在 k8s-node1 和 k8s-node2 执行</span><br><span class="line">kubeadm join 192.168.122.100:6443 --token 47pvys.orya0t0d8fjcqhwj \</span><br><span class="line">        --discovery-token-ca-cert-hash sha256:314d290d2734a305e4a7220067f38f34dd0f6cdf349b983f09dba99a7843ce6f</span><br><span class="line">        </span><br><span class="line"># 如果初始化的 token 不小心清空了，可以通过如下命令获取或者重新申请</span><br><span class="line"># 如果 token 已经过期，就重新申请</span><br><span class="line">kubeadm token create</span><br><span class="line"></span><br><span class="line"># token 没有过期可以通过如下命令获取</span><br><span class="line">kubeadm token list</span><br><span class="line"></span><br><span class="line"># 获取 --discovery-token-ca-cert-hash 值，得到值后需要在前面拼接上 sha256:</span><br><span class="line">openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | \</span><br><span class="line">openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;</span><br></pre></td></tr></table></figure>
</li>
<li><p>部署CNI网络插件</p>
<p>可选择Flannel、Calico、Canal 和 Weave</p>
<p><a target="_blank" rel="noopener" href="https://github.com/flannel-io/flannel">Flannel官方文档与项目地址</a></p>
<p><a target="_blank" rel="noopener" href="https://docs.tigera.io/">Calico官方文档</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/projectcalico/calico">Calico项目地址</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#在master节点上执行</span><br><span class="line">#下载 calico 配置文件（也可以使用Flannel、Canal和Weave）</span><br><span class="line">curl https://calico-v3-25.netlify.app/archive/v3.25/manifests/calico.yaml -O</span><br><span class="line"></span><br><span class="line"># 修改 calico.yaml 文件中的 CALICO_IPV4POOL_CIDR 配置，修改为与初始化的 cidr 相同（默认注释状态，会使用初始化时指定pod网络状态的配置）</span><br><span class="line"></span><br><span class="line"># Calico默认会拉取docker.io中的镜像，可以删除镜像 docker.io/ 前缀，避免下载过慢导致失败</span><br><span class="line">sed -i &#x27;s#docker.io/##g&#x27; calico.yaml</span><br><span class="line"></span><br><span class="line">#构建Calico网络</span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试Kubernetes集群</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#创建部署</span><br><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line"></span><br><span class="line">#暴露端口</span><br><span class="line">kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line"></span><br><span class="line">#查看 pod 以及服务信息</span><br><span class="line">kubectl get pod,svc</span><br><span class="line"></span><br><span class="line">#宿主机访问测试</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="1-1-3-二进制安装"><a href="#1-1-3-二进制安装" class="headerlink" title="1.1.3 二进制安装"></a>1.1.3 二进制安装</h3><p>利用 k8s 官方 github 仓库下载二进制包安装，安装过程较复杂，但相对较为稳定，推荐生产环境使用。</p>
<h3 id="1-1-4-命令行工具安装"><a href="#1-1-4-命令行工具安装" class="headerlink" title="1.1.4 命令行工具安装"></a>1.1.4 命令行工具安装</h3><h2 id="1-2-命令行工具kubectl"><a href="#1-2-命令行工具kubectl" class="headerlink" title="1.2 命令行工具kubectl"></a>1.2 命令行工具kubectl</h2><p>Kubernetes 提供 kubectl 是使用 Kubernetes API 与 Kubernetes 集群的<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/glossary/?all=true#term-control-plane">控制面</a>进行通信的命令行工具。</p>
<p>这个工具叫做 kubectl。</p>
<p><a target="_blank" rel="noopener" href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands">更多命令</a></p>
<h3 id="1-2-1-命令自动补全"><a href="#1-2-1-命令自动补全" class="headerlink" title="1.2.1 命令自动补全"></a>1.2.1 命令自动补全</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apt install bash-completion</span><br><span class="line"></span><br><span class="line">source /usr/share/bash-completion/bash_completion</span><br><span class="line"></span><br><span class="line">#所有用户自动补全</span><br><span class="line">kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl &gt; /dev/null</span><br><span class="line"></span><br><span class="line">#当前用户自动补全</span><br><span class="line">echo &#x27;source &lt;(kubectl completion bash)&#x27; &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="1-2-2-在任意节点使用kubectl"><a href="#1-2-2-在任意节点使用kubectl" class="headerlink" title="1.2.2 在任意节点使用kubectl"></a>1.2.2 在任意节点使用kubectl</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 1. 将 master 节点中 /etc/kubernetes/admin.conf 拷贝到需要运行的服务器的 /etc/kubernetes 目录中</span><br><span class="line">scp /etc/kubernetes/admin.conf root@k8s-node1:/etc/kubernetes</span><br><span class="line">scp /etc/kubernetes/admin.conf root@k8s-node2:/etc/kubernetes</span><br><span class="line"></span><br><span class="line"># 2. 在对应的服务器上配置环境变量</span><br><span class="line">echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>

<h3 id="1-2-3-资源操作"><a href="#1-2-3-资源操作" class="headerlink" title="1.2.3 资源操作"></a>1.2.3 资源操作</h3><h4 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f ./my-manifest.yaml           # 创建资源</span><br><span class="line">$ kubectl create -f ./my1.yaml -f ./my2.yaml     # 使用多个文件创建资源</span><br><span class="line">$ kubectl create -f ./dir                        # 使用目录下的所有清单文件来创建资源</span><br><span class="line">$ kubectl create -f https://git.io/xxx         # 使用 url 来创建资源</span><br><span class="line">$ kubectl run nginx --image=nginx                # 启动一个 nginx 实例</span><br><span class="line">$ kubectl explain pods,svc                       # 获取 pod 和 svc 的文档</span><br><span class="line"></span><br><span class="line"># 从 stdin 输入中创建多个 YAML 对象</span><br><span class="line">$ cat &lt;&lt;EOF | kubectl create -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox-sleep</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;1000000&quot;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox-sleep-less</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox</span><br><span class="line">    args:</span><br><span class="line">    - sleep</span><br><span class="line">    - &quot;1000&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"># 创建包含几个 key 的 Secret</span><br><span class="line">$ cat &lt;&lt;EOF | kubectl create -f -</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  name: mysecret</span><br><span class="line">type: Opaque</span><br><span class="line">data:</span><br><span class="line">  password: $(echo &quot;s33msi4&quot; | base64)</span><br><span class="line">  username: $(echo &quot;jane&quot; | base64)</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<h4 id="显示和查找资源"><a href="#显示和查找资源" class="headerlink" title="显示和查找资源"></a>显示和查找资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># Get commands with basic output</span><br><span class="line">$ kubectl get services                          # 列出所有 namespace 中的所有 service</span><br><span class="line">$ kubectl get pods --all-namespaces             # 列出所有 namespace 中的所有 pod</span><br><span class="line">$ kubectl get pods -o wide                      # 列出所有 pod 并显示详细信息</span><br><span class="line">$ kubectl get deployment my-dep                 # 列出指定 deployment</span><br><span class="line">$ kubectl get pods --include-uninitialized      # 列出该 namespace 中的所有 pod 包括未初始化的</span><br><span class="line"></span><br><span class="line"># 使用详细输出来描述命令</span><br><span class="line">$ kubectl describe nodes my-node</span><br><span class="line">$ kubectl describe pods my-pod</span><br><span class="line"></span><br><span class="line">$ kubectl get services --sort-by=.metadata.name # List Services Sorted by Name</span><br><span class="line"></span><br><span class="line"># 根据重启次数排序列出 pod</span><br><span class="line">$ kubectl get pods --sort-by=&#x27;.status.containerStatuses[0].restartCount&#x27;</span><br><span class="line"></span><br><span class="line"># 获取所有具有 app=cassandra 的 pod 中的 version 标签</span><br><span class="line">$ kubectl get pods --selector=app=cassandra rc -o \</span><br><span class="line">  jsonpath=&#x27;&#123;.items[*].metadata.labels.version&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># 获取所有节点的 ExternalIP</span><br><span class="line">$ kubectl get nodes -o jsonpath=&#x27;&#123;.items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)].address&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># 列出属于某个 PC 的 Pod 的名字</span><br><span class="line"># “jq”命令用于转换复杂的 jsonpath，参考 https://stedolan.github.io/jq/</span><br><span class="line">$ sel=$&#123;$(kubectl get rc my-rc --output=json | jq -j &#x27;.spec.selector | to_entries | .[] | &quot;\(.key)=\(.value),&quot;&#x27;)%?&#125;</span><br><span class="line">$ echo $(kubectl get pods --selector=$sel --output=jsonpath=&#123;.items..metadata.name&#125;)</span><br><span class="line"></span><br><span class="line"># 查看哪些节点已就绪</span><br><span class="line">$ JSONPATH=&#x27;&#123;range .items[*]&#125;&#123;@.metadata.name&#125;:&#123;range @.status.conditions[*]&#125;&#123;@.type&#125;=&#123;@.status&#125;;&#123;end&#125;&#123;end&#125;&#x27; \</span><br><span class="line"> &amp;&amp; kubectl get nodes -o jsonpath=&quot;$JSONPATH&quot; | grep &quot;Ready=True&quot;</span><br><span class="line"></span><br><span class="line"># 列出当前 Pod 中使用的 Secret</span><br><span class="line">$ kubectl get pods -o json | jq &#x27;.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name&#x27; | grep -v null | sort | uniq</span><br></pre></td></tr></table></figure>

<h4 id="更新资源"><a href="#更新资源" class="headerlink" title="更新资源"></a>更新资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rolling-update frontend-v1 -f frontend-v2.json           # 滚动更新 pod frontend-v1</span><br><span class="line">$ kubectl rolling-update frontend-v1 frontend-v2 --image=image:v2  # 更新资源名称并更新镜像</span><br><span class="line">$ kubectl rolling-update frontend --image=image:v2                 # 更新 frontend pod 中的镜像</span><br><span class="line">$ kubectl rolling-update frontend-v1 frontend-v2 --rollback        # 退出已存在的进行中的滚动更新</span><br><span class="line">$ cat pod.json | kubectl replace -f -                              # 基于 stdin 输入的 JSON 替换 pod</span><br><span class="line"></span><br><span class="line"># 强制替换，删除后重新创建资源。会导致服务中断。</span><br><span class="line">$ kubectl replace --force -f ./pod.json</span><br><span class="line"></span><br><span class="line"># 为 nginx RC 创建服务，启用本地 80 端口连接到容器上的 8000 端口</span><br><span class="line">$ kubectl expose rc nginx --port=80 --target-port=8000</span><br><span class="line"></span><br><span class="line"># 更新单容器 pod 的镜像版本（tag）到 v4</span><br><span class="line">$ kubectl get pod mypod -o yaml | sed &#x27;s/\(image: myimage\):.*$/\1:v4/&#x27; | kubectl replace -f -</span><br><span class="line"></span><br><span class="line">$ kubectl label pods my-pod new-label=awesome                      # 添加标签</span><br><span class="line">$ kubectl annotate pods my-pod icon-url=http://goo.gl/XXBTWq       # 添加注解</span><br><span class="line">$ kubectl autoscale deployment foo --min=2 --max=10                # 自动扩展 deployment “foo”</span><br></pre></td></tr></table></figure>

<h4 id="修补资源"><a href="#修补资源" class="headerlink" title="修补资源"></a>修补资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl patch node k8s-node-1 -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;unschedulable&quot;:true&#125;&#125;&#x27; # 部分更新节点</span><br><span class="line"></span><br><span class="line"># 更新容器镜像； spec.containers[*].name 是必须的，因为这是合并的关键字</span><br><span class="line">$ kubectl patch pod valid-pod -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;containers&quot;:[&#123;&quot;name&quot;:&quot;kubernetes-serve-hostname&quot;,&quot;image&quot;:&quot;new image&quot;&#125;]&#125;&#125;&#x27;</span><br><span class="line"></span><br><span class="line"># 使用具有位置数组的 json 补丁更新容器镜像</span><br><span class="line">$ kubectl patch pod valid-pod --type=&#x27;json&#x27; -p=&#x27;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/containers/0/image&quot;, &quot;value&quot;:&quot;new image&quot;&#125;]&#x27;</span><br><span class="line"></span><br><span class="line"># 使用具有位置数组的 json 补丁禁用 deployment 的 livenessProbe</span><br><span class="line">$ kubectl patch deployment valid-deployment  --type json   -p=&#x27;[&#123;&quot;op&quot;: &quot;remove&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/livenessProbe&quot;&#125;]&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="编辑资源"><a href="#编辑资源" class="headerlink" title="编辑资源"></a>编辑资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl edit svc/docker-registry                      # 编辑名为 docker-registry 的 service</span><br><span class="line">$ KUBE_EDITOR=&quot;nano&quot; kubectl edit svc/docker-registry   # 使用其它编辑器</span><br></pre></td></tr></table></figure>

<h4 id="scale资源"><a href="#scale资源" class="headerlink" title="scale资源"></a>scale资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale --replicas=3 rs/foo                                 # Scale a replicaset named &#x27;foo&#x27; to 3</span><br><span class="line">$ kubectl scale --replicas=3 -f foo.yaml                            # Scale a resource specified in &quot;foo.yaml&quot; to 3</span><br><span class="line">$ kubectl scale --current-replicas=2 --replicas=3 deployment/mysql  # If the deployment named mysql&#x27;s current size is 2, scale mysql to 3</span><br><span class="line">$ kubectl scale --replicas=5 rc/foo rc/bar rc/baz                   # Scale multiple replication controllers</span><br></pre></td></tr></table></figure>

<h4 id="删除资源"><a href="#删除资源" class="headerlink" title="删除资源"></a>删除资源</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl scale --replicas=3 rs/foo                                 # Scale a replicaset named &#x27;foo&#x27; to 3</span><br><span class="line">$ kubectl scale --replicas=3 -f foo.yaml                            # Scale a resource specified in &quot;foo.yaml&quot; to 3</span><br><span class="line">$ kubectl scale --current-replicas=2 --replicas=3 deployment/mysql  # If the deployment named mysql&#x27;s current size is 2, scale mysql to 3</span><br><span class="line">$ kubectl scale --replicas=5 rc/foo rc/bar rc/baz                   # Scale multiple replication controllers</span><br></pre></td></tr></table></figure>

<h3 id="1-2-4-Pod与集群"><a href="#1-2-4-Pod与集群" class="headerlink" title="1.2.4 Pod与集群"></a>1.2.4 Pod与集群</h3><h4 id="与运行的Pod交互"><a href="#与运行的Pod交互" class="headerlink" title="与运行的Pod交互"></a>与运行的Pod交互</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl logs my-pod                                 # dump 输出 pod 的日志（stdout）</span><br><span class="line">$ kubectl logs my-pod -c my-container                 # dump 输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用）</span><br><span class="line">$ kubectl logs -f my-pod                              # 流式输出 pod 的日志（stdout）</span><br><span class="line">$ kubectl logs -f my-pod -c my-container              # 流式输出 pod 中容器的日志（stdout，pod 中有多个容器的情况下使用）</span><br><span class="line">$ kubectl run -i --tty busybox --image=busybox -- sh  # 交互式 shell 的方式运行 pod</span><br><span class="line">$ kubectl attach my-pod -i                            # 连接到运行中的容器</span><br><span class="line">$ kubectl port-forward my-pod 5000:6000               # 转发 pod 中的 6000 端口到本地的 5000 端口</span><br><span class="line">$ kubectl exec my-pod -- ls /                         # 在已存在的容器中执行命令（只有一个容器的情况下）</span><br><span class="line">$ kubectl exec my-pod -c my-container -- ls /         # 在已存在的容器中执行命令（pod 中有多个容器的情况下）</span><br><span class="line">$ kubectl top pod POD_NAME --containers               # 显示指定 pod 和容器的指标度量</span><br></pre></td></tr></table></figure>

<h4 id="与节点和集群交互"><a href="#与节点和集群交互" class="headerlink" title="与节点和集群交互"></a>与节点和集群交互</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl cordon my-node                                                # 标记 my-node 不可调度</span><br><span class="line">$ kubectl drain my-node                                                 # 清空 my-node 以待维护</span><br><span class="line">$ kubectl uncordon my-node                                              # 标记 my-node 可调度</span><br><span class="line">$ kubectl top node my-node                                              # 显示 my-node 的指标度量</span><br><span class="line">$ kubectl cluster-info                                                  # 显示 master 和服务的地址</span><br><span class="line">$ kubectl cluster-info dump                                             # 将当前集群状态输出到 stdout                                    </span><br><span class="line">$ kubectl cluster-info dump --output-directory=/path/to/cluster-state   # 将当前集群状态输出到 /path/to/cluster-state</span><br><span class="line"></span><br><span class="line"># 如果该键和影响的污点（taint）已存在，则使用指定的值替换</span><br><span class="line">$ kubectl taint nodes foo dedicated=special-user:NoSchedule</span><br></pre></td></tr></table></figure>

<h3 id="1-2-5-资源类型与别名"><a href="#1-2-5-资源类型与别名" class="headerlink" title="1.2.5 资源类型与别名"></a>1.2.5 资源类型与别名</h3><table>
<thead>
<tr>
<th>资源类型</th>
<th>缩写别名</th>
</tr>
</thead>
<tbody><tr>
<td><code>clusters</code></td>
<td></td>
</tr>
<tr>
<td><code>componentstatuses</code></td>
<td><code>cs</code></td>
</tr>
<tr>
<td><code>configmaps</code></td>
<td><code>cm</code></td>
</tr>
<tr>
<td><code>daemonsets</code></td>
<td><code>ds</code></td>
</tr>
<tr>
<td><code>deployments</code></td>
<td><code>deploy</code></td>
</tr>
<tr>
<td><code>endpoints</code></td>
<td><code>ep</code></td>
</tr>
<tr>
<td><code>event</code></td>
<td><code>ev</code></td>
</tr>
<tr>
<td><code>horizontalpodautoscalers</code></td>
<td><code>hpa</code></td>
</tr>
<tr>
<td><code>ingresses</code></td>
<td><code>ing</code></td>
</tr>
<tr>
<td><code>jobs</code></td>
<td></td>
</tr>
<tr>
<td><code>limitranges</code></td>
<td><code>limits</code></td>
</tr>
<tr>
<td><code>namespaces</code></td>
<td><code>ns</code></td>
</tr>
<tr>
<td><code>networkpolicies</code></td>
<td></td>
</tr>
<tr>
<td><code>nodes</code></td>
<td><code>no</code></td>
</tr>
<tr>
<td><code>statefulsets</code></td>
<td></td>
</tr>
<tr>
<td><code>persistentvolumeclaims</code></td>
<td><code>pvc</code></td>
</tr>
<tr>
<td><code>persistentvolumes</code></td>
<td><code>pv</code></td>
</tr>
<tr>
<td><code>pods</code></td>
<td><code>po</code></td>
</tr>
<tr>
<td><code>podsecuritypolicies</code></td>
<td><code>psp</code></td>
</tr>
<tr>
<td><code>podtemplates</code></td>
<td></td>
</tr>
<tr>
<td><code>replicasets</code></td>
<td><code>rs</code></td>
</tr>
<tr>
<td><code>replicationcontrollers</code></td>
<td><code>rc</code></td>
</tr>
<tr>
<td><code>resourcequotas</code></td>
<td><code>quota</code></td>
</tr>
<tr>
<td><code>cronjob</code></td>
<td></td>
</tr>
<tr>
<td><code>secrets</code></td>
<td></td>
</tr>
<tr>
<td><code>serviceaccount</code></td>
<td><code>sa</code></td>
</tr>
<tr>
<td><code>services</code></td>
<td><code>svc</code></td>
</tr>
<tr>
<td><code>storageclasses</code></td>
<td></td>
</tr>
<tr>
<td><code>thirdpartyresources</code></td>
<td></td>
</tr>
</tbody></table>
<h3 id="1-2-6-格式化输出"><a href="#1-2-6-格式化输出" class="headerlink" title="1.2.6 格式化输出"></a>1.2.6 格式化输出</h3><ul>
<li>输出json格式：-o json</li>
<li>仅打印资源名称：-o name</li>
<li>以纯文本格式输出所有信息：-o wide</li>
<li>输出yaml格式：-o yaml</li>
</ul>
<h2 id="1-3-API概述"><a href="#1-3-API概述" class="headerlink" title="1.3 API概述"></a>1.3 API概述</h2><p>官网文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/using-api/">https://kubernetes.io/zh-cn/docs/reference/using-api/</a></p>
<p>REST API 是 Kubernetes 系统的重要部分，组件之间的所有操作和通信均由 API Server 处理的 REST AP I调用，大多数情况下， API 定义和实现都符合标准的 HTTP REST 格式，可以通过 <a target="_blank" rel="noopener" href="http://docs.kubernetes.org.cn/61.html">kubectl</a> 命令管理工具或其他命令行工具来执行。</p>
<h3 id="1-3-1-类型"><a href="#1-3-1-类型" class="headerlink" title="1.3.1 类型"></a>1.3.1 类型</h3><h4 id="Alpha"><a href="#Alpha" class="headerlink" title="Alpha"></a>Alpha</h4><ul>
<li>包含 alpha 名称的版本（例如v1alpha1）。</li>
<li>该软件可能包含错误。启用一个功能可能会导致 bug。默认情况下，功能可能会被禁用。</li>
<li>随时可能会丢弃对该功能的支持，恕不另行通知。</li>
<li>API 可能在以后的软件版本中以不兼容的方式更改，恕不另行通知。</li>
<li>该软件建议仅在短期测试集群中使用，因为错误的风险增加和缺乏长期支持。</li>
</ul>
<h4 id="Beta"><a href="#Beta" class="headerlink" title="Beta"></a>Beta</h4><ul>
<li>包含 <strong>beta</strong> 名称的版本（例如 <strong>v2beta3</strong> ）。</li>
<li>该软件经过很好的测试。启用功能被认为是安全的。默认情况下功能是开启的。</li>
<li>细节可能会改变，但功能在后续版本不会被删除</li>
<li>对象的模式或语义在随后的 beta 版本或 Stable 版本中可能以不兼容的方式发生变化。如果这种情况发生时，官方会提供迁移操作指南。这可能需要删除、编辑和重新创建API对象。</li>
<li>该版本在后续可能会更改一些不兼容地方，所以建议用于非关键业务，如果你有多个可以独立升级的集群，你也可以放宽此限制。</li>
<li><strong>大家使用过的 Beta 版本后，可以多给社区反馈，如果此版本在后续更新后将不会有太大变化。</strong></li>
</ul>
<h4 id="Stable"><a href="#Stable" class="headerlink" title="Stable"></a>Stable</h4><ul>
<li>该版本名称命名方式：<strong>vX</strong> 这里 <strong>X</strong> 是一个整数。</li>
<li>Stable 版本的功能特性，将出现在后续发布的软件版本中。</li>
</ul>
<h3 id="1-3-2-访问控制"><a href="#1-3-2-访问控制" class="headerlink" title="1.3.2 访问控制"></a>1.3.2 访问控制</h3><h4 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h4><h4 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h4><h3 id="1-3-3-废弃api说明"><a href="#1-3-3-废弃api说明" class="headerlink" title="1.3.3 废弃api说明"></a>1.3.3 废弃api说明</h3><p><a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/reference/using-api/deprecation-guide/">https://kubernetes.io/zh-cn/docs/reference/using-api/deprecation-guide/</a></p>
<h1 id="二、深入pod"><a href="#二、深入pod" class="headerlink" title="二、深入pod"></a>二、深入pod</h1><h2 id="2-1-Pod配置文件"><a href="#2-1-Pod配置文件" class="headerlink" title="2.1 Pod配置文件"></a>2.1 Pod配置文件</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1 # api 文档版本</span><br><span class="line">kind: Pod  # 资源对象类型，也可以配置为像Deployment、StatefulSet这一类的对象</span><br><span class="line">metadata: # Pod 相关的元数据，用于描述 Pod 的数据</span><br><span class="line">  name: nginx-demo # Pod 的名称</span><br><span class="line">  labels: # 定义 Pod 的标签</span><br><span class="line">    type: app # 自定义 label 标签，名字为 type，值为 app</span><br><span class="line">    test: 1.0.0 # 自定义 label 标签，描述 Pod 版本号</span><br><span class="line">  namespace: &#x27;default&#x27; # 命名空间的配置</span><br><span class="line">spec: # 期望 Pod 按照这里面的描述进行创建</span><br><span class="line">  containers: # 对于 Pod 中的容器描述</span><br><span class="line">  - name: nginx # 容器的名称</span><br><span class="line">    image: nginx:1.7.9 # 指定容器的镜像</span><br><span class="line">    imagePullPolicy: IfNotPresent # 镜像拉取策略，指定如果本地有就用本地的，如果没有就拉取远程的</span><br><span class="line">    command: # 指定容器启动时执行的命令</span><br><span class="line">    - nginx</span><br><span class="line">    - -g</span><br><span class="line">    - &#x27;daemon off;&#x27; # nginx -g &#x27;daemon off;&#x27;</span><br><span class="line">    workingDir: /usr/share/nginx/html # 定义容器启动后的工作目录</span><br><span class="line">    ports:</span><br><span class="line">    - name: http # 端口名称</span><br><span class="line">      containerPort: 80 # 描述容器内要暴露什么端口</span><br><span class="line">      protocol: TCP # 描述该端口是基于哪种协议通信的</span><br><span class="line">    - env: # 环境变量</span><br><span class="line">      name: JVM_OPTS # 环境变量名称</span><br><span class="line">      value: &#x27;-Xms128m -Xmx128m&#x27; # 环境变量的值</span><br><span class="line">    reousrces:</span><br><span class="line">      requests: # 最少需要多少资源</span><br><span class="line">        cpu: 100m # 限制 cpu 最少使用 0.1 个核心</span><br><span class="line">        memory: 128Mi # 限制内存最少使用 128兆</span><br><span class="line">      limits: # 最多可以用多少资源</span><br><span class="line">        cpu: 200m # 限制 cpu 最多使用 0.2 个核心</span><br><span class="line">        memory: 256Mi # 限制 最多使用 256兆</span><br><span class="line">  restartPolicy: OnFailure # 重启策略，只有失败的情况才会重启</span><br></pre></td></tr></table></figure>

<h2 id="2-2-探针"><a href="#2-2-探针" class="headerlink" title="2.2 探针"></a>2.2 探针</h2><h3 id="2-2-1-类型"><a href="#2-2-1-类型" class="headerlink" title="2.2.1 类型"></a>2.2.1 类型</h3><h4 id="StartupProbe"><a href="#StartupProbe" class="headerlink" title="StartupProbe"></a>StartupProbe</h4><p>k8s 1.16 版本新增的探针，用于判断应用程序是否已经启动了。</p>
<p>当配置了 startupProbe 后，会先禁用其他探针，直到 startupProbe 成功后，其他探针才会继续。</p>
<p>作用：由于有时候不能准确预估应用一定是多长时间启动成功，因此配置另外两种方式不方便配置初始化时长来检测，而配置了 statupProbe 后，只有在应用启动成功了，才会执行另外两种探针，可以更加方便的结合使用另外两种探针使用。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">startupProbe: # 应用启动探针配置</span><br><span class="line">  httpGet: # 探测方式，基于 http 请求探测</span><br><span class="line">    path: /api/startup # http请求路径</span><br><span class="line">    port: 80 # 请求端口</span><br></pre></td></tr></table></figure>

<h4 id="LivenessProbe"><a href="#LivenessProbe" class="headerlink" title="LivenessProbe"></a>LivenessProbe</h4><p>用于探测容器中的应用是否运行，如果探测失败，kubelet 会根据配置的重启策略进行重启，若没有配置，默认就认为容器启动成功，不会执行重启策略。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  failureThreshold: 5</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /health</span><br><span class="line">    port: 8080</span><br><span class="line">    scheme: HTTP</span><br><span class="line">  initialDelaySeconds: 60</span><br><span class="line">  periodSeconds: 10</span><br><span class="line">  successThreshold: 1</span><br><span class="line">  timeoutSeconds: 5</span><br></pre></td></tr></table></figure>

<h4 id="ReadinessProbe"><a href="#ReadinessProbe" class="headerlink" title="ReadinessProbe"></a>ReadinessProbe</h4><p>用于探测容器内的程序是否健康，它的返回值如果返回 success，那么就认为该容器已经完全启动，并且该容器是可以接收外部流量的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">readinessProbe:</span><br><span class="line">  failureThreshold: 3 # 失败多少次才算真正失败</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /ready</span><br><span class="line">    port: 8181</span><br><span class="line">    scheme: HTTP</span><br><span class="line">  periodSeconds: 10 # 间隔时间</span><br><span class="line">  successThreshold: 1 # 多少次监测成功算成功</span><br><span class="line">  timeoutSeconds: 1 # 请求的超时时间</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2探测方式"><a href="#2-2-2探测方式" class="headerlink" title="2.2.2探测方式"></a>2.2.2探测方式</h3><h4 id="ExecAction"><a href="#ExecAction" class="headerlink" title="ExecAction"></a>ExecAction</h4><p>在容器内部执行一个命令，如果返回值为 0，则任务容器时健康的。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  exec:</span><br><span class="line">    command:</span><br><span class="line">      - cat</span><br><span class="line">      - /health</span><br></pre></td></tr></table></figure>

<h4 id="TCPSocketAction"><a href="#TCPSocketAction" class="headerlink" title="TCPSocketAction"></a>TCPSocketAction</h4><p>通过 tcp 连接监测容器内端口是否开放，如果开放则证明该容器健康</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  tcpSocket:</span><br><span class="line">    port: 80</span><br></pre></td></tr></table></figure>

<h4 id="HTTPGetAction"><a href="#HTTPGetAction" class="headerlink" title="HTTPGetAction"></a>HTTPGetAction</h4><p>生产环境用的较多的方式，发送 HTTP 请求到容器内的应用程序，如果接口返回的状态码在 200~400 之间，则认为容器健康。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">livenessProbe:</span><br><span class="line">  failureThreshold: 5</span><br><span class="line">  httpGet:</span><br><span class="line">    path: /health</span><br><span class="line">    port: 8080</span><br><span class="line">    scheme: HTTP</span><br><span class="line">    httpHeaders:</span><br><span class="line">      - name: xxx</span><br><span class="line">        value: xxx</span><br></pre></td></tr></table></figure>

<h3 id="2-2-3-参数配置"><a href="#2-2-3-参数配置" class="headerlink" title="2.2.3 参数配置"></a>2.2.3 参数配置</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">initialDelaySeconds: 60 # 初始化时间</span><br><span class="line">timeoutSeconds: 2 # 超时时间</span><br><span class="line">periodSeconds: 5 # 监测间隔时间</span><br><span class="line">successThreshold: 1 # 检查 1 次成功就表示成功</span><br><span class="line">failureThreshold: 2 # 监测失败 2 次就表示失败</span><br></pre></td></tr></table></figure>

<h2 id="2-3-生命周期"><a href="#2-3-生命周期" class="headerlink" title="2.3 生命周期"></a>2.3 生命周期</h2><p><img src="https://raw.githubusercontent.com/xinxiaoyu1/images/main/Technical/Kubernetes/20240806_pods_life_cycle.png" alt="pod的生命周期"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">lifecycle:</span><br><span class="line">  postStart: # 容创建完成后执行的动作，不能保证该操作一定在容器的 command 之前执行，一般不使用</span><br><span class="line">    exec: # 可以是 exec / httpGet / tcpSocket</span><br><span class="line">      command:</span><br><span class="line">        - sh</span><br><span class="line">        - -c</span><br><span class="line">        - &#x27;mkdir /data&#x27;</span><br><span class="line">  preStop: # 在容器停止前执行的动作</span><br><span class="line">    httpGet: # 发送一个 http 请求</span><br><span class="line">      path: /</span><br><span class="line">      port: 80</span><br><span class="line">    exec: # 执行一个命令</span><br><span class="line">      command:</span><br><span class="line">        - sh</span><br><span class="line">        - -c</span><br><span class="line">        - sleep 9</span><br></pre></td></tr></table></figure>

<h3 id="2-3-1-Pod退出流程"><a href="#2-3-1-Pod退出流程" class="headerlink" title="2.3.1 Pod退出流程"></a>2.3.1 Pod退出流程</h3><h4 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h4><ol>
<li><p>Endpoint删除pod的ip地址</p>
</li>
<li><p>Pod变成Terminating状态</p>
<p>变为删除中的状态后，会给 pod 一个宽限期，让 pod 去执行一些清理或销毁操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">配置参数：</span><br><span class="line"></span><br><span class="line"># 作用与 pod 中的所有容器</span><br><span class="line">terminationGracePeriodSeconds: 30</span><br><span class="line">containers:</span><br><span class="line">  - xxx</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行perStop的指令</p>
</li>
</ol>
<h3 id="2-3-2-PreStop的应用"><a href="#2-3-2-PreStop的应用" class="headerlink" title="2.3.2 PreStop的应用"></a>2.3.2 PreStop的应用</h3><p>如果应用销毁操作耗时需要比较长，可以在 preStop 按照如下方式进行配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">preStop:</span><br><span class="line">  exec:</span><br><span class="line">    command:</span><br><span class="line">      - sh</span><br><span class="line">      - -c</span><br><span class="line">      - &#x27;sleep 20; kill pgrep java&#x27;</span><br></pre></td></tr></table></figure>

<p>但是需要注意，由于 k8s 默认给 pod 的停止宽限时间为 30s，如果我们停止操作会超过 30s 时，不要光设置 sleep 50，还要将 terminationGracePeriodSeconds: 30 也更新成更长的时间，否则 k8s 最多只会在这个时间的基础上再宽限几秒，不会真正等待 50s</p>
<p><strong>注册中心下线</strong></p>
<p><strong>数据清理</strong></p>
<p><strong>数据销毁</strong></p>
<h1 id="三、资源调度"><a href="#三、资源调度" class="headerlink" title="三、资源调度"></a>三、资源调度</h1><h2 id="3-1-Label和Slelctor"><a href="#3-1-Label和Slelctor" class="headerlink" title="3.1 Label和Slelctor"></a>3.1 Label和Slelctor</h2><h3 id="3-1-1-标签（Label）"><a href="#3-1-1-标签（Label）" class="headerlink" title="3.1.1 标签（Label）"></a>3.1.1 标签（Label）</h3><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>在各类资源的 <code>metadata.labels</code> 中进行配置</p>
<h4 id="kubectl"><a href="#kubectl" class="headerlink" title="kubectl"></a>kubectl</h4><p>临时创建label：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label po &lt;资源名称&gt; app=hello -n namespace</span><br></pre></td></tr></table></figure>

<p>修改已经存在的标签：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label po &lt;资源名称&gt; app=hello2 --overwrite</span><br></pre></td></tr></table></figure>

<p>查看label：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># selector 按照 label 单值查找节点</span><br><span class="line">kubectl get po -A -l app=hello</span><br><span class="line"></span><br><span class="line"># 查看所有节点的 labels</span><br><span class="line">kubectl get po --show-labels</span><br></pre></td></tr></table></figure>

<h3 id="3-1-2-选择器（Selector）"><a href="#3-1-2-选择器（Selector）" class="headerlink" title="3.1.2 选择器（Selector）"></a>3.1.2 选择器（Selector）</h3><h4 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h4><p>在各对象的配置 <code>spec.selector</code> 或其他可以写 <code>selector</code> 的属性中编写</p>
<h4 id="kubectl-1"><a href="#kubectl-1" class="headerlink" title="kubectl"></a>kubectl</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 匹配单个值，查找 app=hello 的 pod</span><br><span class="line">kubectl get po -A -l app=hello</span><br><span class="line"></span><br><span class="line"># 匹配多个值</span><br><span class="line">kubectl get po -A -l &#x27;k8s-app in (metrics-server, kubernetes-dashboard)&#x27;</span><br><span class="line">或 </span><br><span class="line"></span><br><span class="line"># 查找 version!=1 and app=nginx 的 pod 信息</span><br><span class="line">kubectl get po -l version!=1,app=nginx</span><br><span class="line"></span><br><span class="line"># 不等值 + 语句</span><br><span class="line">kubectl get po -A -l version!=1,&#x27;app in (busybox, nginx)&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-Deployment"><a href="#3-2-Deployment" class="headerlink" title="3.2 Deployment"></a>3.2 Deployment</h2><h3 id="3-2-1-功能"><a href="#3-2-1-功能" class="headerlink" title="3.2.1 功能"></a>3.2.1 功能</h3><h4 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">创建一个 deployment</span><br><span class="line">kubectl create deploy nginx-deploy --image=nginx:1.7.9</span><br><span class="line"></span><br><span class="line">或执行</span><br><span class="line">kubectl create -f xxx.yaml --record</span><br><span class="line">--record 会在 annotation 中记录当前命令创建或升级了资源，后续可以查看做过哪些变动操作。</span><br><span class="line"></span><br><span class="line">将创建的 deployment 以 yaml 的格式输出</span><br><span class="line">kubectl get deploy nginx-deploy -o yaml</span><br><span class="line"></span><br><span class="line">查看部署信息</span><br><span class="line">kubectl get deployments</span><br><span class="line"></span><br><span class="line">查看 rs</span><br><span class="line">kubectl get rs</span><br><span class="line"></span><br><span class="line">查看 pod 以及展示标签，可以看到是关联的那个 rs</span><br><span class="line">kubectl get pods --show-labels</span><br></pre></td></tr></table></figure>

<h4 id="滚动更新"><a href="#滚动更新" class="headerlink" title="滚动更新"></a>滚动更新</h4><p>只有修改了 deployment 配置文件中的 template 中的属性后，才会触发更新操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">修改 nginx 版本号</span><br><span class="line">kubectl set image deployment/nginx-deployment nginx=nginx:1.9.1</span><br><span class="line"></span><br><span class="line">或者通过 kubectl edit deployment/nginx-deployment 进行修改</span><br><span class="line"></span><br><span class="line">查看滚动更新的过程</span><br><span class="line">kubectl rollout status deploy &lt;deployment_name&gt;</span><br><span class="line"></span><br><span class="line">查看部署描述，最后展示发生的事件列表也可以看到滚动更新过程</span><br><span class="line">kubectl describe deploy &lt;deployment_name&gt;</span><br><span class="line"></span><br><span class="line">通过 kubectl get deployments 获取部署信息，UP-TO-DATE 表示已经有多少副本达到了配置中要求的数目</span><br><span class="line"></span><br><span class="line">通过 kubectl get rs 可以看到增加了一个新的 rs</span><br><span class="line"></span><br><span class="line">通过 kubectl get pods 可以看到所有 pod 关联的 rs 变成了新的</span><br></pre></td></tr></table></figure>

<p><strong>多个滚动更新并行</strong></p>
<p>假设当前有 5 个 nginx:1.7.9 版本，你想将版本更新为 1.9.1，当更新成功第三个以后，你马上又将期望更新的版本改为 1.9.2，那么此时会立马删除之前的三个，并且立马开启更新 1.9.2 的任务</p>
<h4 id="回滚"><a href="#回滚" class="headerlink" title="回滚"></a>回滚</h4><p>有时候你可能想回退一个Deployment，例如，当Deployment不稳定时，比如一直crash looping。</p>
<p>默认情况下，kubernetes会在系统中保存前两次的Deployment的rollout历史记录，以便你可以随时会退（你可以修改revision history limit来更改保存的revision数）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">案例：</span><br><span class="line">更新 deployment 时参数不小心写错，如 nginx:1.9.1 写成了 nginx:1.91</span><br><span class="line">kubectl set image deployment/nginx-deploy nginx=nginx:1.91</span><br><span class="line"></span><br><span class="line">监控滚动升级状态，由于镜像名称错误，下载镜像失败，因此更新过程会卡住</span><br><span class="line">kubectl rollout status deployments nginx-deploy</span><br><span class="line"></span><br><span class="line">结束监听后，获取 rs 信息，我们可以看到新增的 rs 副本数是 2 个</span><br><span class="line">kubectl get rs</span><br><span class="line"></span><br><span class="line">通过 kubectl get pods 获取 pods 信息，我们可以看到关联到新的 rs 的 pod，状态处于 ImagePullBackOff 状态</span><br><span class="line"></span><br><span class="line">为了修复这个问题，我们需要找到需要回退的 revision 进行回退</span><br><span class="line">通过 kubectl rollout history deployment/nginx-deploy 可以获取 revison 的列表</span><br><span class="line"></span><br><span class="line">通过 kubectl rollout history deployment/nginx-deploy --revision=2 可以查看详细信息</span><br><span class="line"></span><br><span class="line">确认要回退的版本后，可以通过 kubectl rollout undo deployment/nginx-deploy 可以回退到上一个版本</span><br><span class="line"></span><br><span class="line">也可以回退到指定的 revision</span><br><span class="line">kubectl rollout undo deployment/nginx-deploy --to-revision=2</span><br><span class="line"></span><br><span class="line">再次通过 kubectl get deployment 和 kubectl describe deployment 可以看到，我们的版本已经回退到对应的 revison 上了</span><br><span class="line"></span><br><span class="line">可以通过设置 .spec.revisonHistoryLimit 来指定 deployment 保留多少 revison，如果设置为 0，则不允许 deployment 回退了。</span><br></pre></td></tr></table></figure>

<h4 id="扩容缩容"><a href="#扩容缩容" class="headerlink" title="扩容缩容"></a>扩容缩容</h4><p>通过 kube scale 命令可以进行自动扩容&#x2F;缩容，以及通过 kube edit 编辑 replcas 也可以实现扩容&#x2F;缩容</p>
<p>扩容与缩容只是直接创建副本数，没有更新 pod template 因此不会创建新的 rs</p>
<h4 id="暂停与恢复"><a href="#暂停与恢复" class="headerlink" title="暂停与恢复"></a>暂停与恢复</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">由于每次对 pod template 中的信息发生修改后，都会触发更新 deployment 操作，那么此时如果频繁修改信息，就会产生多次更新，而实际上只需要执行最后一次更新即可，当出现此类情况时我们就可以暂停 deployment 的 rollout</span><br><span class="line"></span><br><span class="line">通过 kubectl rollout pause deployment &lt;name&gt; 就可以实现暂停，直到你下次恢复后才会继续进行滚动更新</span><br><span class="line"></span><br><span class="line">尝试对容器进行修改，然后查看是否发生更新操作了</span><br><span class="line">kubectl set image deploy &lt;name&gt; nginx=nginx:1.17.9</span><br><span class="line">kubectl get po </span><br><span class="line"></span><br><span class="line">通过以上操作可以看到实际并没有发生修改，此时我们再次进行修改一些属性，如限制 nginx 容器的最大cpu为 0.2 核，最大内存为 128M，最小内存为 64M，最小 cpu 为 0.1 核</span><br><span class="line">kubectl set resources deploy &lt;deploy_name&gt; -c &lt;container_name&gt; --limits=cpu=200m,memory=128Mi --requests=cpu100m,memory=64Mi</span><br><span class="line"></span><br><span class="line">通过格式化输出 kubectl get deploy &lt;name&gt; -oyaml，可以看到配置确实发生了修改，再通过 kubectl get po 可以看到 pod 没有被更新</span><br><span class="line"></span><br><span class="line">那么此时我们再恢复 rollout，通过命令 kubectl rollout deploy &lt;name&gt;</span><br><span class="line"></span><br><span class="line">恢复后，我们再次查看 rs 和 po 信息，我们可以看到就开始进行滚动更新操作了</span><br><span class="line">kubectl get rs</span><br><span class="line">kubectl get po</span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-配置文件"><a href="#3-2-2-配置文件" class="headerlink" title="3.2.2 配置文件"></a>3.2.2 配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1 # deployment api 版本</span><br><span class="line">kind: Deployment # 资源类型为 deployment</span><br><span class="line">metadata: # 元信息</span><br><span class="line">  labels: # 标签</span><br><span class="line">    app: nginx-deploy # 具体的 key: value 配置形式</span><br><span class="line">  name: nginx-deploy # deployment 的名字</span><br><span class="line">  namespace: default # 所在的命名空间</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1 # 期望副本数</span><br><span class="line">  revisionHistoryLimit: 10 # 进行滚动更新后，保留的历史版本数</span><br><span class="line">  selector: # 选择器，用于找到匹配的 RS</span><br><span class="line">    matchLabels: # 按照标签匹配</span><br><span class="line">      app: nginx-deploy # 匹配的标签key/value</span><br><span class="line">  strategy: # 更新策略</span><br><span class="line">    rollingUpdate: # 滚动更新配置</span><br><span class="line">      maxSurge: 25% # 进行滚动更新时，更新的个数最多可以超过期望副本数的个数/比例</span><br><span class="line">      maxUnavailable: 25% # 进行滚动更新时，最大不可用比例更新比例，表示在所有副本数中，最多可以有多少个不更新成功</span><br><span class="line">    type: RollingUpdate # 更新类型，采用滚动更新</span><br><span class="line">  template: # pod 模板</span><br><span class="line">    metadata: # pod 的元信息</span><br><span class="line">      labels: # pod 的标签</span><br><span class="line">        app: nginx-deploy</span><br><span class="line">    spec: # pod 期望信息</span><br><span class="line">      containers: # pod 的容器</span><br><span class="line">      - image: nginx:1.7.9 # 镜像</span><br><span class="line">        imagePullPolicy: IfNotPresent # 拉取策略</span><br><span class="line">        name: nginx # 容器名称</span><br><span class="line">      restartPolicy: Always # 重启策略</span><br><span class="line">      terminationGracePeriodSeconds: 30 # 删除操作最多宽限多长时间</span><br></pre></td></tr></table></figure>

<h2 id="3-3-StatefulSet"><a href="#3-3-StatefulSet" class="headerlink" title="3.3 StatefulSet"></a>3.3 StatefulSet</h2><h3 id="3-3-1-功能"><a href="#3-3-1-功能" class="headerlink" title="3.3.1 功能"></a>3.3.1 功能</h3><h4 id="创建-1"><a href="#创建-1" class="headerlink" title="创建"></a>创建</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f web.yaml</span><br><span class="line"></span><br><span class="line"># 查看 service 和 statefulset =&gt; sts</span><br><span class="line">kubectl get service nginx</span><br><span class="line">kubectl get statefulset web</span><br><span class="line"></span><br><span class="line"># 查看 PVC 信息</span><br><span class="line">kubectl get pvc</span><br><span class="line"></span><br><span class="line"># 查看创建的 pod，这些 pod 是有序的</span><br><span class="line">kubectl get pods -l app=nginx</span><br><span class="line"></span><br><span class="line"># 查看这些 pod 的 dns</span><br><span class="line"># 运行一个 pod，基础镜像为 busybox 工具包，利用里面的 nslookup 可以看到 dns 信息</span><br><span class="line">kubectl run -i --tty --image busybox dns-test --restart=Never --rm /bin/sh</span><br><span class="line">nslookup web-0.nginx</span><br></pre></td></tr></table></figure>

<h4 id="扩容缩容-1"><a href="#扩容缩容-1" class="headerlink" title="扩容缩容"></a>扩容缩容</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 扩容缩容</span><br><span class="line">$ kubectl scale statefulset web --replicas=5</span><br><span class="line"></span><br><span class="line"># 扩容缩容</span><br><span class="line">$ kubectl patch statefulset web -p &#x27;&#123;&quot;spec&quot;:&#123;&quot;replicas&quot;:3&#125;&#125;&#x27;</span><br></pre></td></tr></table></figure>

<h4 id="镜像更新"><a href="#镜像更新" class="headerlink" title="镜像更新"></a>镜像更新</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 镜像更新（目前还不支持直接更新 image，需要 patch 来间接实现）</span><br><span class="line"></span><br><span class="line">kubectl patch sts web --type=&#x27;json&#x27; -p=&#x27;[&#123;&quot;op&quot;: &quot;replace&quot;, &quot;path&quot;: &quot;/spec/template/spec/containers/0/image&quot;, &quot;value&quot;:&quot;nginx:1.9.1&quot;&#125;]&#x27;</span><br></pre></td></tr></table></figure>

<h5 id="RollingUpdate"><a href="#RollingUpdate" class="headerlink" title="RollingUpdate"></a>RollingUpdate</h5><p>StatefulSet 也可以采用滚动更新策略，同样是修改 pod template 属性后会触发更新，但是由于 pod 是有序的，在 StatefulSet 中更新时是基于 pod 的顺序倒序更新的</p>
<h6 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h6><p>利用滚动更新中的 partition 属性，可以实现简易的灰度发布的效果</p>
<p>例如我们有 5 个 pod，如果当前 partition 设置为 3，那么此时滚动更新时，只会更新那些 序号 &gt;&#x3D; 3 的 pod</p>
<p>利用该机制，我们可以通过控制 partition 的值，来决定只更新其中一部分 pod，确认没有问题后再主键增大更新的 pod 数量，最终实现全部 pod 更新</p>
<h5 id="OnDelete"><a href="#OnDelete" class="headerlink" title="OnDelete"></a>OnDelete</h5><p>只有在 pod 被删除时会进行更新操作</p>
<h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 删除 StatefulSet 和 Headless Service</span><br><span class="line"># 级联删除：删除 statefulset 时会同时删除 pods</span><br><span class="line">kubectl delete statefulset web</span><br><span class="line"># 非级联删除：删除 statefulset 时不会删除 pods，删除 sts 后，pods 就没人管了，此时再删除 pod 不会重建的</span><br><span class="line">kubectl deelte sts web --cascade=false</span><br><span class="line"># 删除 service</span><br><span class="line">kubectl delete service nginx</span><br></pre></td></tr></table></figure>

<h4 id="删除pvc"><a href="#删除pvc" class="headerlink" title="删除pvc"></a>删除pvc</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># StatefulSet删除后PVC还会保留着，数据不再使用的话也需要删除</span><br><span class="line">$ kubectl delete pvc www-web-0 www-web-1</span><br></pre></td></tr></table></figure>

<h3 id="3-3-2-配置文件"><a href="#3-3-2-配置文件" class="headerlink" title="3.3.2 配置文件"></a>3.3.2 配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    name: web</span><br><span class="line">  clusterIP: None</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: StatefulSet # StatefulSet 类型的资源</span><br><span class="line">metadata:</span><br><span class="line">  name: web # StatefulSet 对象的名字</span><br><span class="line">spec:</span><br><span class="line">  serviceName: &quot;nginx&quot; # 使用哪个 service 来管理 dns</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector：</span><br><span class="line">    matchLabels：</span><br><span class="line">      app：nginx</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.7.9</span><br><span class="line">        ports: # 容器内部要暴露的端口</span><br><span class="line">        - containerPort: 80 # 具体暴露的端口号</span><br><span class="line">          name: web # 该端口配置的名字</span><br><span class="line">        volumeMounts: # 加载数据卷</span><br><span class="line">        - name: www # 指定加载哪个数据卷</span><br><span class="line">          mountPath: /usr/share/nginx/html # 加载到容器的哪个目录</span><br><span class="line">  volumeClaimTemplates: # 数据卷模板</span><br><span class="line">  - metadata: # 数据卷描述</span><br><span class="line">      name: www # 数据卷的名称</span><br><span class="line">      annotations: # 数据卷的注解</span><br><span class="line">        volume.alpha.kubernetes.io/storage-class: anything</span><br><span class="line">    spec: # 数据卷的规约</span><br><span class="line">      accessModes: [ &quot;ReadWriteOnce&quot; ] # 访问模式</span><br><span class="line">      resources:</span><br><span class="line">        requests:</span><br><span class="line">          storage: 1Gi</span><br></pre></td></tr></table></figure>

<h2 id="3-4-DaemonSet"><a href="#3-4-DaemonSet" class="headerlink" title="3.4 DaemonSet"></a>3.4 DaemonSet</h2><h3 id="3-4-1-配置文件"><a href="#3-4-1-配置文件" class="headerlink" title="3.4.1 配置文件"></a>3.4.1 配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet # 创建DaemonSet 资源</span><br><span class="line">metadata:</span><br><span class="line">  name: fluentd # 名字</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: logging</span><br><span class="line">        id: fluentd</span><br><span class="line">      name: fluentd</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: fluentd-es</span><br><span class="line">        image: agilestacks/fluentd-elasticsearch:v1.3.0</span><br><span class="line">        env: # 环境变量的key</span><br><span class="line">         - name: FLUENTD_ARGS # 环境变量的 key</span><br><span class="line">           value: -qq # 环境变量的value</span><br><span class="line">        volumeMounts: #加载数据卷，避免数据丢失</span><br><span class="line">         - name: containers #数据卷的名字</span><br><span class="line">           mountPath: /var/lib/docker/containers # 将数据卷挂载到容器内的哪个目录</span><br><span class="line">         - name: varlog</span><br><span class="line">           mountPath: /varlog</span><br><span class="line">      volumes: # 定义数据卷</span><br><span class="line">         - hostPath: #数据卷类型，主机路径的模式，也就是与node共享目录</span><br><span class="line">             path: /var/lib/docker/containers # node中的共享目录</span><br><span class="line">           name: containers 定义的数据卷的名称</span><br><span class="line">         - hostPath:</span><br><span class="line">             path: /var/log</span><br><span class="line">           name: varlog</span><br></pre></td></tr></table></figure>

<h3 id="3-4-2-指定Node节点"><a href="#3-4-2-指定Node节点" class="headerlink" title="3.4.2 指定Node节点"></a>3.4.2 指定Node节点</h3><p>DaemonSet 会忽略 Node 的 unschedulable 状态，有两种方式来指定 Pod 只运行在指定的 Node 节点上：</p>
<ul>
<li><p>nodeSelector：只调度到匹配指定 label 的 Node 上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">先为 Node 打上标签</span><br><span class="line">kubectl label nodes k8s-node1 svc_type=microsvc</span><br><span class="line"></span><br><span class="line">然后再 daemonset 配置中设置 nodeSelector</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        svc_type: microsvc</span><br></pre></td></tr></table></figure>
</li>
<li><p>nodeAffinity：功能更丰富的 Node 选择器，比如支持集合操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">nodeAffinity 目前支持两种：requiredDuringSchedulingIgnoredDuringExecution 和 preferredDuringSchedulingIgnoredDuringExecution，分别代表必须满足条件和优选条件。</span><br><span class="line"></span><br><span class="line">比如下面的例子代表调度到包含标签 wolfcode.cn/framework-name 并且值为 spring 或 springboot 的 Node 上，并且优选还带有标签 another-node-label-key=another-node-label-value 的Node。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-node-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    nodeAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">        nodeSelectorTerms:</span><br><span class="line">        - matchExpressions:</span><br><span class="line">          - key: wolfcode.cn/framework-name</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - spring</span><br><span class="line">            - springboot</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - weight: 1</span><br><span class="line">        preference:</span><br><span class="line">          matchExpressions:</span><br><span class="line">          - key: another-node-label-key</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - another-node-label-value</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-node-affinity</span><br><span class="line">    image: pauseyyf/pause</span><br></pre></td></tr></table></figure>
</li>
<li><p>podAffinity：调度到满足条件的 Pod 所在的 Node 上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">podAffinity 基于 Pod 的标签来选择 Node，仅调度到满足条件Pod 所在的 Node 上，支持 podAffinity 和 podAntiAffinity。这个功能比较绕，以下面的例子为例：</span><br><span class="line">    如果一个 “Node 所在空间中包含至少一个带有 auth=oauth2 标签且运行中的 Pod”，那么可以调度到该 Node</span><br><span class="line">    不调度到 “包含至少一个带有 auth=jwt 标签且运行中 Pod”的 Node 上</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-pod-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity:</span><br><span class="line">    podAffinity:</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - labelSelector:</span><br><span class="line">          matchExpressions:</span><br><span class="line">          - key: auth</span><br><span class="line">            operator: In</span><br><span class="line">            values:</span><br><span class="line">            - oauth2</span><br><span class="line">        topologyKey: failure-domain.beta.kubernetes.io/zone</span><br><span class="line">    podAntiAffinity:</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">      - weight: 100</span><br><span class="line">        podAffinityTerm:</span><br><span class="line">          labelSelector:</span><br><span class="line">            matchExpressions:</span><br><span class="line">            - key: auth</span><br><span class="line">              operator: In</span><br><span class="line">              values:</span><br><span class="line">              - jwt</span><br><span class="line">          topologyKey: kubernetes.io/hostname</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-pod-affinity</span><br><span class="line">    image: pauseyyf/pause</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-4-3-滚动更新"><a href="#3-4-3-滚动更新" class="headerlink" title="3.4.3 滚动更新"></a>3.4.3 滚动更新</h3><p>不建议使用 RollingUpdate，建议使用 OnDelete 模式，这样避免频繁更新 ds</p>
<h2 id="3-5-HPA自动扩-缩容"><a href="#3-5-HPA自动扩-缩容" class="headerlink" title="3.5 HPA自动扩&#x2F;缩容"></a>3.5 HPA自动扩&#x2F;缩容</h2><p>通过观察 pod 的 cpu、内存使用率或自定义 metrics 指标进行自动的扩容或缩容 pod 的数量。</p>
<p>通常用于 Deployment，不适用于无法扩&#x2F;缩容的对象，如 DaemonSet</p>
<p>控制管理器每隔30s（可以通过–horizontal-pod-autoscaler-sync-period修改）查询metrics的资源使用情况</p>
<h3 id="3-5-1-开启指标服务"><a href="#3-5-1-开启指标服务" class="headerlink" title="3.5.1 开启指标服务"></a>3.5.1 开启指标服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 下载 metrics-server 组件配置文件</span><br><span class="line">wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml -O metrics-server-components.yaml</span><br><span class="line"></span><br><span class="line"># 修改镜像地址为国内的地址</span><br><span class="line">sed -i &#x27;s/k8s.gcr.io\/metrics-server/registry.cn-hangzhou.aliyuncs.com\/google_containers/g&#x27; metrics-server-components.yaml</span><br><span class="line"></span><br><span class="line"># 修改容器的 tls 配置，不验证 tls，在 containers 的 args 参数中增加 --kubelet-insecure-tls 参数</span><br><span class="line"></span><br><span class="line"># 安装组件</span><br><span class="line">kubectl apply -f metrics-server-components.yaml</span><br><span class="line"></span><br><span class="line"># 查看 pod 状态</span><br><span class="line">kubectl get pods --all-namespaces | grep metrics</span><br></pre></td></tr></table></figure>

<h3 id="3-5-2-cpu、内存指标监控"><a href="#3-5-2-cpu、内存指标监控" class="headerlink" title="3.5.2 cpu、内存指标监控"></a>3.5.2 cpu、内存指标监控</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">实现 cpu 或内存的监控，首先有个前提条件是该对象必须配置了 resources.requests.cpu 或 resources.requests.memory 才可以，可以配置当 cpu/memory 达到上述配置的百分比后进行扩容或缩容</span><br><span class="line"></span><br><span class="line">创建一个 HPA：</span><br><span class="line">先准备一个好一个有做资源限制的 deployment</span><br><span class="line">执行命令 kubectl autoscale deploy nginx-deploy --cpu-percent=20 --min=2 --max=5</span><br><span class="line">通过 kubectl get hpa 可以获取 HPA 信息</span><br><span class="line"></span><br><span class="line">测试：找到对应服务的 service，编写循环测试脚本提升内存与 cpu 负载</span><br><span class="line">while true; do wget -q -O- http://&lt;ip:port&gt; &gt; /dev/null ; done</span><br><span class="line"></span><br><span class="line">可以通过多台机器执行上述命令，增加负载，当超过负载后可以查看 pods 的扩容情况 kubectl get pods</span><br><span class="line"></span><br><span class="line">查看 pods 资源使用情况</span><br><span class="line">kubectl top pods</span><br><span class="line"></span><br><span class="line">扩容测试完成后，再关闭循环执行的指令，让 cpu 占用率降下来，然后过 5 分钟后查看自动缩容情况</span><br></pre></td></tr></table></figure>

<h3 id="3-5-3-自定义metrics"><a href="#3-5-3-自定义metrics" class="headerlink" title="3.5.3 自定义metrics"></a>3.5.3 自定义metrics</h3><ul>
<li>控制管理器开启–horizontal-pod-autoscaler-use-rest-clients</li>
<li>控制管理器的–apiserver指向<a target="_blank" rel="noopener" href="https://github.com/kubernetes/kube-aggregator">API Server Aggregator</a></li>
<li>在API Server Aggregator中注册自定义的metrics API</li>
</ul>
<h1 id="四、服务发布"><a href="#四、服务发布" class="headerlink" title="四、服务发布"></a>四、服务发布</h1><h2 id="4-1-Service"><a href="#4-1-Service" class="headerlink" title="4.1 Service"></a>4.1 Service</h2><p>负责东西流量（同层级&#x2F;内部服务网络通信）的通信</p>
<h3 id="4-1-1-Service的定义"><a href="#4-1-1-Service的定义" class="headerlink" title="4.1.1 Service的定义"></a>4.1.1 Service的定义</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-svc</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-svc</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort # NodePort可外部通过节点IP访问，ClusterIP仅内部访问</span><br><span class="line">  ports:</span><br><span class="line">  - name: http # service 端口配置的名称</span><br><span class="line">    protocol: TCP # 端口绑定的协议，支持 TCP、UDP、SCTP，默认为 TCP</span><br><span class="line">    port: 80 # service 自己的端口</span><br><span class="line">    targetPort: 9527 # 目标 pod 的端口</span><br><span class="line">    nodePort: 31000 # type为NodePort时可配置，不指定会在30000-32767里随机一个端口</span><br><span class="line">  - name: https</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 443</span><br><span class="line">  selector: # 选中当前 service 匹配哪些 pod，对哪些 pod 的东西流量进行代理</span><br><span class="line">    app: nginx</span><br></pre></td></tr></table></figure>

<h4 id="命令操作"><a href="#命令操作" class="headerlink" title="命令操作"></a>命令操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 创建 service</span><br><span class="line">kubectl create -f nginx-svc.yaml</span><br><span class="line"></span><br><span class="line"># 查看 service 信息，通过 service 的 cluster ip 进行访问</span><br><span class="line">kubectl get svc </span><br><span class="line"></span><br><span class="line"># 查看 pod 信息，通过 pod 的 ip 进行访问</span><br><span class="line">kubectl get po -o wide</span><br><span class="line"></span><br><span class="line"># 创建其他 pod 通过 service name 进行访问（推荐）</span><br><span class="line">kubectl exec -it busybox -- sh</span><br><span class="line">curl http://nginx-svc</span><br><span class="line"></span><br><span class="line"># 默认在当前 namespace 中访问，如果需要跨 namespace 访问 pod，则在 service name 后面加上 .&lt;namespace&gt; 即可</span><br><span class="line">curl http://nginx-svc.default</span><br></pre></td></tr></table></figure>

<h4 id="Endpoint"><a href="#Endpoint" class="headerlink" title="Endpoint"></a>Endpoint</h4><h3 id="4-1-2代理k8s外部服务"><a href="#4-1-2代理k8s外部服务" class="headerlink" title="4.1.2代理k8s外部服务"></a>4.1.2代理k8s外部服务</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">实现方式：</span><br><span class="line">编写 service 配置文件时，不指定 selector 属性</span><br><span class="line">自己创建 endpoint</span><br><span class="line">endpoint 配置：</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Endpoints</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-svc-external # 与 service 一致</span><br><span class="line">  name: nginx-svc-external # 与 service 一致</span><br><span class="line">  namespace: default # 与 service 一致</span><br><span class="line">subsets:</span><br><span class="line">- addresses:</span><br><span class="line">  - ip: &lt;target ip&gt; # 目标 ip 地址</span><br><span class="line">  ports: # 与 service 一致</span><br><span class="line">  - name: http</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br></pre></td></tr></table></figure>

<ul>
<li>各环境访问名称统一</li>
<li>访问k8s集群外的其他服务</li>
<li>项目迁移</li>
</ul>
<h3 id="4-1-3反向代理外部域名"><a href="#4-1-3反向代理外部域名" class="headerlink" title="4.1.3反向代理外部域名"></a>4.1.3反向代理外部域名</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: wolfcode-external-domain</span><br><span class="line">  name: wolfcode-external-domain</span><br><span class="line">spec:</span><br><span class="line">  type: ExternalName</span><br><span class="line">  externalName: www.wolfcode.cn</span><br></pre></td></tr></table></figure>

<h3 id="4-1-4-常用类型"><a href="#4-1-4-常用类型" class="headerlink" title="4.1.4 常用类型"></a>4.1.4 常用类型</h3><h4 id="ClusterIP"><a href="#ClusterIP" class="headerlink" title="ClusterIP"></a>ClusterIP</h4><p>只能在集群内部使用，不配置类型的话默认就是 ClusterIP</p>
<h4 id="ExternalName"><a href="#ExternalName" class="headerlink" title="ExternalName"></a>ExternalName</h4><p>返回定义的 CNAME 别名，可以配置为域名</p>
<h4 id="NodePort"><a href="#NodePort" class="headerlink" title="NodePort"></a>NodePort</h4><p>会在所有安装了 kube-proxy 的节点都绑定一个端口，此端口可以代理至对应的 Pod，集群外部可以使用任意节点 ip + NodePort 的端口号访问到集群中对应 Pod 中的服务。</p>
<p>当类型设置为 NodePort 后，可以在 ports 配置中增加 nodePort 配置指定端口，需要在下方的端口范围内，如果不指定会随机指定端口</p>
<p>端口范围：30000~32767</p>
<p>端口范围配置在 &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service 文件中</p>
<h4 id="LoadBalancer"><a href="#LoadBalancer" class="headerlink" title="LoadBalancer"></a>LoadBalancer</h4><p>使用云服务商（阿里云、腾讯云等）提供的负载均衡器服务</p>
<h2 id="4-2-Ingress"><a href="#4-2-Ingress" class="headerlink" title="4.2 Ingress"></a>4.2 Ingress</h2><p>Ingress 大家可以理解为也是一种 LB 的抽象，它的实现也是支持 nginx、haproxy 等负载均衡服务的</p>
<h3 id="4-2-1-安装ingress-nginx"><a href="#4-2-1-安装ingress-nginx" class="headerlink" title="4.2.1 安装ingress-nginx"></a>4.2.1 安装ingress-nginx</h3><p><a target="_blank" rel="noopener" href="https://kubernetes.github.io/ingress-nginx/deploy/#using-helm">https://kubernetes.github.io/ingress-nginx/deploy/#using-helm</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">1.添加ingress-nginx官方helm仓库</span><br><span class="line">helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx</span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line">2.查找所有的版本</span><br><span class="line">helm search repo ingress-nginx/ingress-nginx -l</span><br><span class="line"></span><br><span class="line">3.下载</span><br><span class="line">helm fetch ingress-nginx/ingress-nginx --version 4.5.2</span><br><span class="line"></span><br><span class="line">4.解压缩</span><br><span class="line">tar zxvf ingress-nginx-4.5.2.tgz</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">进入ingress-nginx目录修改values.yaml参数配置</span><br><span class="line"></span><br><span class="line">1.修改dnsPolicy的值为ClusterFirstWithHostNet</span><br><span class="line">    # By default, while using host network, name resolution uses the host&#x27;s DNS. If you wish nginx-controller</span><br><span class="line">    # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.</span><br><span class="line">    #dnsPolicy: ClusterFirst</span><br><span class="line">    dnsPolicy: ClusterFirstWithHostNet</span><br><span class="line">    </span><br><span class="line">2.修改hostNetwork的值为true</span><br><span class="line">    # -- Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),</span><br><span class="line">    # since CNI and hostport don&#x27;t mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920</span><br><span class="line">    # is merged</span><br><span class="line">    #hostNetwork: false</span><br><span class="line">    hostNetwork: true</span><br><span class="line">    </span><br><span class="line">3.修改kind的值为DaemonSet</span><br><span class="line">    # -- Use a `DaemonSet` or `Deployment`</span><br><span class="line">    #kind: Deployment</span><br><span class="line">    kind: DaemonSet</span><br><span class="line">    </span><br><span class="line">4.在nodeSelector下添加ingress: &quot;true&quot;  # 增加选择器，如果 node 上有 ingress=true 就部署</span><br><span class="line">    nodeSelector:</span><br><span class="line">        kubernetes.io/os: linux</span><br><span class="line">        ingress: &quot;true&quot;</span><br><span class="line">        </span><br><span class="line">5.修改type的值为ClusterIP  # 将 service 中的 type 由 LoadBalancer 修改为 ClusterIP，如果服务器是云平台才用 LoadBalancer</span><br><span class="line">        ## Ref: https://kubernetes.io/docs/concepts/services-networking/dual-stack/</span><br><span class="line">        ipFamilies:</span><br><span class="line">            - IPv4</span><br><span class="line">        ports:</span><br><span class="line">            http: 80</span><br><span class="line">            https: 443</span><br><span class="line">        targetPorts:</span><br><span class="line">            http: http</span><br><span class="line">            https: https</span><br><span class="line">        #type: LoadBalancer</span><br><span class="line">        type: ClusterIP</span><br><span class="line">        </span><br><span class="line">6.修改enabled的值为false</span><br><span class="line">        ## Additional annotations to the admission webhooks.</span><br><span class="line">        ## These annotations will be added to the ValidatingWebhookConfiguration and</span><br><span class="line">        ## the Jobs Spec of the admission webhooks.</span><br><span class="line">        #enabled: true</span><br><span class="line">        enabled: false</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">给node打标签</span><br><span class="line">kubectl label nodes k8s-node1 ingress=true</span><br><span class="line"></span><br><span class="line">新建命令空间</span><br><span class="line">kubectl create namespace ingress-nginx</span><br><span class="line"></span><br><span class="line">安装ingress-nginx</span><br><span class="line">cd ingress-nginx/</span><br><span class="line">helm install ingress-nginx -n ingress-nginx .</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-基本使用"><a href="#4-2-2-基本使用" class="headerlink" title="4.2.2 基本使用"></a>4.2.2 基本使用</h3><h4 id="创建一个ingress"><a href="#创建一个ingress" class="headerlink" title="创建一个ingress"></a>创建一个ingress</h4><p>文档：<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/">https://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress # 资源类型为 Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-test</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: &quot;nginx&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class="line">spec:</span><br><span class="line">  rules: # ingress 规则配置，可以配置多个</span><br><span class="line">  - host: www.xiaoyu.com # 域名配置，可以使用通配符 *</span><br><span class="line">    http:</span><br><span class="line">      paths: # 相当于 nginx 的 location 配置，可以配置多个</span><br><span class="line">      - pathType: Prefix # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service: </span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port: </span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /api # 等价于 nginx 中的 location 的路径前缀匹配</span><br></pre></td></tr></table></figure>

<h4 id="多域名配置"><a href="#多域名配置" class="headerlink" title="多域名配置"></a>多域名配置</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress # 资源类型为 Ingress</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-nginx-test</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: &quot;nginx&quot;</span><br><span class="line">    nginx.ingress.kubernetes.io/rewrite-target: /</span><br><span class="line">spec:</span><br><span class="line">  rules: # ingress 规则配置，可以配置多个</span><br><span class="line">  - host: www.xiaoyu.com # 域名配置，可以使用通配符 *</span><br><span class="line">    http:</span><br><span class="line">      paths: # 相当于 nginx 的 location 配置，可以配置多个</span><br><span class="line">      - pathType: Prefix # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service: </span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port: </span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /api # 等价于 nginx 中的 location 的路径前缀匹配</span><br><span class="line">      - pathType: Exec # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配&gt;，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port:</span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /</span><br><span class="line">  - host: api.xiaoyu.com # 域名配置，可以使用通配符 *</span><br><span class="line">    http:</span><br><span class="line">      paths: # 相当于 nginx 的 location 配置，可以配置多个</span><br><span class="line">      - pathType: Prefix # 路径类型，按照路径类型进行匹配 ImplementationSpecific 需要指定 IngressClass，具体匹配规则以 IngressClass 中的规则为准。Exact：精确匹配&gt;，URL需要与path完全匹配上，且区分大小写的。Prefix：以 / 作为分隔符来进行前缀匹配</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx # 代理到哪个 service</span><br><span class="line">            port:</span><br><span class="line">              number: 80 # service 的端口</span><br><span class="line">        path: /</span><br></pre></td></tr></table></figure>

<h1 id="五、配置与存储"><a href="#五、配置与存储" class="headerlink" title="五、配置与存储"></a>五、配置与存储</h1><h2 id="5-1-配置管理"><a href="#5-1-配置管理" class="headerlink" title="5.1 配置管理"></a>5.1 配置管理</h2><h3 id="5-1-1-ConfigMap"><a href="#5-1-1-ConfigMap" class="headerlink" title="5.1.1 ConfigMap"></a>5.1.1 ConfigMap</h3><p><strong>创建</strong></p>
<p>使用 <code>kubectl create configmap -h</code> 查看示例，构建 configmap 对象</p>
<p><strong>使用ConfigMap</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">创建configmap：</span><br><span class="line">vim db.properties</span><br><span class="line">username=root</span><br><span class="line">password=admin</span><br><span class="line"></span><br><span class="line">vim redis.properties</span><br><span class="line">host: 127.0.0.1</span><br><span class="line">port: 6379</span><br><span class="line"></span><br><span class="line">kubectl create cm test-dir-config --from-file=./</span><br><span class="line"></span><br><span class="line">kubectl create configmap test-env-config --from-literal=JAVA_OPTS_TEST=&#x27;-Xms512m -Xmx512m&#x27; --from-literal=APP_NAME=&#x27;springboot-env-test&#x27;</span><br><span class="line"></span><br><span class="line">编写配置文件：</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-cm-pod</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: Never</span><br><span class="line">  containers:</span><br><span class="line">  - name: env-test</span><br><span class="line">    image: alpine</span><br><span class="line">    command: [&quot;bin/sh&quot;,&quot;-c&quot;,&quot;env;sleep 3600&quot;]</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    env:</span><br><span class="line">    - name: JAVA_VM_OPTS</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config # configMap的名字</span><br><span class="line">          key: JAVA_OPTS_TEST # 表示从 name 的 configMap 中获取名字为 key 的 value，将其赋值给本地环境变量 JAVA_OPTS_TEST</span><br><span class="line">    - name: APP</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config</span><br><span class="line">          key: APP_NAME</span><br><span class="line">    volumMounts: # 加载数据卷</span><br><span class="line">    - name: db-config # 表示加载volumes 属性中哪个数据卷</span><br><span class="line">      mountPath: &quot;/usr/local/mysql/conf&quot; # 想要将数据卷中的文件加载到哪个目录下</span><br><span class="line">      readOnly: true # 是否只读</span><br><span class="line">  volumes: # 数据卷挂载 configMap、secret</span><br><span class="line">  - name: db-config # 数据卷的名字，随意设置</span><br><span class="line">    configMap: # 数据卷类型为configMap</span><br><span class="line">      name: test-dir-config # configMap的名字，必须跟想要加载的configMap 相同</span><br><span class="line">      items: #对 configMap 中的 key 进行映射，如果不指定，默认会将 configMap中所有 key 全部转换为一个个同名的文件</span><br><span class="line">      - key: &quot;db.properties&quot; # configMap中的key</span><br><span class="line">        path: &quot;db.properties&quot; # 将该 key 的值转换为文件         </span><br><span class="line">          </span><br><span class="line">创建pod：</span><br><span class="line">kubectl create -f test-cm-pod.yaml</span><br><span class="line"></span><br><span class="line">测试查看打印的环境变量中是否有JAVA_VM_OPTS和APP：</span><br><span class="line">kubectl logs -f test-cm-pod</span><br><span class="line"></span><br><span class="line">测试查看/usr/local/mysql/conf下是否有db.properties文件</span><br><span class="line">kubectl exec -it test-cm-pod -- sh</span><br></pre></td></tr></table></figure>

<h3 id="5-1-2-加密数据配置Secret"><a href="#5-1-2-加密数据配置Secret" class="headerlink" title="5.1.2 加密数据配置Secret"></a>5.1.2 加密数据配置Secret</h3><p>与 ConfigMap 类似，用于存储配置信息，但是主要用于存储敏感信息、需要加密的信息，Secret 可以提供数据加密、解密功能。</p>
<p>在创建 Secret 时，要注意如果要加密的字符中，包含了有特殊字符，需要使用转义符转移，例如 $ 转移后为 $，也可以对特殊字符使用单引号描述，这样就不需要转移例如 1$289*-! 转换为 ‘1$289*-!’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret -h</span><br><span class="line">kubectl create secret docker-registry -h</span><br><span class="line">kubectl create secret docker-registry sec-test --docker-username=admin --docker-password=test --docker-email=test@test.com</span><br><span class="line"></span><br><span class="line">编写配置文件</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-image-pull-pod</span><br><span class="line">spec:</span><br><span class="line">  imagePullSecrets: # 配置登录docker registry的secret</span><br><span class="line">  name: test-secret</span><br><span class="line">  containers:</span><br><span class="line">  - name: nginx</span><br><span class="line">    image: 192.168.112.110:8858/test/nginx:latest</span><br><span class="line">    command: [&quot;bin/sh&quot;,&quot;-c&quot;,&quot;env;sleep 3600&quot;]</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    env:</span><br><span class="line">    - name: JAVA_VM_OPTS</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config # configMap的名字</span><br><span class="line">          key: JAVA_OPTS_TEST # 表示从 name 的 configMap 中获取名字为 key 的 value，将其赋值给本地环境变量 JAVA_OPTS_TEST</span><br><span class="line">    - name: APP</span><br><span class="line">      valueFrom:</span><br><span class="line">        configMapKeyRef:</span><br><span class="line">          name: test-env-config</span><br><span class="line">          key: APP_NAME</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="5-1-3-SubPath的使用"><a href="#5-1-3-SubPath的使用" class="headerlink" title="5.1.3 SubPath的使用"></a>5.1.3 SubPath的使用</h3><p>使用 ConfigMap 或 Secret 挂载到目录的时候，会将容器中源目录给覆盖掉，此时我们可能只想覆盖目录中的某一个文件，但是这样的操作会覆盖整个文件，因此需要使用到 SubPath</p>
<p>配置方式：</p>
<ol>
<li>定义 volumes 时需要增加 items 属性，配置 key 和 path，且 path 的值不能从 &#x2F; 开始</li>
<li>在容器内的 volumeMounts 中增加 subPath 属性，该值与 volumes 中 items.path 的值相同</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl create configmap nginx-conf-cm --from-file=./nginx.conf</span><br><span class="line"></span><br><span class="line">containers:</span><br><span class="line">  ......</span><br><span class="line">  volumeMounts: # 挂载数据卷</span><br><span class="line">  - mountPath: &#x27;/etc/nginx&#x27; # 挂载的路径</span><br><span class="line">    name: nginx-conf # 使用哪个 configmap 或 secret</span><br><span class="line">    subPath: etc/nginx/nginx.conf # 与 volumes.[0].items.path 相同</span><br><span class="line">volumes:</span><br><span class="line">- name: nginx-conf # 数据卷的名称</span><br><span class="line">  configMap: #数据卷类型为configmap</span><br><span class="line">    name: nginx-conf-cm # configMap 名字</span><br><span class="line">    items: # subPath 配置，要将configmap中的哪些数据挂载进来</span><br><span class="line">      key: nginx.conf # 指定要挂载哪个key</span><br><span class="line">      path: nginx.conf # 挂载后该key重命名为什么名字</span><br></pre></td></tr></table></figure>

<h3 id="5-1-4-配置的热更新"><a href="#5-1-4-配置的热更新" class="headerlink" title="5.1.4 配置的热更新"></a>5.1.4 配置的热更新</h3><p>我们通常会将项目的配置文件作为 configmap 然后挂载到 pod，那么如果更新 configmap 中的配置，会不会更新到 pod 中呢？</p>
<p>这得分成几种情况：<br>默认方式：会更新，更新周期是更新时间 + 缓存时间<br>subPath：不会更新<br>变量形式：如果 pod 中的一个变量是从 configmap 或 secret 中得到，同样也是不会更新的</p>
<p>对于 subPath 的方式，我们可以取消 subPath 的使用，将配置文件挂载到一个不存在的目录，避免目录的覆盖，然后再利用软连接的形式，将该文件链接到目标位置</p>
<p>但是如果目标位置原本就有文件，可能无法创建软链接，此时可以基于前面讲过的 postStart 操作执行删除命令，将默认的吻技安删除即可</p>
<h4 id="5-1-4-1-通过edit命令直接修改configmap"><a href="#5-1-4-1-通过edit命令直接修改configmap" class="headerlink" title="5.1.4.1 通过edit命令直接修改configmap"></a>5.1.4.1 通过edit命令直接修改configmap</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit cm test-dir-config</span><br></pre></td></tr></table></figure>

<h4 id="5-1-4-2-通过replace替换"><a href="#5-1-4-2-通过replace替换" class="headerlink" title="5.1.4.2 通过replace替换"></a>5.1.4.2 通过replace替换</h4><p>由于 configmap 我们创建通常都是基于文件创建，并不会编写 yaml 配置文件，因此修改时我们也是直接修改配置文件，而 replace 是没有 <code>--from-file</code> 参数的，因此无法实现基于源配置文件的替换，此时我们可以利用下方的命令实现</p>
<p># 该命令的重点在于 <code>--dry-run</code> 参数，该参数的意思打印 yaml 文件，但不会将该文件发送给 apiserver，再结合 -oyaml 输出 yaml 文件就可以得到一个配置好但是没有发给 apiserver 的文件，然后再结合 replace 监听控制台输出得到 yaml 数据即可实现替换</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create cm --from-file=nginx.conf --dry-run -oaml | kubectl replace -f-</span><br></pre></td></tr></table></figure>

<h3 id="5-1-5-不可变的Secret和ConfigMap"><a href="#5-1-5-不可变的Secret和ConfigMap" class="headerlink" title="5.1.5 不可变的Secret和ConfigMap"></a>5.1.5 不可变的Secret和ConfigMap</h3><p>对于一些敏感服务的配置文件，在线上有时是不允许修改的，此时在配置 configmap 时可以设置 <code> immutable: true</code>来禁止修改</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">...</span><br><span class="line">immutable: true</span><br></pre></td></tr></table></figure>

<h2 id="5-2-持久化存储"><a href="#5-2-持久化存储" class="headerlink" title="5.2 持久化存储"></a>5.2 持久化存储</h2><h3 id="5-2-1-Volumes"><a href="#5-2-1-Volumes" class="headerlink" title="5.2.1 Volumes"></a>5.2.1 Volumes</h3><h4 id="Hostpath"><a href="#Hostpath" class="headerlink" title="Hostpath"></a>Hostpath</h4><p>将节点上的文件或目录挂载到 Pod 上，此时该目录会变成持久化存储目录，即使 Pod 被删除后重启，也可以重新加载到该目录，该目录下的文件不会丢失</p>
<h5 id="配置文件-2"><a href="#配置文件-2" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-volume-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-volume</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pd # 挂载到容器的哪个目录</span><br><span class="line">      name: test-volume # 挂载哪个 volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    hostPath: # 与主机共享目录，加载主机中的指定目录到容器中</span><br><span class="line">      path: /data # 节点中的目录</span><br><span class="line">      type: Directory # 检查类型，在挂载前对挂载目录做什么检查操作，有多种选项，默认为空字符串，不做任何检查</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">类型：</span><br><span class="line">空字符串：默认类型，不做任何检查</span><br><span class="line">DirectoryOrCreate：如果给定的 path 不存在，就创建一个 755 的空目录</span><br><span class="line">Directory：这个目录必须存在</span><br><span class="line">FileOrCreate：如果给定的文件不存在，则创建一个空文件，权限为 644</span><br><span class="line">File：这个文件必须存在</span><br><span class="line">Socket：UNIX 套接字，必须存在</span><br><span class="line">CharDevice：字符设备，必须存在</span><br><span class="line">BlockDevice：块设备，必须存在</span><br></pre></td></tr></table></figure>

<h4 id="EmptyDir"><a href="#EmptyDir" class="headerlink" title="EmptyDir"></a>EmptyDir</h4><p>EmptyDir 主要用于一个 Pod 中不同的 Container 共享数据使用的，由于只是在 Pod 内部使用，因此与其他 volume 比较大的区别是，当 Pod 如果被删除了，那么 emptyDir 也会被删除。</p>
<p>存储介质可以是任意类型，如 SSD、磁盘或网络存储。可以将 emptyDir.medium 设置为 Memory 让 k8s 使用 tmpfs（内存支持文件系统），速度比较快，但是重启 tmpfs 节点时，数据会被清除，且设置的大小会计入到 Container 的内存限制中。</p>
<h5 id="配置文件-3"><a href="#配置文件-3" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: empty-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-emptydir1</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /cache</span><br><span class="line">      name: cache-volume</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-emptydir2</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /share</span><br><span class="line">      name: cache-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: cache-volume</span><br><span class="line">    emptyDir: &#123;&#125;</span><br><span class="line">    </span><br><span class="line">测试</span><br><span class="line">kubectl exec -it empty-test-pod -c nginx-emptydir1 -- sh</span><br></pre></td></tr></table></figure>

<h3 id="5-2-2-NFS挂载"><a href="#5-2-2-NFS挂载" class="headerlink" title="5.2.2 NFS挂载"></a>5.2.2 NFS挂载</h3><p>nfs 卷能将 NFS (网络文件系统) 挂载到你的 Pod 中。 不像 emptyDir 那样会在删除 Pod 的同时也会被删除，nfs 卷的内容在删除 Pod 时会被保存，卷只是被卸载。 这意味着 nfs 卷可以被预先填充数据，并且这些数据可以在 Pod 之间共享。</p>
<h4 id="安装nfs"><a href="#安装nfs" class="headerlink" title="安装nfs"></a>安装nfs</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 安装 nfs</span><br><span class="line">apt-get install nfs-common nfs-kernel-server -y</span><br><span class="line">#yum install nfs-utils -y</span><br><span class="line"></span><br><span class="line"># 创建共享目录</span><br><span class="line">mkdir -p /data/nfs</span><br><span class="line">cd /data/nfs</span><br><span class="line">mkdir rw</span><br><span class="line">mkdir ro</span><br><span class="line"></span><br><span class="line"># 设置共享目录 export</span><br><span class="line">vim /etc/exports</span><br><span class="line">/data/nfs/rw 192.168.122.0/24(insecure,rw,sync,no_subtree_check,no_root_squash)</span><br><span class="line">/data/nfs/ro 192.168.122.0/24(insecure,ro,sync,no_subtree_check,no_root_squash)</span><br><span class="line"></span><br><span class="line"># 启动 nfs</span><br><span class="line">systemctl start nfs-kernel-server.service</span><br><span class="line">#systemctl start nfs-server</span><br><span class="line"></span><br><span class="line"># 查看 nfs 版本</span><br><span class="line">cat /proc/fs/nfsd/versions</span><br><span class="line"></span><br><span class="line"># 到其他测试节点安装 nfs-utils 并加载测试</span><br><span class="line">mkdir -p /mnt/nfs/rw</span><br><span class="line">mount -t nfs 192.168.122.120:/data/nfs/rw /mnt/nfs/rw</span><br></pre></td></tr></table></figure>

<h4 id="配置文件-4"><a href="#配置文件-4" class="headerlink" title="配置文件"></a>配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-test-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nfs-test-container</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /data</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    nfs:</span><br><span class="line">      server: 192.168.122.120 # 网络存储服务地址</span><br><span class="line">      path: /data/nfs/rw # 网络存储路径</span><br><span class="line">      readOnly: false # 是否只读</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">测试在其他node节点创建文件并在pod中查看</span><br></pre></td></tr></table></figure>

<h3 id="5-2-3-PV与PVC"><a href="#5-2-3-PV与PVC" class="headerlink" title="5.2.3 PV与PVC"></a>5.2.3 PV与PVC</h3><p><strong>持久卷（PersistentVolume，PV）</strong> 是集群中的一块存储，可以由管理员事先制备， 或者使用<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/storage/storage-classes/">存储类（Storage Class）</a>来动态制备。 持久卷是集群资源，就像节点也是集群资源一样。PV 持久卷和普通的 Volume 一样， 也是使用卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 此 API 对象中记述了存储的实现细节，无论其背后是 NFS、iSCSI 还是特定于云平台的存储系统。</p>
<p><strong>持久卷申领（PersistentVolumeClaim，PVC）</strong> 表达的是用户对存储的请求。概念上与 Pod 类似。 Pod 会耗用节点资源，而 PVC 申领会耗用 PV 资源。Pod 可以请求特定数量的资源（CPU 和内存）；同样 PVC 申领也可以请求特定的大小和访问模式 （例如，可以要求 PV 卷能够以 ReadWriteOnce、ReadOnlyMany 或 ReadWriteMany 模式之一来挂载，参见<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#access-modes">访问模式</a>）。</p>
<h4 id="5-2-3-1-生命周期"><a href="#5-2-3-1-生命周期" class="headerlink" title="5.2.3.1 生命周期"></a>5.2.3.1 生命周期</h4><h5 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h5><h6 id="静态构建"><a href="#静态构建" class="headerlink" title="静态构建"></a>静态构建</h6><p>集群管理员创建若干 PV 卷。这些卷对象带有真实存储的细节信息， 并且对集群用户可用（可见）。PV 卷对象存在于 Kubernetes API 中，可供用户消费（使用）。</p>
<h6 id="动态构建"><a href="#动态构建" class="headerlink" title="动态构建"></a>动态构建</h6><p>如果集群中已经有的 PV 无法满足 PVC 的需求，那么集群会根据 PVC 自动构建一个 PV，该操作是通过 StorageClass 实现的。</p>
<p>想要实现这个操作，前提是 PVC 必须设置 StorageClass，否则会无法动态构建该 PV，可以通过启用 DefaultStorageClass 来实现 PV 的构建。</p>
<h5 id="绑定"><a href="#绑定" class="headerlink" title="绑定"></a>绑定</h5><p>当用户创建一个 PVC 对象后，主节点会监测新的 PVC 对象，并且寻找与之匹配的 PV 卷，找到 PV 卷后将二者绑定在一起。</p>
<p>如果找不到对应的 PV，则需要看 PVC 是否设置 StorageClass 来决定是否动态创建 PV，若没有配置，PVC 就会一致处于未绑定状态，直到有与之匹配的 PV 后才会申领绑定关系。</p>
<h5 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h5><p>Pod 将 PVC 当作存储卷来使用，集群会通过 PVC 找到绑定的 PV，并为 Pod 挂载该卷。</p>
<p>Pod 一旦使用 PVC 绑定 PV 后，为了保护数据，避免数据丢失问题，PV 对象会受到保护，在系统中无法被删除。</p>
<h5 id="回收策略"><a href="#回收策略" class="headerlink" title="回收策略"></a>回收策略</h5><p>当用户不再使用其存储卷时，他们可以从 API 中将 PVC 对象删除， 从而允许该资源被回收再利用。PersistentVolume 对象的回收策略告诉集群， 当其被从申领中释放时如何处理该数据卷。 目前，数据卷可以被 Retained（保留）、Recycled（回收）或 Deleted（删除）。</p>
<h6 id="保留（Retain）"><a href="#保留（Retain）" class="headerlink" title="保留（Retain）"></a>保留（Retain）</h6><p>回收策略 Retain 使得用户可以手动回收资源。当 PersistentVolumeClaim 对象被删除时，PersistentVolume 卷仍然存在，对应的数据卷被视为”已释放（released）”。 由于卷上仍然存在这前一申领人的数据，该卷还不能用于其他申领。 管理员可以通过下面的步骤来手动回收该卷：</p>
<ol>
<li>删除 PersistentVolume 对象。与之相关的、位于外部基础设施中的存储资产 （例如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）在 PV 删除之后仍然存在。</li>
<li>根据情况，手动清除所关联的存储资产上的数据。</li>
<li>手动删除所关联的存储资产。</li>
</ol>
<p>如果你希望重用该存储资产，可以基于存储资产的定义创建新的 PersistentVolume 卷对象。</p>
<h6 id="删除（Delete）"><a href="#删除（Delete）" class="headerlink" title="删除（Delete）"></a>删除（Delete）</h6><p>对于支持 Delete 回收策略的卷插件，删除动作会将 PersistentVolume 对象从 Kubernetes 中移除，同时也会从外部基础设施（如 AWS EBS、GCE PD、Azure Disk 或 Cinder 卷）中移除所关联的存储资产。 动态制备的卷会继承<a target="_blank" rel="noopener" href="https://kubernetes.io/zh-cn/docs/concepts/storage/persistent-volumes/#reclaim-policy">其 StorageClass 中设置的回收策略</a>， 该策略默认为 Delete。管理员需要根据用户的期望来配置 StorageClass； 否则 PV 卷被创建之后必须要被编辑或者修补。</p>
<h6 id="回收（Recycle）"><a href="#回收（Recycle）" class="headerlink" title="回收（Recycle）"></a>回收（Recycle）</h6><p><strong>警告：</strong> 回收策略 Recycle 已被废弃。取而代之的建议方案是使用动态制备。</p>
<p>如果下层的卷插件支持，回收策略 Recycle 会在卷上执行一些基本的擦除 （rm -rf &#x2F;thevolume&#x2F;*）操作，之后允许该卷用于新的 PVC 申领。</p>
<h4 id="5-2-3-2-PV"><a href="#5-2-3-2-PV" class="headerlink" title="5.2.3.2 PV"></a>5.2.3.2 PV</h4><h5 id="状态"><a href="#状态" class="headerlink" title="状态"></a>状态</h5><p><strong>Available：</strong> 空闲，未被绑定</p>
<p><strong>Bound：</strong> 已经被PVC绑定</p>
<p><strong>Released：</strong> PVC被删除，资源已回收，但是PV未被重新使用</p>
<p><strong>Failed：</strong> 自动回收失败</p>
<h5 id="配置文件-5"><a href="#配置文件-5" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv0001</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 5Gi # pv 的容量</span><br><span class="line">  volumeMode: Filesystem # 存储类型为文件系统</span><br><span class="line">  accessModes: # 访问模式：ReadWriteOnce、ReadWriteMany、ReadOnlyMany</span><br><span class="line">    - ReadWriteOnce # 可被单节点独写</span><br><span class="line">  persistentVolumeReclaimPolicy: Recycle # 回收策略</span><br><span class="line">  storageClassName: slow # 创建 PV 的存储类名，需要与 pvc 的相同</span><br><span class="line">  mountOptions: # 加载配置</span><br><span class="line">    - hard</span><br><span class="line">    - nfsvers=4.1</span><br><span class="line">  nfs: # 连接到 nfs</span><br><span class="line">    path: /data/nfs/rw/test-pv # 存储路径</span><br><span class="line">    server: 192.168.113.121 # nfs 服务地址</span><br></pre></td></tr></table></figure>

<h4 id="5-2-3-3-PVC"><a href="#5-2-3-3-PVC" class="headerlink" title="5.2.3.3 PVC"></a>5.2.3.3 PVC</h4><h5 id="Pod绑定PVC"><a href="#Pod绑定PVC" class="headerlink" title="Pod绑定PVC"></a>Pod绑定PVC</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">在 pod 的挂载容器配置中，增加 pvc 挂载</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: test-pvc-pod</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    name: nginx-volume</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: /test-pod</span><br><span class="line">      name: test-volume</span><br><span class="line">  volumes:</span><br><span class="line">  - name: test-volume</span><br><span class="line">    persistentVolumeClaim:</span><br><span class="line">      claimName: nfs-pvc # pvc 的名称</span><br></pre></td></tr></table></figure>

<h5 id="配置文件-6"><a href="#配置文件-6" class="headerlink" title="配置文件"></a>配置文件</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteOnce # 权限需要与对应的 pv 相同</span><br><span class="line">  volumeMode: Filesystem</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 5Gi # 资源可以小于 pv 的，但是不能大于，如果大于就会匹配不到 pv</span><br><span class="line">  storageClassName: slow # 名字需要与对应的 pv 相同</span><br><span class="line">#  selector: # 使用选择器选择对应的 pv</span><br><span class="line">#    matchLabels:</span><br><span class="line">#      release: &quot;stable&quot;</span><br><span class="line">#    matchExpressions:</span><br><span class="line">#      - &#123;key: environment, operator: In, values: [dev]&#125;</span><br></pre></td></tr></table></figure>

<h4 id="5-2-3-4-StorageClass"><a href="#5-2-3-4-StorageClass" class="headerlink" title="5.2.3.4 StorageClass"></a>5.2.3.4 StorageClass</h4><h5 id="制备器（Provisioner）"><a href="#制备器（Provisioner）" class="headerlink" title="制备器（Provisioner）"></a>制备器（Provisioner）</h5><p>每个 StorageClass 都有一个制备器（Provisioner），用来决定使用哪个卷插件制备 PV。</p>
<h5 id="NFS动态制备案例"><a href="#NFS动态制备案例" class="headerlink" title="NFS动态制备案例"></a>NFS动态制备案例</h5><p>参考文档1：<a target="_blank" rel="noopener" href="https://kubernetes.io/docs/concepts/storage/storage-classes/">https://kubernetes.io/docs/concepts/storage/storage-classes/</a></p>
<p>参考文档2：<a target="_blank" rel="noopener" href="https://github.com/kubernetes-csi/csi-driver-nfs#readme">https://github.com/kubernetes-csi/csi-driver-nfs#readme</a></p>
<p>使用helm安装特定版本csi-driver-nfs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm repo add csi-driver-nfs https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/charts</span><br><span class="line">helm install csi-driver-nfs csi-driver-nfs/csi-driver-nfs --namespace kube-system --version v4.7.0</span><br></pre></td></tr></table></figure>

<p>创建storage class</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-csi</span><br><span class="line">provisioner: nfs.csi.k8s.io</span><br><span class="line">parameters:</span><br><span class="line">  server: 192.168.122.120    # 改为自己的 nfs server</span><br><span class="line">  share: /data/nfs/rw    # 改为自己的nfs 共享路径</span><br><span class="line">  # csi.storage.k8s.io/provisioner-secret is only needed for providing mountOptions in DeleteVolume</span><br><span class="line">  # csi.storage.k8s.io/provisioner-secret-name: &quot;mount-options&quot;</span><br><span class="line">  # csi.storage.k8s.io/provisioner-secret-namespace: &quot;default&quot;</span><br><span class="line">reclaimPolicy: Delete</span><br><span class="line">volumeBindingMode: Immediate</span><br><span class="line">mountOptions:</span><br><span class="line">  - nfsvers=4.1</span><br></pre></td></tr></table></figure>

<p>创建PVC</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f https://raw.githubusercontent.com/kubernetes-csi/csi-driver-nfs/master/deploy/example/pvc-nfs-csi-dynamic.yaml</span><br><span class="line"></span><br><span class="line"># pvc-nfs-csi-dynamic.yaml文件内容：</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: pvc-nfs-dynamic</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 10Gi</span><br><span class="line">  storageClassName: nfs-csi</span><br></pre></td></tr></table></figure>

<p>动态PVC测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-pv-test-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 300Mi</span><br><span class="line">  storageClassName: nfs-csi</span><br></pre></td></tr></table></figure>

<p>查看结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pvc</span><br><span class="line">kubectl get pv</span><br><span class="line">ls /data/nfs/rw</span><br></pre></td></tr></table></figure>



<p><strong>注：以下部分由于quay.io&#x2F;external_storage&#x2F;nfs-client-provisioner:latest镜像截至2024&#x2F;5&#x2F;8已有6年未更新，新版docker已不支持该版镜像；其他镜像源经过测试也无法使用故删除</strong></p>
<h5 id="NFS动态制备案例-1"><a href="#NFS动态制备案例-1" class="headerlink" title="NFS动态制备案例"></a><del>NFS动态制备案例</del></h5><h6 id="nfs-provisioner"><a href="#nfs-provisioner" class="headerlink" title="nfs-provisioner"></a><del>nfs-provisioner</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    app: nfs-client-provisioner</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  strategy:</span><br><span class="line">    type: Recreate</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nfs-client-provisioner</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nfs-client-provisioner</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: nfs-client-provisioner</span><br><span class="line">      containers:</span><br><span class="line">        - name: nfs-client-provisioner</span><br><span class="line">          #image: quay.io/external_storage/nfs-client-provisioner:latest # 原镜像，被墙，无法直接访问</span><br><span class="line">          image: registry.cn-hangzhou.aliyuncs.com/open-ali/nfs-client-provisioner:latest</span><br><span class="line">          volumeMounts:</span><br><span class="line">            - name: nfs-client-root</span><br><span class="line">              mountPath: /persistentvolumes</span><br><span class="line">          env:</span><br><span class="line">            - name: PROVISIONER_NAME</span><br><span class="line">              value: fuseim.pri/ifs</span><br><span class="line">            - name: NFS_SERVER</span><br><span class="line">              value: 192.168.122.120</span><br><span class="line">            - name: NFS_PATH</span><br><span class="line">              value: /data/nfs/rw</span><br><span class="line">      volumes:</span><br><span class="line">        - name: nfs-client-root</span><br><span class="line">          nfs:</span><br><span class="line">            server: 192.168.122.120</span><br><span class="line">            path: /data/nfs/rw</span><br></pre></td></tr></table></figure>

<h6 id="StorageClass配置"><a href="#StorageClass配置" class="headerlink" title="StorageClass配置"></a><del>StorageClass配置</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  name: managed-nfs-storage</span><br><span class="line">  namespace: kube-system</span><br><span class="line">provisioner: fuseim.pri/ifs # 外部制备器提供者，编写为提供者的名称</span><br><span class="line">parameters:</span><br><span class="line">  archiveOnDelete: &quot;false&quot; # 是否存档，false 表示不存档，会删除 oldPath 下面的数据，true 表示存档，会重命名路径</span><br><span class="line">reclaimPolicy: Retain # 回收策略，默认为 Delete 可以配置为 Retain</span><br><span class="line">volumeBindingMode: Immediate # 默认为 Immediate，表示创建 PVC 立即进行绑定，只有 azuredisk 和 AWSelasticblockstore 支持其他值</span><br></pre></td></tr></table></figure>

<h6 id="RBAC配置"><a href="#RBAC配置" class="headerlink" title="RBAC配置"></a><del>RBAC配置</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumes&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;delete&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;persistentvolumeclaims&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;update&quot;]</span><br><span class="line">  - apiGroups: [&quot;storage.k8s.io&quot;]</span><br><span class="line">    resources: [&quot;storageclasses&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;events&quot;]</span><br><span class="line">    verbs: [&quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: run-nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">    namespace: default</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: nfs-client-provisioner-runner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">---</span><br><span class="line">kind: Role</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups: [&quot;&quot;]</span><br><span class="line">    resources: [&quot;endpoints&quot;]</span><br><span class="line">    verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;]</span><br><span class="line">---</span><br><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  namespace: kube-system</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: nfs-client-provisioner</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: leader-locking-nfs-client-provisioner</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">创建rbac</span><br><span class="line">kubectl apply -f rbac.yaml</span><br><span class="line"></span><br><span class="line">创建deployment</span><br><span class="line">kubectl apply -f deployment.yaml</span><br><span class="line"></span><br><span class="line">创建storage class</span><br><span class="line">kubectl apply -f storageclass.yaml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="PVC处于Pending状态"><a href="#PVC处于Pending状态" class="headerlink" title="PVC处于Pending状态"></a><del>PVC处于Pending状态</del></h6><p><del>在 k8s 1.20 之后，出于对性能和统一 apiserver 调用方式的初衷，移除了对 SelfLink 的支持，而默认上面指定的 provisioner 版本需要 SelfLink 功能，因此 PVC 无法进行自动制备。</del></p>
<ul>
<li><p><del>配置SelfLink</del></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">修改 apiserver 配置文件</span><br><span class="line">vim /etc/kubernetes/manifests/kube-apiserver.yaml</span><br><span class="line"></span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - --feature-gates=RemoveSelfLink=false # 新增该行</span><br><span class="line">    ......</span><br><span class="line"></span><br><span class="line">修改后重新应用该配置</span><br><span class="line">kubectl apply -f /etc/kubernetes/manifests/kube-apiserver.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p><del>不需要SelfLink的provisioner</del></p>
<p><del>将 provisioner 修改为如下镜像之一即可</del></p>
<p><del><a target="_blank" rel="noopener" href="http://gcr.io/k8s-staging-sig-storage/nfs-subdir-external-provisioner:v4.0.0">gcr.io&#x2F;k8s-staging-sig-storage&#x2F;nfs-subdir-external-provisioner:v4.0.0</a></del></p>
<p><del><a target="_blank" rel="noopener" href="http://registry.cn-beijing.aliyuncs.com/pylixm/nfs-subdir-external-provisioner:v4.0.0">registry.cn-beijing.aliyuncs.com&#x2F;pylixm&#x2F;nfs-subdir-external-provisioner:v4.0.0</a></del></p>
</li>
</ul>
<h6 id="PVC测试配置"><a href="#PVC测试配置" class="headerlink" title="PVC测试配置"></a><del>PVC测试配置</del></h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolumeClaim</span><br><span class="line">metadata:</span><br><span class="line">  name: auto-pv-test-pvc</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">  - ReadWriteOnce</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 300Mi</span><br><span class="line">  storageClassName: managed-nfs-storage</span><br></pre></td></tr></table></figure>

<h1 id="六、高级调度"><a href="#六、高级调度" class="headerlink" title="六、高级调度"></a>六、高级调度</h1><h2 id="6-1-CronJob计划任务"><a href="#6-1-CronJob计划任务" class="headerlink" title="6.1 CronJob计划任务"></a>6.1 CronJob计划任务</h2><h3 id="cron表达式"><a href="#cron表达式" class="headerlink" title="cron表达式"></a>cron表达式</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># ┌───────────── 分钟 (0 - 59)</span><br><span class="line"># │ ┌───────────── 小时 (0 - 23)</span><br><span class="line"># │ │ ┌───────────── 月的某天 (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── 月份 (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）</span><br><span class="line"># │ │ │ │ │                          或者是 sun，mon，tue，web，thu，fri，sat</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * *</span><br></pre></td></tr></table></figure>

<h3 id="配置文件-7"><a href="#配置文件-7" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: batch/v1</span><br><span class="line">kind: CronJob</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line">spec:</span><br><span class="line">  concurrencyPolicy: Allow # 并发调度策略：Allow 允许并发调度，Forbid：不允许并发执行，Replace：如果之前的任务还没执行完，就直接执行新的，放弃上一个任务</span><br><span class="line">  failedJobsHistoryLimit: 1 # 保留多少个失败的任务</span><br><span class="line">  successfulJobsHistoryLimit: 3 # 保留多少个成功的任务</span><br><span class="line">  suspend: false # 是否挂起任务，若为 true 则该任务不会执行</span><br><span class="line">#  startingDeadlineSeconds: 30 # 间隔多长时间检测失败的任务并重新执行，时间不能小于 10</span><br><span class="line">  schedule: &quot;* * * * *&quot; # 调度策略</span><br><span class="line">  jobTemplate:</span><br><span class="line">    spec:</span><br><span class="line">      template:</span><br><span class="line">        spec:</span><br><span class="line">          containers:</span><br><span class="line">          - name: hello</span><br><span class="line">            image: busybox:1.28</span><br><span class="line">            imagePullPolicy: IfNotPresent</span><br><span class="line">            command:</span><br><span class="line">            - /bin/sh</span><br><span class="line">            - -c</span><br><span class="line">            - date; echo Hello from the Kubernetes cluster</span><br><span class="line">          restartPolicy: OnFailure</span><br></pre></td></tr></table></figure>

<h2 id="6-2-初始化容器InitContainer"><a href="#6-2-初始化容器InitContainer" class="headerlink" title="6.2 初始化容器InitContainer"></a>6.2 初始化容器InitContainer</h2><p>在真正的容器启动之前，先启动 InitContainer，在初始化容器中完成真实容器所需的初始化操作，完成后再启动真实的容器。</p>
<p>相对于 postStart 来说，首先 InitController 能够保证一定在 EntryPoint 之前执行，而 postStart 不能，其次 postStart 更适合去执行一些命令操作，而 InitController 实际就是一个容器，可以在其他基础容器环境下执行更复杂的初始化功能。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">在 pod 创建的模板中配置 initContainers 参数：</span><br><span class="line">spec:</span><br><span class="line">  initContainers:</span><br><span class="line">  - image: nginx</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    command: [&quot;sh&quot;, &quot;-c&quot;, &quot;echo &#x27;inited;&#x27; &gt;&gt; ~/.init&quot;]</span><br><span class="line">    name: init-test</span><br></pre></td></tr></table></figure>

<h2 id="6-3-污点与容忍"><a href="#6-3-污点与容忍" class="headerlink" title="6.3 污点与容忍"></a>6.3 污点与容忍</h2><p>k8s 集群中可能管理着非常庞大的服务器，这些服务器可能是各种各样不同类型的，比如机房、地理位置、配置等，有些是计算型节点，有些是存储型节点，此时我们希望能更好的将 pod 调度到与之需求更匹配的节点上。</p>
<p>此时就需要用到污点（Taint）和容忍（Toleration），这些配置都是 key: value 类型的。</p>
<h3 id="6-3-1-污点（Taint）"><a href="#6-3-1-污点（Taint）" class="headerlink" title="6.3.1 污点（Taint）"></a>6.3.1 污点（Taint）</h3><p>污点：是标注在节点上的，当我们在一个节点上打上污点以后，k8s 会认为尽量不要将 pod 调度到该节点上，除非该 pod 上面表示可以容忍该污点，且一个节点可以打多个污点，此时则需要 pod 容忍所有污点才会被调度该节点。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 为节点打上污点</span><br><span class="line">kubectl taint node k8s-master key=value:NoSchedule</span><br><span class="line"></span><br><span class="line"># 移除污点</span><br><span class="line">kubectl taint node k8s-master key=value:NoSchedule-</span><br><span class="line"></span><br><span class="line"># 查看污点</span><br><span class="line">kubectl describe no k8s-master</span><br></pre></td></tr></table></figure>

<p>污点的影响：<br>NoSchedule：不能容忍的 pod 不能被调度到该节点，但是已经存在的节点不会被驱逐<br>NoExecute：不能容忍的节点会被立即清除，能容忍且没有配置 <strong>tolerationSeconds</strong> 属性，则可以一直运行，设置了 <strong>tolerationSeconds</strong>: 3600 属性，则该 pod 还能继续在该节点运行 3600 秒</p>
<h4 id="NoSchedule"><a href="#NoSchedule" class="headerlink" title="NoSchedule"></a>NoSchedule</h4><p>如果不能容忍该污点，那么 Pod 就无法调度到该节点上</p>
<h4 id="NoExecute"><a href="#NoExecute" class="headerlink" title="NoExecute"></a>NoExecute</h4><ul>
<li>如果 Pod 不能忍受这类污点，Pod 会马上被驱逐。</li>
<li>如果 Pod 能够忍受这类污点，但是在容忍度定义中没有指定 tolerationSeconds， 则 Pod 还会一直在这个节点上运行。</li>
<li>如果 Pod 能够忍受这类污点，而且指定了 tolerationSeconds， 则 Pod 还能在这个节点上继续运行这个指定的时间长度。</li>
</ul>
<h3 id="6-3-2-容忍（Toleration）"><a href="#6-3-2-容忍（Toleration）" class="headerlink" title="6.3.2 容忍（Toleration）"></a>6.3.2 容忍（Toleration）</h3><p>容忍：是标注在 pod 上的，当 pod 被调度时，如果没有配置容忍，则该 pod 不会被调度到有污点的节点上，只有该 pod 上标注了满足某个节点的所有污点，则会被调度到这些节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># pod 的 spec 下面配置容忍</span><br><span class="line">tolerations:</span><br><span class="line">- key: &quot;污点的 key&quot;</span><br><span class="line">  value: &quot;污点的 value&quot;</span><br><span class="line">  offect: &quot;NoSchedule&quot; # 污点产生的影响</span><br><span class="line">  operator: &quot;Equal&quot; # 表是 value 与污点的 value 要相等，也可以设置为 Exists 表示存在 key 即可，此时可以不用配置 value</span><br></pre></td></tr></table></figure>

<h4 id="Equal"><a href="#Equal" class="headerlink" title="Equal"></a>Equal</h4><p>比较操作类型为 Equal，则意味着必须与污点值做匹配，key&#x2F;value都必须相同，才表示能够容忍该污点</p>
<h4 id="Exists"><a href="#Exists" class="headerlink" title="Exists"></a>Exists</h4><p>容忍与污点的比较只比较 key，不比较 value，不关心 value 是什么东西，只要 key 存在，就表示可以容忍。</p>
<h2 id="6-4-亲和力"><a href="#6-4-亲和力" class="headerlink" title="6.4 亲和力"></a>6.4 亲和力</h2><h3 id="6-4-1-NodeAffinity"><a href="#6-4-1-NodeAffinity" class="headerlink" title="6.4.1 NodeAffinity"></a>6.4.1 NodeAffinity</h3><p>节点亲和力：进行 pod 调度时，优先调度到符合条件的亲和力节点上</p>
<h4 id="RequiredDuringSchedulingIgnoredDuringExecution"><a href="#RequiredDuringSchedulingIgnoredDuringExecution" class="headerlink" title="RequiredDuringSchedulingIgnoredDuringExecution"></a>RequiredDuringSchedulingIgnoredDuringExecution</h4><p>硬亲和力，即支持必须部署在指定的节点上，也支持必须不部署在指定的节点上</p>
<h4 id="PreferredDuringSchedulingIgnoredDuringExecution"><a href="#PreferredDuringSchedulingIgnoredDuringExecution" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExecution"></a>PreferredDuringSchedulingIgnoredDuringExecution</h4><p>软亲和力：尽量部署在满足条件的节点上，或尽量不要部署在被匹配的节点上</p>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><h5 id="匹配类型"><a href="#匹配类型" class="headerlink" title="匹配类型"></a>匹配类型</h5><ul>
<li>In：部署在满足条件的节点上</li>
<li>Noth：匹配不在条件中的节点，实现节点反亲和性</li>
<li>Exists：只要存在 key 名字就可以，不关心值是什么</li>
<li>DoesNotExist：匹配指定 key 名不存在的节点，实现节点反亲和性</li>
<li>Gt：value 为数值，且节点上的值小于指定的条件</li>
<li>Lt：value 为数值，且节点上的值大于指定条件</li>
</ul>
<h5 id="配置模板"><a href="#配置模板" class="headerlink" title="配置模板"></a>配置模板</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-node-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity: # 亲和力配置</span><br><span class="line">    nodeAffinity: # 节点亲和力</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution: # 节点必须匹配下方配置</span><br><span class="line">        nodeSelectorTerms: # 选择器</span><br><span class="line">        - matchExpressions: # 匹配表达式</span><br><span class="line">          - key: topology.kubernetes.io/zone # 匹配 label 的 key</span><br><span class="line">            operator: In # 匹配方式，只要匹配成功下方的一个 value 即可</span><br><span class="line">            values:</span><br><span class="line">            - antarctica-east1 # 匹配的 value</span><br><span class="line">            - antarctica-west1 # 匹配的 value</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution: # 节点尽量匹配下方配置</span><br><span class="line">      - weight: 1 # 权重[1,100]，按照匹配规则对所有节点累加权重，最终之和会加入优先级评分，优先级越高被调度的可能性越高</span><br><span class="line">        preference:</span><br><span class="line">          matchExpressions: # 匹配表达式</span><br><span class="line">          - key: another-node-label-key # label 的 key</span><br><span class="line">            operator: In # 匹配方式，满足一个即可</span><br><span class="line">            values:</span><br><span class="line">            - another-node-label-value # 匹配的 value</span><br><span class="line">#      - weight: 20</span><br><span class="line">        ......</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-node-affinity</span><br><span class="line">    image: pause:2.0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">为node打标签</span><br><span class="line">kubectl label nodes k8s-node1 security=S1</span><br></pre></td></tr></table></figure>

<h3 id="6-4-2-PodAffinity"><a href="#6-4-2-PodAffinity" class="headerlink" title="6.4.2 PodAffinity"></a>6.4.2 PodAffinity</h3><p>Pod 亲和力：将与指定 pod 亲和力相匹配的 pod 部署在同一节点。</p>
<h4 id="RequiredDuringSchedulingIgnoredDuringExecution-1"><a href="#RequiredDuringSchedulingIgnoredDuringExecution-1" class="headerlink" title="RequiredDuringSchedulingIgnoredDuringExecution"></a>RequiredDuringSchedulingIgnoredDuringExecution</h4><p>必须将应用部署在一块</p>
<h4 id="PreferredDuringSchedulingIgnoredDuringExecution-1"><a href="#PreferredDuringSchedulingIgnoredDuringExecution-1" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExecution"></a>PreferredDuringSchedulingIgnoredDuringExecution</h4><p>尽量将应用部署在一块</p>
<h4 id="配置模板-1"><a href="#配置模板-1" class="headerlink" title="配置模板"></a>配置模板</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: with-pod-affinity</span><br><span class="line">spec:</span><br><span class="line">  affinity: # 亲和力配置</span><br><span class="line">    podAffinity: # pod 亲和力配置</span><br><span class="line">      requiredDuringSchedulingIgnoredDuringExecution: # 当前 pod 必须匹配到对应条件 pod 所在的 node 上</span><br><span class="line">      - labelSelector: # 标签选择器</span><br><span class="line">          matchExpressions: # 匹配表达式</span><br><span class="line">          - key: security # 匹配的 key</span><br><span class="line">            operator: In # 匹配方式</span><br><span class="line">            values: # 匹配其中的一个 value</span><br><span class="line">            - S1</span><br><span class="line">        topologyKey: topology.kubernetes.io/zone</span><br><span class="line">    podAntiAffinity: # pod 反亲和力配置</span><br><span class="line">      preferredDuringSchedulingIgnoredDuringExecution: # 尽量不要将当前节点部署到匹配下列参数的 pod 所在的 node 上</span><br><span class="line">      - weight: 100 # 权重</span><br><span class="line">        podAffinityTerm: # pod 亲和力配置条件</span><br><span class="line">          labelSelector: # 标签选择器</span><br><span class="line">            matchExpressions: # 匹配表达式</span><br><span class="line">            - key: security # 匹配的 key</span><br><span class="line">              operator: In # 匹配的方式</span><br><span class="line">              values:</span><br><span class="line">              - S2 # 匹配的 value</span><br><span class="line">          topologyKey: topology.kubernetes.io/zone</span><br><span class="line">  containers:</span><br><span class="line">  - name: with-pod-affinity</span><br><span class="line">    image: pause:2.0</span><br></pre></td></tr></table></figure>

<h3 id="6-4-3-PodAntiAffinity"><a href="#6-4-3-PodAntiAffinity" class="headerlink" title="6.4.3 PodAntiAffinity"></a>6.4.3 PodAntiAffinity</h3><p>Pod 反亲和力：根据策略尽量部署或不部署到一块</p>
<h4 id="RequiredDuringSchedulingIgnoredDuringExecution-2"><a href="#RequiredDuringSchedulingIgnoredDuringExecution-2" class="headerlink" title="RequiredDuringSchedulingIgnoredDuringExecution"></a>RequiredDuringSchedulingIgnoredDuringExecution</h4><p>不要将应用与之匹配的部署到一块</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">podAffinity:</span><br><span class="line">  requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">  - labelSelector:</span><br><span class="line">      matchExpressions:</span><br><span class="line">      - key: security</span><br><span class="line">        operator: In</span><br><span class="line">        values:</span><br><span class="line">        - S1</span><br><span class="line">    topologyKey: topology.kubernetes.io/zone</span><br></pre></td></tr></table></figure>

<h4 id="PreferredDuringSchedulingIgnoredDuringExecution-2"><a href="#PreferredDuringSchedulingIgnoredDuringExecution-2" class="headerlink" title="PreferredDuringSchedulingIgnoredDuringExecution"></a>PreferredDuringSchedulingIgnoredDuringExecution</h4><p>尽量不要将应用部署到一块</p>
<h1 id="七、身份认证与权限"><a href="#七、身份认证与权限" class="headerlink" title="七、身份认证与权限"></a>七、身份认证与权限</h1><p>Kubernetes 中提供了良好的多租户认证管理机制，如 RBAC、ServiceAccount 还有各种策略等。</p>
<p>通过该文件可以看到已经配置了 RBAC 访问控制<br>&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service</p>
<h2 id="7-1-认证"><a href="#7-1-认证" class="headerlink" title="7.1 认证"></a>7.1 认证</h2><p>所有 Kubernetes 集群有两类用户：由 Kubernetes 管理的<a target="_blank" rel="noopener" href="http://docs.kubernetes.org.cn/84.html">Service Accounts</a> （服务账户）和（Users Accounts） 普通账户。</p>
<p>普通账户是假定被外部或独立服务管理的，由管理员分配 keys，用户像使用 Keystone 或 google 账号一样，被存储在包含 usernames 和 passwords 的 list 的文件里。</p>
<p><em>需要注意：在 Kubernetes 中不能通过 API 调用将普通用户添加到集群中</em>。</p>
<ul>
<li>普通帐户是针对（人）用户的，服务账户针对 Pod 进程。</li>
<li>普通帐户是全局性。在集群所有namespaces中，名称具有惟一性。</li>
<li>通常，群集的普通帐户可以与企业数据库同步，新的普通帐户创建需要特殊权限。服务账户创建目的是更轻量化，允许集群用户为特定任务创建服务账户。</li>
<li>普通帐户和服务账户的审核注意事项不同。</li>
<li>对于复杂系统的配置包，可以包括对该系统的各种组件的服务账户的定义。</li>
</ul>
<h3 id="7-1-1-User-Accounts"><a href="#7-1-1-User-Accounts" class="headerlink" title="7.1.1 User Accounts"></a>7.1.1 User Accounts</h3><h3 id="7-1-2-Service-Accounts"><a href="#7-1-2-Service-Accounts" class="headerlink" title="7.1.2 Service Accounts"></a>7.1.2 Service Accounts</h3><h4 id="Service-Account-自动化"><a href="#Service-Account-自动化" class="headerlink" title="Service Account 自动化"></a>Service Account 自动化</h4><h5 id="Service-Account-Admission-Controller"><a href="#Service-Account-Admission-Controller" class="headerlink" title="Service Account Admission Controller"></a>Service Account Admission Controller</h5><p>通过 <a target="_blank" rel="noopener" href="http://docs.kubernetes.org.cn/144.html">Admission Controller</a> 插件来实现对 pod 修改，它是 apiserver 的一部分。创建或更新 pod 时会同步进行修改 pod。当插件处于激活状态（在大多数发行版中都默认情况）创建或修改 pod 时，会按以下操作执行：</p>
<ol>
<li>如果 pod 没有设置 ServiceAccount，则将 ServiceAccount 设置为 default。</li>
<li>确保 pod 引用的 ServiceAccount 存在，否则将会拒绝请求。</li>
<li>如果 pod 不包含任何 ImagePullSecrets，则将ServiceAccount 的 ImagePullSecrets 会添加到 pod 中。</li>
<li>为包含 API 访问的 Token 的 pod 添加了一个 volume。</li>
<li>把 volumeSource 添加到安装在 pod 的每个容器中，挂载在 &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount。</li>
</ol>
<h5 id="Token-Countroller"><a href="#Token-Countroller" class="headerlink" title="Token Countroller"></a>Token Countroller</h5><p>TokenController 作为 controller-manager 的一部分运行。异步行为:</p>
<ul>
<li>观察 serviceAccount 的创建，并创建一个相应的 Secret 来允许 API 访问。</li>
<li>观察 serviceAccount 的删除，并删除所有相应的ServiceAccountToken Secret</li>
<li>观察 secret 添加，并确保关联的 ServiceAccount 存在，并在需要时向 secret 中添加一个 Token。</li>
<li>观察 secret 删除，并在需要时对应 ServiceAccount 的关联</li>
</ul>
<h5 id="Service-Account-Controller"><a href="#Service-Account-Controller" class="headerlink" title="Service Account Controller"></a>Service Account Controller</h5><p>Service Account Controller 在 namespaces 里管理ServiceAccount，并确保每个有效的 namespaces 中都存在一个名为 “default” 的 ServiceAccount。</p>
<h2 id="7-2-授权（RBAC）"><a href="#7-2-授权（RBAC）" class="headerlink" title="7.2 授权（RBAC）"></a>7.2 授权（RBAC）</h2><h3 id="7-2-1-Role"><a href="#7-2-1-Role" class="headerlink" title="7.2.1 Role"></a>7.2.1 Role</h3><p>代表一个角色，会包含一组权限，没有拒绝规则，只是附加允许。它是 Namespace 级别的资源，只能作用与 Namespace 之内。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看已有的角色信息</span><br><span class="line">kubectl get role -n ingress-nginx -oyaml</span><br></pre></td></tr></table></figure>

<h4 id="配置文件-8"><a href="#配置文件-8" class="headerlink" title="配置文件"></a>配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: Role</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app.kubernetes.io/name: ingress-nginx</span><br><span class="line">    app.kubernetes.io/part-of: ingress-nginx</span><br><span class="line">  name: nginx-ingress</span><br><span class="line">  namespace: ingress-nginx</span><br><span class="line">roles:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  - pods</span><br><span class="line">  - secrets</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resourceNames:</span><br><span class="line">  - ingress-controller-label-nginx</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">  - update</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - configmaps</span><br><span class="line">  verbs:</span><br><span class="line">  - create</span><br></pre></td></tr></table></figure>

<h3 id="7-2-2-ClusterRole"><a href="#7-2-2-ClusterRole" class="headerlink" title="7.2.2 ClusterRole"></a>7.2.2 ClusterRole</h3><p>功能与 Role 一样，区别是资源类型为集群类型，而 Role 只在 Namespace</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查看某个集群角色的信息</span><br><span class="line">kubectl get clusterrole view -oyaml</span><br></pre></td></tr></table></figure>

<h3 id="7-2-3-RoleBinding"><a href="#7-2-3-RoleBinding" class="headerlink" title="7.2.3 RoleBinding"></a>7.2.3 RoleBinding</h3><p>Role 或 ClusterRole 只是用于制定权限集合，具体作用与什么对象上，需要使用 RoleBinding 来进行绑定。</p>
<p>作用于 Namespace 内，可以将 Role 或 ClusterRole 绑定到 User、Group、Service Account 上。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看 rolebinding 信息</span><br><span class="line">kubectl get rolebinding --all-namespaces</span><br><span class="line"></span><br><span class="line"># 查看指定 rolebinding 的配置信息</span><br><span class="line">kubectl get rolebinding &lt;role_binding_name&gt; --all-namespaces -oyaml</span><br></pre></td></tr></table></figure>

<h4 id="配置文件-9"><a href="#配置文件-9" class="headerlink" title="配置文件"></a>配置文件</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: RoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  ......</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Role</span><br><span class="line">  name nginx-ingress-role</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: nginx-ingress-serviceaccount</span><br><span class="line">  namespace: ingress-nginx</span><br></pre></td></tr></table></figure>

<h3 id="7-2-4-ClusterRoleBinding"><a href="#7-2-4-ClusterRoleBinding" class="headerlink" title="7.2.4 ClusterRoleBinding"></a>7.2.4 ClusterRoleBinding</h3><p>与 RoleBinding 相同，但是作用于集群之上，可以绑定到该集群下的任意 User、Group 或 Service Account </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/" data-id="clzi26lgi0000gy7n0xnt83rf" data-title="K8S实战进阶" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2024/04/01/K8S%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">K8S核心概念</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kubernetes/" rel="tag">kubernetes</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/k8s/" style="font-size: 10px;">k8s</a> <a href="/tags/kubernetes/" style="font-size: 10px;">kubernetes</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/04/">April 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/1970/01/">January 1970</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/04/01/K8S%E5%AE%9E%E6%88%98%E8%BF%9B%E9%98%B6/">K8S实战进阶</a>
          </li>
        
          <li>
            <a href="/2024/04/01/K8S%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/">K8S核心概念</a>
          </li>
        
          <li>
            <a href="/1970/01/01/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>